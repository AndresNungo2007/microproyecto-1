{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microproyecto 1\n",
    "\n",
    "## Descripci√≥n del problema:\n",
    "\n",
    "El problema a resolver consiste en generar nuevas secuencias de notas musicales basadas en el estilo de los artistas existentes, mencionados en la r√∫brica del taller haciendo uso de archivos .mid como fuente de datos esto con el fin de entrenar un modelo que sea capaz de aprender de las diferentes caracter√≠sticas y posteriormente producir nuevas composiciones donde mantenga coherencia musical.\n",
    "\n",
    "## Objetivo:\n",
    "\n",
    "Con esta actividad se busca que el estudiante pueda poner en pr√°ctica el uso de modelos de redes neuronales para trabajar con datos secuenciales. Tras realizar esta actividad se espera que el estudiante est√© en capacidad de:\n",
    "1. Estructurar datos secuenciales de forma que pueden ser usados por modelos de redes neuronales.\n",
    "2. Desarrollar soluciones de machine learning para datos secuenciales en distintos dominios.\n",
    "3. Entrenar modelos de machine learning con m√∫ltiples salidas.\n",
    "4. Entrenar modelos de machine learning con una funci√≥n de costo compuesta.\n",
    "5. Utilizar el modelo entrenado para generar nuevas secuencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrantes Equipo 20\n",
    "- Andr√©s Felipe √ëungo Fern√°ndez\n",
    "- Andr√©s Juli√°n Gonzalez Barrera\n",
    "- Hernando Jose Jimenez D√≠az\n",
    "- Gloria In√©s L√≥pez Urbano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# √çndice\n",
    "\n",
    "El *notebook* aborda el microproyecto con la siguiente estructura:\n",
    "\n",
    "| üîπ | Secci√≥n        |\n",
    "|----|----------------|\n",
    "| 1Ô∏è.   | Instalaci√≥n e importe de librer√≠as |\n",
    "| 1Ô∏è.1Ô∏è  | Importar librer√≠as |\n",
    "| 1Ô∏è.2Ô∏è. | Definici√≥n variables globales |\n",
    "| 2Ô∏è.   | Carga y procesamiento de los datos       |\n",
    "| 2Ô∏è.1Ô∏è. | Extracci√≥n caracter√≠sticas de los archivos .mid       |\n",
    "| 2Ô∏è.2Ô∏è. | Estandarizar variables cuantitativas       |\n",
    "| 2Ô∏è.3Ô∏è. | Generar secuencias de entrenamiento _requeridas para LSTM_       |\n",
    "| 2Ô∏è.4Ô∏è. | Funci√≥n Guardar secuencias a MIDI       |\n",
    "| 3Ô∏è. | **Definici√≥n de *pipelines* de procesamiento y modelamiento**          |\n",
    "| 3Ô∏è.1Ô∏è. | **Definici√≥n de funciones y grillas**   |\n",
    "| 4Ô∏è. | **Desarrollo del modelo**   |\n",
    "| 4Ô∏è.1Ô∏è. | **B√∫squeda de hiperpar√°metros**   |\n",
    "| 4Ô∏è.2Ô∏è. | **Funciones para re-entrenamiento**   |\n",
    "| 4Ô∏è.3Ô∏è. | **Definici√≥n de _main_**   |\n",
    "| 5Ô∏è. | **An√°lisis de resultados y discusi√≥n**   |\n",
    "| 6Ô∏è. | **Conclusi√≥n**   |\n",
    "| 7Ô∏è. | **Referencias**   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalaci√≥n e importe de librer√≠as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versi√≥n usada de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.11\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la ejecuci√≥n de este Notebook, se recomienda realizar instalaci√≥n de las librer√≠as mencionadas a continuaci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IW1eQD90BIgG",
    "outputId": "e262966a-1613-46c1-ecd9-f57aa3bb2d5d"
   },
   "outputs": [],
   "source": [
    "#!pip install torch\n",
    "#!pip install pretty_midi\n",
    "#!pip install mido\n",
    "#!pip install pyFluidSynth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar DLLs externas.\n",
    "TODO: explicar como se realiza la instalacion de FluidSynth en windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CDLL 'C:\\Tools\\FluidSynth\\bin\\libfluidsynth-3.dll', handle 7ffd99240000 at 0x2bb567dfc20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Bootstrap FluidSynth (Windows, persistente por sesi√≥n de kernel) ---\n",
    "import os\n",
    "if os.name == \"nt\":\n",
    "    DLL_DIR = r\"C:\\Tools\\FluidSynth\\bin\"  # carpeta donde pusiste libfluidsynth-3.dll\n",
    "    if hasattr(os, \"add_dll_directory\"):\n",
    "        os.add_dll_directory(DLL_DIR)\n",
    "    os.environ[\"FLUIDSYNTH_LIBRARY\"] = os.path.join(DLL_DIR, \"libfluidsynth-3.dll\")\n",
    "\n",
    "# (opcional) smoke test de la DLL para fallar pronto si algo cambi√≥\n",
    "from ctypes import CDLL\n",
    "CDLL(os.environ[\"FLUIDSYNTH_LIBRARY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WY-yhu2NgFf6"
   },
   "source": [
    "## 1.1 Importar librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_J3PzSeYEF4S"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from scipy.io.wavfile import write\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Librer√≠as para MIDI y audio\n",
    "import fluidsynth as pyfluidsynth\n",
    "import pretty_midi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPTN5Y8YgIjn"
   },
   "source": [
    "## 1.2 Definici√≥n variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BU-R44U_GJ3O"
   },
   "outputs": [],
   "source": [
    "ROOT_DIR =  \"./Dataset/music_artist\"  # \"/content/drive/MyDrive/Colab Notebooks/Dataset/TEST\"   # <-- directorio ra√≠z con carpetas de compositores\n",
    "OUTPUT_DIR = Path(\"./OUTPUT\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SEQ_LEN = 32 # Block size\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_SIZE = 384\n",
    "EPOCHS = 40\n",
    "LR = 3e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_TYPE = \"LSTM\"  # opciones: \"RNN\", \"LSTM\", \"GRU\"\n",
    "INSTRUMENT_NAME = \"Acoustic Grand Piano\"\n",
    "COMPOSER = \"schubert\"  # este es el artista que tiene m√°s datos\n",
    "NUM_SEQS       = 3  # N√∫mero de secuencias a generar\n",
    "STEPS_PER_SEQ  = 200  # Notas que debe tener cada secuencia\n",
    "TEMPERATURE    = 0.7  # Temperatura\n",
    "NUM_LAYERS = 4\n",
    "DROPOUT = 0.3\n",
    "TOP_K = 20\n",
    "PESO_LOSS_CONT = 50\n",
    "SF2 = \"./soundfonts/FluidR3_GM.sf2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 13\n",
    "random.seed(RANDOM_STATE); np.random.seed(RANDOM_STATE); torch.manual_seed(RANDOM_STATE)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "beKjgq-gGSI6",
    "outputId": "764903b1-722b-490c-d606-c5f8b7d8f6ac"
   },
   "outputs": [],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFgUa-JNgPMd"
   },
   "source": [
    "# 2. Carga y procesamiento de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJrvj5YdhVoo"
   },
   "source": [
    "## 2.1. Extracci√≥n caracter√≠sticas de los archivos .mid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta secci√≥n se realiza la selecci√≥n del primer instrumento encontrado y extracci√≥n notas del instrumento seleccionado. Como resultado se extraen las siguientes caracter√≠sticas por cada nota le√≠da:   \n",
    "- Pitch: representa la nota musical.\n",
    "- Step: es el espacio de tiempo que hay entre la nota anterior y la nota actual.\n",
    "- Duraction: Es la diferencia de tiempo en el que termina la nota actual (end) menos el inicio de la nota (start).\n",
    "- Velocity: es la velocidad de la nota musical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_raw_note_sequences(root_dir, instrument_name=None, program_number=None, composer_name=None):\n",
    "    raw_sequences = []\n",
    "    candidates = [composer_name] if composer_name else [\n",
    "        d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))\n",
    "    ]\n",
    "    for composer in candidates:\n",
    "        folder = os.path.join(root_dir, composer)\n",
    "        midi_files = glob.glob(os.path.join(folder, \"*.mid\"))\n",
    "\n",
    "        for mf in midi_files:\n",
    "            try:\n",
    "                pm = pretty_midi.PrettyMIDI(mf)\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo leer {mf}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # --- Selecci√≥n de instrumento ---\n",
    "            chosen_instruments = []\n",
    "            for i, inst in enumerate(pm.instruments):\n",
    "                name = pretty_midi.program_to_instrument_name(inst.program)\n",
    "                print(f\"[{i}] prog={inst.program:>2} name={name} notas={len(inst.notes)}\")\n",
    "                if instrument_name is not None:\n",
    "                    inst_name = pretty_midi.program_to_instrument_name(inst.program)\n",
    "                    if inst_name.lower() == instrument_name.lower():\n",
    "                        chosen_instruments.append(inst)\n",
    "                elif program_number is not None:\n",
    "                    if inst.program == program_number:\n",
    "                        chosen_instruments.append(inst)\n",
    "\n",
    "            # Si no hubo match expl√≠cito y no se especific√≥ filtro, tomamos el primero (comportamiento viejo)\n",
    "            if instrument_name is None and program_number is None:\n",
    "                chosen_instruments = pm.instruments[:1]  # solo el primero\n",
    "\n",
    "            if not chosen_instruments:\n",
    "                # Nada que extraer en este archivo para el instrumento pedido\n",
    "                continue\n",
    "\n",
    "            # --- Extraer notas SOLO del/los instrumentos elegidos ---\n",
    "            notes = []\n",
    "            for inst in chosen_instruments:\n",
    "                for note_mus in inst.notes:\n",
    "                    start = note_mus.start\n",
    "                    end = note_mus.end\n",
    "                    duration = end - start\n",
    "                    velocity = note_mus.velocity\n",
    "                    notes.append((start, note_mus.pitch, duration, velocity))\n",
    "\n",
    "            if not notes:\n",
    "                continue\n",
    "\n",
    "            # Ordenar por inicio y construir [pitch, step, duration, velocity]\n",
    "            notes.sort(key=lambda x: x[0])\n",
    "            note_feats = []\n",
    "            prev_start = notes[0][0]\n",
    "            for start, pitch, duration, velocity in notes:\n",
    "                step = start - prev_start\n",
    "                prev_start = start\n",
    "                note_feats.append([pitch, step, duration, velocity])\n",
    "\n",
    "            if note_feats:\n",
    "                raw_sequences.append(np.array(note_feats, dtype=np.float32))\n",
    "\n",
    "    return raw_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C04D1njqhYFn"
   },
   "source": [
    "## 2.2. Estandarizar variables cuantitativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este paso es necesario dado que los modelos de red neuronal son muy sensibles a las escalas de los datos. Al no estandarizar las variables continuas, el modelo no aprender√° correctamente las relaciones entre variables.\n",
    "La presente estandarizaci√≥n lleva todas las variables continuas a extraer el promedio y la desviaci√≥n estandar normalizando cada valor individual, siguiendo la f√≥rmula del z-score:\n",
    "`norm_x = (x - mean) / std`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jv0A8oHWKEne"
   },
   "outputs": [],
   "source": [
    "def standardize_note_sequences(sequences):\n",
    "    \"\"\"\n",
    "    Estandariza las variables continuas (step, duration, velocity)\n",
    "    y mantiene el pitch intacto para usarlo luego con embeddings.\n",
    "    \"\"\"\n",
    "    all_steps, all_durations, all_velocities = [], [], []\n",
    "\n",
    "    # Recolectar todas las variables continuas para calcular media y std global\n",
    "    for seq in sequences:\n",
    "        all_steps.extend(seq[:, 1])\n",
    "        all_durations.extend(seq[:, 2])\n",
    "        all_velocities.extend(seq[:, 3])\n",
    "\n",
    "    # Estad√≠sticas globales\n",
    "    step_mean, step_std = np.mean(all_steps), np.std(all_steps)\n",
    "    dur_mean, dur_std = np.mean(all_durations), np.std(all_durations)\n",
    "    vel_mean, vel_std = np.mean(all_velocities), np.std(all_velocities)\n",
    "\n",
    "    standardized = []\n",
    "    for seq in sequences:\n",
    "        seq_std = seq.copy()\n",
    "        # No tocar pitch (columna 0)\n",
    "        seq_std[:, 1] = (seq[:, 1] - step_mean) / (step_std + 1e-6)\n",
    "        seq_std[:, 2] = (seq[:, 2] - dur_mean) / (dur_std + 1e-6)\n",
    "        seq_std[:, 3] = (seq[:, 3] - vel_mean) / (vel_std + 1e-6)\n",
    "        standardized.append(seq_std)\n",
    "\n",
    "    stats = {\n",
    "        \"step_mean\": step_mean, \"step_std\": step_std,\n",
    "        \"dur_mean\": dur_mean, \"dur_std\": dur_std,\n",
    "        \"vel_mean\": vel_mean, \"vel_std\": vel_std\n",
    "    }\n",
    "\n",
    "    return standardized, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1n9XyNyhcej"
   },
   "source": [
    "## 2.3. Generar secuencias de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta secci√≥n realiza la conversi√≥n de una secuencia larga de notas en muestras peque√±as de longitud fija llamadas ventanas o secuencias de entrenamiento.\n",
    "La entrada de datos debe tener estandarizadas las variables continuas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWsFUkyhS404"
   },
   "outputs": [],
   "source": [
    "def create_windows(sequences, seq_len=32):\n",
    "    \"\"\"\n",
    "    Crea pares (X, y) para entrenamiento a partir de las secuencias estandarizadas.\n",
    "    X: secuencia de longitud seq_len\n",
    "    y: la nota siguiente\n",
    "    La variable pitch se mantiene intacto dado que es una variable categ√≥rica que se usar√° con embeddings.\n",
    "    \"\"\"\n",
    "    X_pitch, X_cont, y_pitch, y_cont = [], [], [], []\n",
    "\n",
    "    for seq in sequences:\n",
    "        if len(seq) < seq_len + 1:\n",
    "            continue\n",
    "\n",
    "        # Dividir en ventanas\n",
    "        for i in range(len(seq) - seq_len):\n",
    "            window = seq[i:i+seq_len]\n",
    "            target = seq[i+seq_len]\n",
    "\n",
    "            # Separar pitch (entero) y las features continuas\n",
    "            X_pitch.append(window[:, 0].astype(np.int64))     # pitch\n",
    "            X_cont.append(window[:, 1:].astype(np.float32))   # step, duration, velocity\n",
    "            y_pitch.append(int(target[0]))                    # pitch de la siguiente nota\n",
    "            y_cont.append(target[1:].astype(np.float32))      # step, duration, velocity siguientes\n",
    "\n",
    "    # Convertir a arrays numpy\n",
    "    X_pitch = np.array(X_pitch, dtype=np.int64)\n",
    "    X_cont = np.array(X_cont, dtype=np.float32)\n",
    "    y_pitch = np.array(y_pitch, dtype=np.int64)\n",
    "    y_cont = np.array(y_cont, dtype=np.float32)\n",
    "\n",
    "    return (X_pitch, X_cont), (y_pitch, y_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vH4IXLREhjSW"
   },
   "source": [
    "## 2.4. Funci√≥n Guardar secuencias a MIDI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funci√≥n `save_sequence_to_midi` permite tomar las secuencias estandarizadas y generar de nuevo el archivo .mid con el fin de validar que no se haya corrompido las notas musicales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkQMkq6idGIz"
   },
   "outputs": [],
   "source": [
    "def save_sequence_to_midi(seq, output_path=\"generated.mid\", instrument_name=\"Acoustic Grand Piano\"):\n",
    "    \"\"\"\n",
    "    seq: np.array (N,4) con columnas [pitch, step, duration, velocity] en ESCALA REAL.\n",
    "    \"\"\"\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    try:\n",
    "        program_number = pretty_midi.instrument_name_to_program(instrument_name)\n",
    "    except ValueError:\n",
    "        program_number = 0\n",
    "    instrument = pretty_midi.Instrument(program=program_number)\n",
    "\n",
    "    # Asegurar valores v√°lidos\n",
    "    pitch    = seq[:, 0].astype(int)\n",
    "    step     = np.maximum(seq[:, 1].astype(float), 0.0)\n",
    "    duration = np.maximum(seq[:, 2].astype(float), 0.01)\n",
    "    velocity = np.clip(seq[:, 3].astype(float), 0, 127).astype(int)\n",
    "\n",
    "    # Reconstruir tiempos absolutos\n",
    "    t = 0.0\n",
    "    for p, s, d, v in zip(pitch, step, duration, velocity):\n",
    "        t += s\n",
    "        note = pretty_midi.Note(velocity=int(v), pitch=int(p), start=float(t), end=float(t + d))\n",
    "        instrument.notes.append(note)\n",
    "\n",
    "    pm.instruments.append(instrument)\n",
    "    pm.write(output_path)\n",
    "    print(f\"MIDI guardado en: {output_path} ({instrument_name})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_std_sequence_to_midi(seq_std, stats, output_path=\"reconstructed.mid\", instrument_name=\"Acoustic Grand Piano\"):\n",
    "    \"\"\"\n",
    "    seq_std: np.array (N,4) [pitch, stepZ, durationZ, velocityZ] estandarizados.\n",
    "    stats: dict con medias/stds {'step_mean','step_std','dur_mean','dur_std','vel_mean','vel_std'}\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    # Desestandarizar\n",
    "    pitch    = seq_std[:, 0]\n",
    "    step     = seq_std[:, 1] * stats[\"step_std\"] + stats[\"step_mean\"]\n",
    "    duration = seq_std[:, 2] * stats[\"dur_std\"] + stats[\"dur_mean\"]\n",
    "    velocity = seq_std[:, 3] * stats[\"vel_std\"] + stats[\"vel_mean\"]\n",
    "    seq_real = np.stack([pitch, step, duration, velocity], axis=1)\n",
    "    # Reutilizar la can√≥nica\n",
    "    save_sequence_to_midi(seq_real, output_path=output_path, instrument_name=instrument_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasar de MIDI a WAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_midi_to_wav(midi_path: str, wav_path: str, sf2_path: str, samplerate: int = 44100):\n",
    "    fs = pyfluidsynth.Synth(samplerate=samplerate)  # <--- usa el alias importado\n",
    "    sfid = fs.sfload(sf2_path)\n",
    "    try:\n",
    "        pm = pretty_midi.PrettyMIDI(midi_path)\n",
    "        audio = pm.fluidsynth(fs=samplerate, synthesizer=fs, sfid=sfid, normalize=True)  # normaliza p/evitar clipping\n",
    "\n",
    "        # Convertir a PCM_16 (compatible con Reproductor de Windows)\n",
    "        peak = float(np.max(np.abs(audio))) if audio.size else 1.0\n",
    "        if peak == 0: peak = 1.0\n",
    "        audio = (audio / peak) * 0.99\n",
    "        audio_int16 = (np.clip(audio, -1, 1) * 32767).astype(np.int16)\n",
    "\n",
    "        write(wav_path, samplerate, audio_int16)\n",
    "    finally:\n",
    "        fs.delete()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDtYzja2g0S3"
   },
   "source": [
    "#  Dataset pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4KJLzr0Xg0CI"
   },
   "outputs": [],
   "source": [
    "class MusicWindowsDataset(Dataset):\n",
    "    def __init__(self, Xp, Xc, yp, yc):\n",
    "        self.Xp = Xp\n",
    "        self.Xc = Xc\n",
    "        self.yp = yp\n",
    "        self.yc = yc\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Xp)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        import torch\n",
    "        Xp = torch.as_tensor(self.Xp[i], dtype=torch.long)        # [L]\n",
    "        Xc = torch.as_tensor(self.Xc[i], dtype=torch.float32)     # [L,3]\n",
    "        yp = torch.as_tensor(self.yp[i], dtype=torch.long)        # []\n",
    "        yc = torch.as_tensor(self.yc[i], dtype=torch.float32)     # [3]\n",
    "        return (Xp, Xc), (yp, yc)  # <<< clave: 2-tuplas anidadas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No5bj9H_gUW7"
   },
   "source": [
    "# Test modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1x6IR8wfQj8"
   },
   "outputs": [],
   "source": [
    "class MusicLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=64, cont_dim=3, hidden_size=256, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=None)\n",
    "        self.input_dim = emb_dim + cont_dim\n",
    "        self.lstm = nn.LSTM(self.input_dim, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.pitch_out = nn.Linear(hidden_size, vocab_size)  # clasificaci√≥n pitch\n",
    "        self.cont_out = nn.Linear(hidden_size, cont_dim)     # regresi√≥n step,duration,velocity\n",
    "\n",
    "    def forward(self, pitch_seq, cont_seq):\n",
    "        \"\"\"\n",
    "        pitch_seq: LongTensor (B, seq_len)\n",
    "        cont_seq: FloatTensor (B, seq_len, cont_dim)\n",
    "        returns:\n",
    "            pitch_logits: (B, vocab_size)\n",
    "            cont_pred: (B, cont_dim)\n",
    "        \"\"\"\n",
    "        emb = self.emb(pitch_seq)                # (B, seq_len, emb_dim)\n",
    "        x = torch.cat([emb, cont_seq], dim=-1)   # (B, seq_len, emb+cont)\n",
    "        out, (h, c) = self.lstm(x)               # out: (B, seq_len, hidden)\n",
    "        last = out[:, -1, :]                     # (B, hidden)\n",
    "        pitch_logits = self.pitch_out(last)      # (B, vocab_size)\n",
    "        cont_pred = self.cont_out(last)          # (B, cont_dim)\n",
    "        return pitch_logits, cont_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qN3alkGGgWhe"
   },
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stopping basado en una m√©trica escalar (modo 'min').\n",
    "    Guarda el mejor valor observado y cuenta √©pocas sin mejora.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=6, min_delta=0.0):\n",
    "        self.patience = int(patience)\n",
    "        self.min_delta = float(min_delta)\n",
    "        self.best = None\n",
    "        self.bad_epochs = 0\n",
    "\n",
    "    def step(self, value: float) -> bool:\n",
    "        \"\"\"\n",
    "        Devuelve True si hubo mejora y debe guardarse checkpoint.\n",
    "        \"\"\"\n",
    "        if self.best is None or (value < self.best - self.min_delta):\n",
    "            self.best = float(value)\n",
    "            self.bad_epochs = 0\n",
    "            return True\n",
    "        else:\n",
    "            self.bad_epochs += 1\n",
    "            return False\n",
    "\n",
    "    def should_stop(self) -> bool:\n",
    "        return self.bad_epochs >= self.patience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-ekixiAfR_B"
   },
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          train_loader,\n",
    "          val_loader,\n",
    "          device,\n",
    "          epochs=40,\n",
    "          lr=5e-4,\n",
    "          cont_loss_weight=50.0,\n",
    "          # üîπ par√°metros de early stopping\n",
    "          es_patience=6,\n",
    "          es_min_delta=0.0,\n",
    "          best_ckpt_path=\"OUTPUT/best_music_lstm.pth\",\n",
    "          verbose=True):\n",
    "    import torch\n",
    "    import torch.nn.functional as F\n",
    "    from torch.optim import AdamW\n",
    "\n",
    "    model.to(device)\n",
    "    opt = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_CE\": [],\n",
    "        \"val_MSE\": [],\n",
    "        \"val_total\": [],\n",
    "        \"best_epoch\": None,\n",
    "        \"best_val_total\": None,\n",
    "        \"best_ckpt_path\": best_ckpt_path,\n",
    "    }\n",
    "\n",
    "    # üîπ inicializa EarlyStopping\n",
    "    es = EarlyStopping(patience=es_patience, min_delta=es_min_delta)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ---- TRAIN ----\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        for (Xp, Xc), (yp, yc) in train_loader:\n",
    "            Xp = Xp.to(device)           # long [B, L]\n",
    "            Xc = Xc.to(device)           # float [B, L, 3]\n",
    "            yp = yp.to(device)           # long [B]\n",
    "            yc = yc.to(device)           # float [B, 3]\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits, cont_pred = model(Xp, Xc)         # logits [B,L,V]; cont_pred [B,L,3]\n",
    "            # ‚úÖ usa directamente la salida del modelo\n",
    "            logits_last = logits               # (B, V)\n",
    "            cont_last   = cont_pred            # (B, 3)\n",
    "\n",
    "            ce  = F.cross_entropy(logits_last, yp)    # CE para pitch\n",
    "            mse = F.mse_loss(cont_last, yc)           # MSE para continuos (normalizados)\n",
    "            loss = ce + cont_loss_weight * mse\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "\n",
    "            running += loss.item()\n",
    "\n",
    "        train_loss = running / max(1, len(train_loader))\n",
    "\n",
    "        # ---- VALID ----\n",
    "        model.eval()\n",
    "        val_ce = 0.0\n",
    "        val_mse = 0.0\n",
    "        with torch.no_grad():\n",
    "            for (Xp, Xc), (yp, yc) in val_loader:\n",
    "                Xp = Xp.to(device)\n",
    "                Xc = Xc.to(device)\n",
    "                yp = yp.to(device)\n",
    "                yc = yc.to(device)\n",
    "\n",
    "                logits, cont_pred = model(Xp, Xc)\n",
    "                logits_last = logits          # (B, V)\n",
    "                cont_last   = cont_pred       # (B, 3)\n",
    "\n",
    "                ce  = F.cross_entropy(logits_last, yp)\n",
    "                mse = F.mse_loss(cont_last, yc)\n",
    "                val_ce  += ce.item()\n",
    "                val_mse += mse.item()\n",
    "\n",
    "        val_ce  /= max(1, len(val_loader))\n",
    "        val_mse /= max(1, len(val_loader))\n",
    "        # üîπ m√©trica de parada coherente con tu loss de entrenamiento\n",
    "        val_total = val_ce + cont_loss_weight * val_mse\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_CE\"].append(val_ce)\n",
    "        history[\"val_MSE\"].append(val_mse)\n",
    "        history[\"val_total\"].append(val_total)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch} | train_loss={train_loss:.4f} | \"\n",
    "                  f\"val_CE={val_ce:.4f} | val_MSE={val_mse:.5f} | \"\n",
    "                  f\"val_total={val_total:.4f}\")\n",
    "\n",
    "        # üîπ checkpoint si mejora\n",
    "        if es.step(val_total):\n",
    "            torch.save({\"model_state\": model.state_dict()}, best_ckpt_path)\n",
    "            history[\"best_epoch\"] = epoch\n",
    "            history[\"best_val_total\"] = val_total\n",
    "            if verbose:\n",
    "                print(f\"  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en {best_ckpt_path}\")\n",
    "\n",
    "        # üîπ parar si no mejora por 'patience'\n",
    "        if es.should_stop():\n",
    "            if verbose:\n",
    "                print(f\"  ‚Ü≥ Early stopping en epoch {epoch} (best_epoch={history['best_epoch']})\")\n",
    "            break\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImKXlCTVgYa5"
   },
   "source": [
    "# Generacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ufTV-9JfX4E"
   },
   "outputs": [],
   "source": [
    "#sample_from_logits\n",
    "def sample_from_logits_topk(logits, k=10, temperature=1.0):\n",
    "    \"\"\"\n",
    "    logits: torch.Tensor [vocab] o numpy.ndarray [vocab]\n",
    "    Devuelve: √≠ndice entero muestreado en top-k (con temperatura).\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    if not isinstance(logits, torch.Tensor):\n",
    "        logits = torch.from_numpy(logits)\n",
    "\n",
    "    # Evita k inv√°lido\n",
    "    vocab = logits.shape[-1]\n",
    "    k = max(1, min(int(k), int(vocab)))\n",
    "\n",
    "    # √öltimo paso de la secuencia si viene con eje extra\n",
    "    # (p.ej., [1, V] -> [V])\n",
    "    if logits.ndim > 1:\n",
    "        logits = logits.view(-1)\n",
    "\n",
    "    # Temperatura\n",
    "    if temperature is None or temperature <= 0:\n",
    "        temperature = 1.0\n",
    "    logits = logits / float(temperature)\n",
    "\n",
    "    # Top-k + muestreo\n",
    "    topk_vals, topk_idx = torch.topk(logits, k)            # [k]\n",
    "    topk_probs = torch.softmax(topk_vals, dim=-1)           # [k]\n",
    "    choice = torch.multinomial(topk_probs, 1)               # [1]\n",
    "    return int(topk_idx[choice].item())\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_sequence(model, device,\n",
    "                      seed_pitch_seq,   # list[int] o np.ndarray shape [T]\n",
    "                      seed_cont_seq,    # np.ndarray shape [T, 3]\n",
    "                      steps=200,\n",
    "                      idx2pitch=None,\n",
    "                      stats=None,\n",
    "                      temperature=1.0,\n",
    "                      top_k=10,\n",
    "                      max_context=32):\n",
    "    \"\"\"\n",
    "    Devuelve: np.ndarray shape [T_gen, 4] con columnas [pitch, step, dur, vel]\n",
    "              (en tu mismo formato downstream).\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import torch\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # --- Normalizaci√≥n defensiva de entradas ---\n",
    "    seed_pitch_seq = np.asarray(seed_pitch_seq, dtype=np.int64)          # [T]\n",
    "    seed_cont_seq  = np.asarray(seed_cont_seq,  dtype=np.float32)        # [T,3]\n",
    "    assert seed_cont_seq.ndim == 2 and seed_cont_seq.shape[1] == 3, \"seed_cont_seq debe ser [T,3]\"\n",
    "\n",
    "    # Construir tensores en el dispositivo sin listas de ndarrays:\n",
    "    def _mk_inputs(pitches_np, cont_np):\n",
    "        # recorta al contexto\n",
    "        pitches_np = pitches_np[-max_context:]\n",
    "        cont_np    = cont_np[-max_context:]\n",
    "        inp_pitch = torch.as_tensor(pitches_np, dtype=torch.long, device=device).unsqueeze(0)   # [1, L]\n",
    "        inp_cont  = torch.as_tensor(cont_np,    dtype=torch.float32, device=device).unsqueeze(0) # [1, L, 3]\n",
    "        return inp_pitch, inp_cont\n",
    "\n",
    "    # Copias de trabajo (para ir anexando)\n",
    "    cur_pitch = seed_pitch_seq.copy()\n",
    "    cur_cont  = seed_cont_seq.copy()\n",
    "\n",
    "    generated_rows = []  # acumularemos filas [pitch, step, dur, vel] (desnormalizadas al final si aplica)\n",
    "\n",
    "    for _ in range(steps):\n",
    "        inp_pitch, inp_cont = _mk_inputs(cur_pitch, cur_cont)\n",
    "        logits, cont_pred = model(inp_pitch, inp_cont)   # logits: [1,L,V]; cont_pred: [1,L,3] (normalizado)\n",
    "\n",
    "        # Tomar el √∫ltimo paso temporal\n",
    "        logits_last = logits.squeeze(0)                  # (V,)  torch.Tensor\n",
    "        cont_last   = cont_pred.squeeze(0).cpu().numpy() # (3,)  np.float32 (normalizado)\n",
    "\n",
    "        # Muestreo discreto\n",
    "        next_pitch_idx = sample_from_logits_topk(logits_last, k=top_k, temperature=temperature)\n",
    "\n",
    "        # ---- Desnormalizar los 3 continuos (si diste 'stats') ----\n",
    "        if stats is not None:\n",
    "            step = (cont_last[0] * (float(stats[\"step_std\"]) + 1e-6)) + float(stats[\"step_mean\"])\n",
    "            dur  = (cont_last[1] * (float(stats[\"dur_std\"])  + 1e-6)) + float(stats[\"dur_mean\"])\n",
    "            vel  = (cont_last[2] * (float(stats[\"vel_std\"])  + 1e-6)) + float(stats[\"vel_mean\"])\n",
    "        else:\n",
    "            step, dur, vel = float(cont_last[0]), float(cont_last[1]), float(cont_last[2])\n",
    "\n",
    "        # Seguridad: valores v√°lidos\n",
    "        next_pitch = int(np.clip(next_pitch_idx, 0, 127))\n",
    "        step = max(0.0, float(step))\n",
    "        dur  = max(1e-3, float(dur))\n",
    "        vel  = float(np.clip(vel, 1.0, 127.0))\n",
    "\n",
    "        # Append a las listas de estado (en formato NORMALIZADO para el modelo)\n",
    "        # Nota: para la siguiente iteraci√≥n el modelo necesita los continuos NORMALIZADOS,\n",
    "        # por lo que guardamos adem√°s la versi√≥n normalizada:\n",
    "        if stats is not None:\n",
    "            step_n = (step - float(stats[\"step_mean\"])) / (float(stats[\"step_std\"]) + 1e-6)\n",
    "            dur_n  = (dur  - float(stats[\"dur_mean\"]))  / (float(stats[\"dur_std\"])  + 1e-6)\n",
    "            vel_n  = (vel  - float(stats[\"vel_mean\"]))  / (float(stats[\"vel_std\"])  + 1e-6)\n",
    "            cur_cont = np.vstack([cur_cont, [step_n, dur_n, vel_n]]).astype(np.float32)\n",
    "        else:\n",
    "            cur_cont = np.vstack([cur_cont, [step, dur, vel]]).astype(np.float32)\n",
    "\n",
    "        cur_pitch = np.append(cur_pitch, next_pitch).astype(np.int64)\n",
    "\n",
    "        # Guardar fila desnormalizada para el MIDI\n",
    "        generated_rows.append([next_pitch, step, dur, vel])\n",
    "\n",
    "    return np.asarray(generated_rows, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5fFn6iYgaUw"
   },
   "source": [
    "# Pipeline completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZSwCOwbfiQ4",
    "outputId": "6a88845d-4c25-4ac3-812e-601f5c7fed42"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"1) Extrayendo secuencias crudas...\")\n",
    "    raw_sequences = extract_raw_note_sequences(ROOT_DIR, instrument_name= INSTRUMENT_NAME, composer_name=COMPOSER)\n",
    "    print(f\"  secuencias extra√≠das: {len(raw_sequences)}\")\n",
    "\n",
    "    train_sequences, val_sequences = train_test_split(raw_sequences, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "    print(\"2) Estandarizando (pitch se mantiene intacto)...\")\n",
    "    standardized_sequences, stats = standardize_note_sequences(train_sequences)\n",
    "    print(\"  stats:\", stats)\n",
    "\n",
    "\n",
    "\n",
    "    def apply_standardization(seqs, stats):\n",
    "        out = []\n",
    "        for seq in seqs:\n",
    "            s = seq.copy()\n",
    "            s[:,1] = (s[:,1]-stats[\"step_mean\"])/(stats[\"step_std\"]+1e-6)\n",
    "            s[:,2] = (s[:,2]-stats[\"dur_mean\"] )/(stats[\"dur_std\"] +1e-6)\n",
    "            s[:,3] = (s[:,3]-stats[\"vel_mean\"] )/(stats[\"vel_std\"] +1e-6)\n",
    "            out.append(s)\n",
    "        return out\n",
    "\n",
    "    val_standardized = apply_standardization(val_sequences, stats)\n",
    "    print(\"3) Creando ventanas...\")\n",
    "    (Xp_tr, Xc_tr), (yp_tr, yc_tr) = create_windows(standardized_sequences, seq_len=SEQ_LEN)\n",
    "    (Xp_va, Xc_va), (yp_va, yc_va) = create_windows(val_standardized,       seq_len=SEQ_LEN)\n",
    "\n",
    "    print(\"  Train -> Xp_tr:\", Xp_tr.shape, \"Xc_tr:\", Xc_tr.shape, \"yp_tr:\", yp_tr.shape)\n",
    "    print(\"  Valid -> Xp_va:\", Xp_va.shape, \"Xc_va:\", Xc_va.shape, \"yp_va:\", yp_va.shape)\n",
    "\n",
    "\n",
    "    # construir vocab (opcional\n",
    "    if Xp_tr.shape[0] == 0:\n",
    "        raise RuntimeError(\"No hay muestras. Aumenta datos o reduce SEQ_LEN.\")\n",
    "    max_pitch = int(np.max(Xp_tr))\n",
    "    vocab_size = max(128, max_pitch + 1)\n",
    "    print(\"vocab_size:\", vocab_size)\n",
    "\n",
    "    # dataset\n",
    "    train_ds = MusicWindowsDataset(Xp_tr, Xc_tr, yp_tr, yc_tr)\n",
    "    val_ds   = MusicWindowsDataset(Xp_va,   Xc_va,   yp_va,   yc_va)\n",
    "    loader   = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "    vloader  = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "    # modelo\n",
    "    model = MusicLSTM(vocab_size=vocab_size, emb_dim=64, cont_dim=3, hidden_size= HIDDEN_SIZE, num_layers= NUM_LAYERS,dropout=DROPOUT) # Ajustado num_layers\n",
    "    print(\"Training model on device:\", DEVICE)\n",
    "    history = train(\n",
    "        model,\n",
    "        train_loader=loader,\n",
    "        val_loader=vloader,\n",
    "        device=DEVICE,\n",
    "        epochs=EPOCHS,\n",
    "        lr=LR,\n",
    "        cont_loss_weight= PESO_LOSS_CONT,\n",
    "        es_patience=6,                 # ajusta si quieres m√°s/menos paciencia\n",
    "        es_min_delta=1e-4,             # mejora m√≠nima para considerar \"mejora\"\n",
    "        best_ckpt_path=(OUTPUT_DIR / \"best_music_lstm.pth\").as_posix(),\n",
    "    )\n",
    "\n",
    "    # guardar modelo y stats\n",
    "    # Cargar mejor estado antes de generar\n",
    "    best_ckpt = torch.load((OUTPUT_DIR / \"best_music_lstm.pth\").as_posix(), map_location=DEVICE)\n",
    "    model.load_state_dict(best_ckpt[\"model_state\"])\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    # ------------------ Generaci√≥n de ejemplos ------------------\n",
    " \n",
    "    total_samples = Xp_tr.shape[0]\n",
    "   \n",
    "    # Elegimos √≠ndices de semillas distintos si hay suficientes, o con reposici√≥n si no\n",
    "    idx_pool = list(range(total_samples))\n",
    "    if total_samples >= NUM_SEQS:\n",
    "        seed_indices = random.sample(idx_pool, NUM_SEQS)  # sin reemplazo\n",
    "    else:\n",
    "        seed_indices = [random.choice(idx_pool) for _ in range(NUM_SEQS)]  # con reemplazo\n",
    "    \n",
    "    for j, idx in enumerate(seed_indices, start=1):\n",
    "        seed_pitch = Xp_tr[idx].tolist()\n",
    "        seed_cont  = Xc_tr[idx]\n",
    "        print(f\"[Gen {j}] Usando semilla index: {idx}\")\n",
    "    \n",
    "        generated = generate_sequence(\n",
    "            model, DEVICE,\n",
    "            seed_pitch, seed_cont,\n",
    "            steps=STEPS_PER_SEQ,\n",
    "            idx2pitch=None,\n",
    "            stats=stats,\n",
    "            temperature=TEMPERATURE,\n",
    "            top_k=TOP_K   # prueba k=10; ajusta a 5‚Äì20 seg√∫n diversidad deseada\n",
    "        )\n",
    "        if generated.shape[0] > 200:\n",
    "          generated = generated[-200:, :]\n",
    "    \n",
    "        midi_path = OUTPUT_DIR / f\"generated_music_lstm_{j}.mid\"\n",
    "        wav_path = OUTPUT_DIR / f\"generated_music_lstm_{j}.wav\"\n",
    "        # Si tu save_sequence_to_midi acepta instrument_name:\n",
    "        save_sequence_to_midi(generated, output_path=midi_path.as_posix(), instrument_name=INSTRUMENT_NAME)\n",
    "        \n",
    "        try:\n",
    "            render_midi_to_wav(midi_path.as_posix(), wav_path.as_posix(), SF2, samplerate=44100)\n",
    "            print(f\"[Gen {j}] WAV guardado en:  {wav_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Gen {j}] ‚ö†Ô∏è No se pudo generar WAV (revisa pyfluidsynth/DLL/SF2): {e}\")\n",
    "        \n",
    "        print(f\"[Gen {j}] MIDI guardado en: {midi_path}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "iJrvj5YdhVoo",
    "C04D1njqhYFn",
    "w1n9XyNyhcej",
    "GtygejbZhgP-",
    "vH4IXLREhjSW"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "python_312_CUDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
