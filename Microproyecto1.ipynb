{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b672c30",
   "metadata": {},
   "source": [
    "![Universidad_de_los_Andes_30.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0b1b4a",
   "metadata": {},
   "source": [
    "***\n",
    "# **Microproyecto 1**\n",
    "\n",
    "## Descripci√≥n del problema:\n",
    "\n",
    "El problema a resolver consiste en generar nuevas secuencias de notas musicales basadas en el estilo de los artistas existentes, mencionados en la r√∫brica del taller haciendo uso de archivos .mid como fuente de datos esto con el fin de entrenar un modelo que sea capaz de aprender de las diferentes caracter√≠sticas y posteriormente producir nuevas composiciones donde mantenga coherencia musical.\n",
    "\n",
    "## Objetivo:\n",
    "\n",
    "Con esta actividad se busca que el estudiante pueda poner en pr√°ctica el uso de modelos de redes neuronales para trabajar con datos secuenciales. Tras realizar esta actividad se espera que el estudiante est√© en capacidad de:\n",
    "1. Estructurar datos secuenciales de forma que pueden ser usados por modelos de redes neuronales.\n",
    "2. Desarrollar soluciones de machine learning para datos secuenciales en distintos dominios.\n",
    "3. Entrenar modelos de machine learning con m√∫ltiples salidas.\n",
    "4. Entrenar modelos de machine learning con una funci√≥n de costo compuesta.\n",
    "5. Utilizar el modelo entrenado para generar nuevas secuencias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727c2e24",
   "metadata": {},
   "source": [
    "***\n",
    "## Integrantes Equipo 20\n",
    "- Andr√©s Felipe √ëungo Fern√°ndez\n",
    "- Andr√©s Juli√°n Gonzalez Barrera\n",
    "- Hernando Jose Jimenez D√≠az\n",
    "- Gloria In√©s L√≥pez Urbano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5fded7",
   "metadata": {},
   "source": [
    "***\n",
    "# √çndice\n",
    "\n",
    "El *notebook* aborda el microproyecto con la siguiente estructura:\n",
    "\n",
    "| üîπ | Secci√≥n        |\n",
    "|----|----------------|\n",
    "| 1Ô∏è.   | **Instalaci√≥n e importe de librer√≠as** |\n",
    "| 1Ô∏è.1Ô∏è  | Importar librer√≠as |\n",
    "| 1Ô∏è.2Ô∏è. | Definici√≥n variables globales y funciones auxiliares|\n",
    "| 1Ô∏è.3Ô∏è. | Definici√≥n de semillas |\n",
    "| 2Ô∏è.   | **Carga y procesamiento de los datos**  |\n",
    "| 2Ô∏è.1Ô∏è. | Extracci√≥n caracter√≠sticas de los archivos .mid  |\n",
    "| 2Ô∏è.2Ô∏è. | Estandarizar variables cuantitativas  |\n",
    "| 2Ô∏è.3Ô∏è. | Generar secuencias de entrenamiento _requeridas para LSTM_  |\n",
    "| 2Ô∏è.4Ô∏è. | Funci√≥n Guardar secuencias a MIDI  |\n",
    "| 3Ô∏è. | **Desarrollo del modelo** |\n",
    "| 3Ô∏è.1Ô∏è. | Dataset PyTorch  |\n",
    "| 3Ô∏è.2Ô∏è. | Definici√≥n del modelo   |\n",
    "| 4Ô∏è. | **Etapa Entrenamiento**   |\n",
    "| 4Ô∏è.1Ô∏è. | Funciones para entrenar   |\n",
    "| 4Ô∏è.2Ô∏è. | Funciones para generar las nuevas notas musicales   |\n",
    "| 5Ô∏è. | **Definici√≥n de _main_**  |\n",
    "| 6Ô∏è. | **Conversi√≥n archivos .mid a .wav**   |\n",
    "| 7Ô∏è. | **An√°lisis de resultados y discusi√≥n**   |\n",
    "| 8. | **Conclusi√≥n**   |\n",
    "| 9. | **Referencias**   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16f7b63",
   "metadata": {},
   "source": [
    "# 1. Instalaci√≥n e importe de librer√≠as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7deab13",
   "metadata": {},
   "source": [
    "Versi√≥n usada de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4453010d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.13.5\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc59e49",
   "metadata": {},
   "source": [
    "Para la ejecuci√≥n de este Notebook, se recomienda realizar instalaci√≥n de las librer√≠as mencionadas a continuaci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c44f70ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch\n",
    "#!pip install pretty_midi\n",
    "#!pip install mido\n",
    "#!pip install pyFluidSynth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c8813b",
   "metadata": {},
   "source": [
    "## 1.1 Importar librer√≠as\n",
    "\n",
    "Diferente a las libras utilizadas a lo largo de la maestr√≠a, se destaca la importaci√≥n de la librer√≠a **`psfluidsynth`** la cual nos va a permitir m√°s adelante junto con el uso de lo que se conoce como *soundfont*, transformar los archivos desde el formato *.mid* a *.wav*. Para m√°s informaci√≥n por favor revisar la bibliograf√≠a relacionada en este documento [¬π]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19a8b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaci√≥n de librer√≠as del sistema\n",
    "import sys, glob, os, time\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "from importlib.metadata import version\n",
    "\n",
    "# Gesti√≥n de archivos\n",
    "from scipy.io.wavfile import write\n",
    "from pathlib import Path\n",
    "\n",
    "# Importaci√≥n de librer√≠a de DL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Dataloader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Separaci√≥n de datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Librer√≠as para MIDI y audio\n",
    "import fluidsynth as pyfluidsynth\n",
    "import pretty_midi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d4e25e-d44c-4e73-afec-f41fb758348e",
   "metadata": {},
   "source": [
    "Se verifica versionamiento de las librer√≠as para que pueda ser m√°s f√°cil replicar este *notebook* m√°s adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55019f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy :  1.26.4\n",
      "pandas :  2.3.2\n",
      "scikit-learn :  1.7.2\n",
      "matplotlib :  3.10.6\n",
      "joblib :  1.5.1\n",
      "torch :  2.10.0.dev20251012+cu130\n",
      "tqdm :  4.67.1\n",
      "pretty_midi :  0.2.11\n"
     ]
    }
   ],
   "source": [
    "# Ignorar las warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Versiones utilizadas\n",
    "librerias = [\"numpy\",\n",
    "            \"pandas\",\n",
    "            \"scikit-learn\",\n",
    "            \"matplotlib\",\n",
    "            \"joblib\",\n",
    "            \"torch\",\n",
    "            \"tqdm\",\n",
    "            \"pretty_midi\"]\n",
    "for library in librerias:\n",
    "  print(library, \": \", version(library))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d50cab2",
   "metadata": {},
   "source": [
    "## 1.2 Definici√≥n variables globales y funciones auxiliares\n",
    "En esta secci√≥n se definen los par√°metros clave utilizados m√°s adelante para el desarrollo de *notebook*. Empezando por las carpetas de insumos y de salidas, las rutas de los *soundfont* que m√°s adelante permitir√°n la conversi√≥n a *.wav*. Los par√°metros de entrenamiento donde se destaca **`SEQ_LEN`**, el tama√±o de las ventanas de contexto, **`BATCH_SIZE`** el tama√±o de los sub-conjuntos de entrenamiento, **`PESO_LOSS_CONT`** que m√°s adelante va a jugar un papel fundamental en el c√°lculo de la p√©rdida total, la cual est√° compuesta por una funci√≥n de p√©rdida tipo **`MSE`** y otra tipo **`CROSS ENTROPY`**. \n",
    "\n",
    "Tambi√©n m√°s adelante, se definen par√°metros clave dentro de la arquitectura de la red neuronal utilizada, pero en la que ahondaremos m√°s adelante. \n",
    "\n",
    "Este notebook en particular va a permitir, definir qu√© instrumento tomar para el entrenamiento y qu√© compositor elegir. En este caso se eligen los par√°metros **`Acoustic Grand Piano`** y **`schubert`** de manera conveniente ya que esta elecci√≥n permite obtener la mayor cantidad de notas para entrenar el modelo.\n",
    "\n",
    "Cerramos esta secci√≥n con los par√°metros que nos van a permitir generar las secuencias m√∫sicales. No hay mucho m√°s que decir aqu√≠ adem√°s de que se usa la t√©cnica de temperatura y una variaci√≥n del \"top K\" aprendido en clase la cu√°l **no** se basa en percentiles de manera expl√≠cita, sino que el \"K\" refiere a la toma de cualquiera de las mejores K notas obtenidas para cada predicci√≥n [¬≤]. Consideramos que al ser el rango de la predicci√≥n l√≠mite (discreto de 0 a 127 para los formato *.mid*) esta puede ser la palanca m√°s correcta para poder \"calibrar\" el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa73c55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Soundfont encontrado: ./soundfonts/FluidR3_GM.sf2\n"
     ]
    }
   ],
   "source": [
    "#Rutas\n",
    "ROOT_DIR =  \"./Dataset/music_artist\"\n",
    "OUTPUT_DIR = Path(\"./OUTPUT\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Buscar soundfont disponible (multiplataforma)\n",
    "def find_soundfont():\n",
    "   \n",
    "    # Posibles ubicaciones de soundfonts\n",
    "    possible_soundfonts = [\"./soundfonts/FluidR3_GM.sf2\",  \n",
    "        \"/opt/homebrew/share/soundfonts/default.sf2\", \n",
    "        \"/opt/homebrew/share/soundfonts/FluidR3_GM.sf2\",\n",
    "        \"/usr/local/share/soundfonts/default.sf2\", \n",
    "        \"/usr/local/share/soundfonts/FluidR3_GM.sf2\",\n",
    "        \"/usr/share/soundfonts/default.sf2\", \n",
    "        \"/usr/share/soundfonts/FluidR3_GM.sf2\",\n",
    "        \"/usr/share/sounds/sf2/FluidR3_GM.sf2\",\n",
    "        \"/usr/share/sounds/sf2/default.sf2\"]\n",
    "    \n",
    "    for sf2_path in possible_soundfonts:\n",
    "        if os.path.exists(sf2_path):\n",
    "            print(f\"‚úì Soundfont encontrado: {sf2_path}\")\n",
    "            return sf2_path\n",
    "    \n",
    "    # Si no se encuentra ninguno, dar instrucciones\n",
    "    print(\" No se encontr√≥ ning√∫n archivo soundfont (.sf2)\")\n",
    "    print(\"\\nInstrucciones para obtener un soundfont:\")\n",
    "    if sys.platform == \"darwin\":  # macOS\n",
    "        print(\"  1. Descarga FluidR3_GM.sf2 desde: https://member.keymusician.com/Member/FluidR3_GM/FluidR3_GM.sf2\")\n",
    "        print(\"  2. Gu√°rdar en: ./soundfonts/FluidR3_GM.sf2\")\n",
    "    elif sys.platform.startswith(\"linux\"):  # Linux\n",
    "        print(\"  Ubuntu/Debian: sudo apt-get install fluid-soundfont-gm\")\n",
    "        print(\"  O descarga desde: https://member.keymusician.com/Member/FluidR3_GM/FluidR3_GM.sf2\")\n",
    "    else:  # Windows\n",
    "        print(\"  Descarga desde: https://member.keymusician.com/Member/FluidR3_GM/FluidR3_GM.sf2\")\n",
    "        print(\"  Gu√°rdar en: .\\\\soundfonts\\\\FluidR3_GM.sf2\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "SF2 = find_soundfont()\n",
    "\n",
    "# Par√°metros de lotes de entrenamiento\n",
    "SEQ_LEN = 32 # Block size\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 40\n",
    "LR = 5e-4\n",
    "PESO_LOSS_CONT = 20\n",
    "PATIENCE = 8\n",
    "MIN_DELTA = 1e-3\n",
    "\n",
    "# P√°rametros redes\n",
    "HIDDEN_SIZE = 320\n",
    "NUM_LAYERS = 3\n",
    "DROPOUT = 0.35\n",
    "EMB_DIM = 96\n",
    "\n",
    "# Elecciones usuario\n",
    "MODEL_TYPE = \"LSTM\"  \n",
    "INSTRUMENT_NAME = \"Acoustic Grand Piano\"\n",
    "COMPOSER = \"schubert\"  # este es el artista que tiene m√°s datos\n",
    "\n",
    "# Par√°metros de generaci√≥n de secuencias\n",
    "NUM_SEQS       = 3  # N√∫mero de secuencias a generar\n",
    "STEPS_PER_SEQ  = 200  # Notas que debe tener cada secuencia\n",
    "TEMPERATURE    = 0.65  # Temperatura\n",
    "TOP_K = 20  # Metodolog√≠a para delimitar el dominio de notas a elegir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c87fd776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta funci√≥n permite informar cu√°nto tiempo tarda en correr cada modelo. Prop√≥sito: solo informativo para referencia al momento de ejecutar el Notebook.\n",
    "def print_time_execution(inicio, fin):\n",
    "    str_log = \"\"\n",
    "    duracion = fin - inicio\n",
    "    if duracion > 60:\n",
    "        minutos = duracion // 60\n",
    "        segundos = duracion % 60\n",
    "        str_log = f\"Tiempo: {minutos:.0f} minutos y {segundos:.2f} segundos\"\n",
    "    else:\n",
    "        str_log = f\"Tiempo: {duracion:.2f} segundos\"\n",
    "    print(str_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744cf26d",
   "metadata": {},
   "source": [
    "## 1.3 Definici√≥n de semillas\n",
    "\n",
    "Aseguramos reproducibilidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e212aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semilla pseudo-aleatoria usada\n",
    "RANDOM_STATE = 13\n",
    "random.seed(RANDOM_STATE); np.random.seed(RANDOM_STATE); torch.manual_seed(RANDOM_STATE)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(RANDOM_STATE)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c7c52f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì GPU disponible: NVIDIA GeForce RTX 5070\n",
      "  - Memoria total: 12.82 GB\n",
      "  - CUDA version: 13.0\n",
      "  - Dispositivo seleccionado: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detecci√≥n y validaci√≥n del dispositivo\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(f\"‚úì GPU disponible: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  - Memoria total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"  - CUDA version: {torch.version.cuda}\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\" GPU no disponible, usando CPU\")\n",
    "    print(\" - Nota: El entrenamiento ser√° m√°s lento en CPU\")\n",
    "\n",
    "print(f\"  - Dispositivo seleccionado: {DEVICE}\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aee225b",
   "metadata": {},
   "source": [
    "# 2. Carga y procesamiento de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a118b4b",
   "metadata": {},
   "source": [
    "## 2.1. Extracci√≥n caracter√≠sticas de los archivos .mid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a8a0e7",
   "metadata": {},
   "source": [
    "En esta secci√≥n se realiza la selecci√≥n del primer instrumento encontrado y extracci√≥n notas del instrumento seleccionado. Como resultado se extraen las siguientes caracter√≠sticas por cada nota le√≠da:   \n",
    "- *Pitch*: representa la nota musical.\n",
    "- *Step*: es el espacio de tiempo que hay entre la nota anterior y la nota actual.\n",
    "- *Duration*: Es la diferencia de tiempo en el que termina la nota actual (end) menos el inicio de la nota (start).\n",
    "- *Velocity*: es la velocidad de la nota musical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a72f87e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7083be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracci√≥n de notas crudas sin procesar por dataloader\n",
    "def extract_raw_note_sequences(root_dir, instrument_name=None, program_number=None, composer_name=None):\n",
    "    raw_sequences = []\n",
    "    candidates = [composer_name] if composer_name else [ d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "    for composer in candidates:\n",
    "        folder = os.path.join(root_dir, composer)\n",
    "        midi_files = glob.glob(os.path.join(folder, \"*.mid\"))\n",
    "\n",
    "        for mf in midi_files:\n",
    "            try:\n",
    "                pm = pretty_midi.PrettyMIDI(mf)\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo leer {mf}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Selecci√≥n instrumento\n",
    "            chosen_instruments = []\n",
    "            for i, inst in enumerate(pm.instruments):\n",
    "                name = pretty_midi.program_to_instrument_name(inst.program)\n",
    "                print(f\"[{i}] prog={inst.program:>2} name={name} notas={len(inst.notes)}\")\n",
    "                if instrument_name is not None:\n",
    "                    inst_name = pretty_midi.program_to_instrument_name(inst.program)\n",
    "                    if inst_name.lower() == instrument_name.lower():\n",
    "                        chosen_instruments.append(inst)\n",
    "                elif program_number is not None:\n",
    "                    if inst.program == program_number:\n",
    "                        chosen_instruments.append(inst)\n",
    "\n",
    "            # Si no hubo match expl√≠cito y no se especific√≥ filtro, tomamos el primero\n",
    "            if instrument_name is None and program_number is None:\n",
    "                chosen_instruments = pm.instruments[:1]  \n",
    "\n",
    "            if not chosen_instruments:\n",
    "                # Nada que extraer en este archivo para el instrumento pedido\n",
    "                continue\n",
    "\n",
    "            # Extraer notas SOLO del/los instrumentos elegidos \n",
    "            notes = []\n",
    "            for inst in chosen_instruments:\n",
    "                for note_mus in inst.notes:\n",
    "                    start = note_mus.start\n",
    "                    end = note_mus.end\n",
    "                    duration = end - start\n",
    "                    velocity = note_mus.velocity\n",
    "                    notes.append((start, note_mus.pitch, duration, velocity))\n",
    "\n",
    "            if not notes:\n",
    "                continue\n",
    "\n",
    "            # Ordenar por inicio y construir [pitch, step, duration, velocity]\n",
    "            notes.sort(key=lambda x: x[0])\n",
    "            note_feats = []\n",
    "            prev_start = notes[0][0]\n",
    "            for start, pitch, duration, velocity in notes:\n",
    "                step = start - prev_start\n",
    "                prev_start = start\n",
    "                note_feats.append([pitch, step, duration, velocity])\n",
    "\n",
    "            if note_feats:\n",
    "                raw_sequences.append(np.array(note_feats, dtype=np.float32))\n",
    "\n",
    "    return raw_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293f1c6c",
   "metadata": {},
   "source": [
    "## 2.2. Estandarizar variables cuantitativas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c1bd8",
   "metadata": {},
   "source": [
    "Este paso es necesario dado que los modelos de red neuronal son muy sensibles a las escalas de los datos. Al no estandarizar las variables continuas (*step*, *duration* y *velocity*), el modelo no aprender√° correctamente las relaciones entre variables.\n",
    "\n",
    "La presente estandarizaci√≥n lleva todas las variables continuas a extraer el promedio y la desviaci√≥n estandar normalizando cada valor individual, siguiendo la f√≥rmula del *Z-score*:\n",
    "**$norm_x = (x - mean) / std$**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7c36d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandariza las variables continuas (step, duration, velocity)\n",
    "def standardize_note_sequences(sequences):\n",
    "    all_steps, all_durations, all_velocities = [], [], []\n",
    "\n",
    "    # Recolectar todas las variables continuas para calcular media y std global\n",
    "    for seq in sequences:\n",
    "        all_steps.extend(seq[:, 1])\n",
    "        all_durations.extend(seq[:, 2])\n",
    "        all_velocities.extend(seq[:, 3])\n",
    "\n",
    "    # Estad√≠sticas globales\n",
    "    step_mean, step_std = np.mean(all_steps), np.std(all_steps)\n",
    "    dur_mean, dur_std = np.mean(all_durations), np.std(all_durations)\n",
    "    vel_mean, vel_std = np.mean(all_velocities), np.std(all_velocities)\n",
    "\n",
    "    standardized = []\n",
    "    for seq in sequences:\n",
    "        seq_std = seq.copy()\n",
    "        # No tocar pitch (columna 0)\n",
    "        seq_std[:, 1] = (seq[:, 1] - step_mean) / (step_std + 1e-6)\n",
    "        seq_std[:, 2] = (seq[:, 2] - dur_mean) / (dur_std + 1e-6)\n",
    "        seq_std[:, 3] = (seq[:, 3] - vel_mean) / (vel_std + 1e-6)\n",
    "        standardized.append(seq_std)\n",
    "\n",
    "    stats = {\"step_mean\": step_mean, \"step_std\": step_std,\n",
    "            \"dur_mean\": dur_mean, \"dur_std\": dur_std,\n",
    "            \"vel_mean\": vel_mean, \"vel_std\": vel_std}\n",
    "\n",
    "    return standardized, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4187d670",
   "metadata": {},
   "source": [
    "## 2.3. Generar secuencias de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9641529a",
   "metadata": {},
   "source": [
    "Esta secci√≥n realiza la conversi√≥n de una secuencia larga de notas en muestras peque√±as de longitud fija llamadas ventanas de contexto o secuencias de entrenamiento. La entrada de datos debe tener estandarizadas las variables continuas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9e3e041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea pares (X, y) con ventanas de contexto para entrenamiento a partir de las secuencias estandarizadas.\n",
    "def create_windows(sequences, seq_len=32):\n",
    "\n",
    "    X_pitch, X_cont, y_pitch, y_cont = [], [], [], []\n",
    "\n",
    "    for seq in sequences:\n",
    "        if len(seq) < seq_len + 1:\n",
    "            continue\n",
    "\n",
    "        # Dividir en ventanas\n",
    "        for i in range(len(seq) - seq_len):\n",
    "            window = seq[i:i+seq_len]\n",
    "            target = seq[i+seq_len]\n",
    "\n",
    "            # Separar pitch (entero) y las features continuas\n",
    "            X_pitch.append(window[:, 0].astype(np.int64))     # pitch\n",
    "            X_cont.append(window[:, 1:].astype(np.float32))   # step, duration, velocity\n",
    "            y_pitch.append(int(target[0]))                    # pitch de la siguiente nota\n",
    "            y_cont.append(target[1:].astype(np.float32))      # step, duration, velocity siguientes\n",
    "\n",
    "    # Convertir a arrays numpy\n",
    "    X_pitch = np.array(X_pitch, dtype=np.int64)\n",
    "    X_cont = np.array(X_cont, dtype=np.float32)\n",
    "    y_pitch = np.array(y_pitch, dtype=np.int64)\n",
    "    y_cont = np.array(y_cont, dtype=np.float32)\n",
    "\n",
    "    return (X_pitch, X_cont), (y_pitch, y_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024d29a7",
   "metadata": {},
   "source": [
    "## 2.4. Funci√≥n Guardar secuencias a MIDI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b3d7e4",
   "metadata": {},
   "source": [
    "Las funciones **`save_sequence_to_midi`** y **`save_std_sequence_to_midi`** permiten tomar las secuencias (estandarizadas o no estandarizadas) y generar de nuevo el archivo *.mid* con el fin de validar que no se hayan corrompido las notas musicales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b9bc967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado de secuencias a .mid con insumo sin estandarizar\n",
    "def save_sequence_to_midi(seq, output_path=\"generated.mid\", instrument_name=\"Acoustic Grand Piano\"):\n",
    "\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    #Obtenci√≥n del instrumento\n",
    "    try:\n",
    "        program_number = pretty_midi.instrument_name_to_program(instrument_name)\n",
    "    except ValueError:\n",
    "        program_number = 0\n",
    "    instrument = pretty_midi.Instrument(program=program_number)\n",
    "\n",
    "    # Asegurar valores v√°lidos\n",
    "    pitch    = seq[:, 0].astype(int)\n",
    "    step     = np.maximum(seq[:, 1].astype(float), 0.0)\n",
    "    duration = np.maximum(seq[:, 2].astype(float), 0.01)\n",
    "    velocity = np.clip(seq[:, 3].astype(float), 0, 127).astype(int)\n",
    "\n",
    "    # Reconstruir tiempos absolutos\n",
    "    t = 0.0\n",
    "    for p, s, d, v in zip(pitch, step, duration, velocity):\n",
    "        t += s\n",
    "        note = pretty_midi.Note(velocity=int(v), pitch=int(p), start=float(t), end=float(t + d))\n",
    "        instrument.notes.append(note)\n",
    "\n",
    "    pm.instruments.append(instrument)\n",
    "    pm.write(output_path)\n",
    "    print(f\"MIDI guardado en: {output_path} ({instrument_name})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d62040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado de secuencias a .mid con insumo estandarizado\n",
    "def save_std_sequence_to_midi(seq_std, stats, output_path=\"reconstructed.mid\", instrument_name=\"Acoustic Grand Piano\"):\n",
    "\n",
    "    # Desestandarizar\n",
    "    pitch    = seq_std[:, 0]\n",
    "    step     = seq_std[:, 1] * stats[\"step_std\"] + stats[\"step_mean\"]\n",
    "    duration = seq_std[:, 2] * stats[\"dur_std\"] + stats[\"dur_mean\"]\n",
    "    velocity = seq_std[:, 3] * stats[\"vel_std\"] + stats[\"vel_mean\"]\n",
    "    seq_real = np.stack([pitch, step, duration, velocity], axis=1)\n",
    "    # Reutilizar la can√≥nica\n",
    "    save_sequence_to_midi(seq_real, output_path=output_path, instrument_name=instrument_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5277aa5e",
   "metadata": {},
   "source": [
    "# 3. Desarrollo del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2e1b0c",
   "metadata": {},
   "source": [
    "## 3.1. Dataset PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c302e1",
   "metadata": {},
   "source": [
    "Preparamos los datos musicales usando la clase **`MusicWindowsDataset`** para llevar nuestro *dataset* a un formato *tensor* - *long* / *float32*  para que el modelo en **`torch`** pueda consumirlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "148b0ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicWindowsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset personalizado para las ventanas de m√∫sica.\n",
    "    Proporciona pares ((Xp, Xc), (yp, yc)) donde:\n",
    "    - Xp: secuencia de pitches (enteros)\n",
    "    - Xc: secuencia de caracter√≠sticas continuas (step, duration, velocity)\n",
    "    - yp: pitch objetivo (entero)\n",
    "    - yc: caracter√≠sticas continuas objetivo (step, duration, velocity)\n",
    "    \"\"\"\n",
    "    def __init__(self, Xp, Xc, yp, yc):\n",
    "        self.Xp = Xp\n",
    "        self.Xc = Xc\n",
    "        self.yp = yp\n",
    "        self.yc = yc\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Xp)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        import torch\n",
    "        Xp = torch.as_tensor(self.Xp[i], dtype=torch.long)        # [L]\n",
    "        Xc = torch.as_tensor(self.Xc[i], dtype=torch.float32)     # [L,3]\n",
    "        yp = torch.as_tensor(self.yp[i], dtype=torch.long)        # []\n",
    "        yc = torch.as_tensor(self.yc[i], dtype=torch.float32)     # [3]\n",
    "        return (Xp, Xc), (yp, yc)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc992c",
   "metadata": {},
   "source": [
    "## 3.2 Definici√≥n del modelo\n",
    "\n",
    "Consideramos que en escencia el modelo que mejor puede captura la informaci√≥n respecto a las secuencias musicales es el conocido **`LSTM`**. Sus memorias de corto y largo plazo, pueden capturar relaciones entre sus notas las cuales pueden ser ciclicas-corto placistas pero tambi√©n, estas memorias, permiten conservar la estructura \"como un todo\" de la secuencia musical, haciendo que tenga sentido y armon√≠a. Los detalles de la arquitectura se muestran m√°s adelante en el diagrama, pero en escencia el modelo usado gira alrededor de la metodolog√≠a **`LSTM`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75ce95d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Modelo LSTM para predecir la siguiente nota y sus caracter√≠sticas continuas.\n",
    "class MusicLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, emb_dim=64, cont_dim=3, hidden_size=256, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=None)\n",
    "        self.emb_drop = nn.Dropout(0.15)\n",
    "        self.input_dim = emb_dim + cont_dim\n",
    "        self.lstm = nn.LSTM(self.input_dim, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.ln = nn.LayerNorm(hidden_size)  # Capa de normalizaci√≥n\n",
    "        self.pitch_out = nn.Linear(hidden_size, vocab_size)\n",
    "        self.cont_out  = nn.Linear(hidden_size, cont_dim)\n",
    "\n",
    "    def forward(self, pitch_seq, cont_seq):\n",
    "\n",
    "        emb = self.emb(pitch_seq)                # (B, seq_len, emb_dim)\n",
    "        x = torch.cat([emb, cont_seq], dim=-1)   # (B, seq_len, emb+cont)\n",
    "        out, (h, c) = self.lstm(x)               # out: (B, seq_len, hidden)\n",
    "        last = out[:, -1, :]\n",
    "        last = self.ln(last)\n",
    "        pitch_logits = self.pitch_out(last)\n",
    "        cont_pred    = self.cont_out(last)\n",
    "        return pitch_logits, cont_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ceddb",
   "metadata": {},
   "source": [
    "## 3.3 Diagrama de arquitectura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb42db50",
   "metadata": {},
   "source": [
    "El modelo **MusicLSTM** recibe dos entradas: una secuencia discreta de *pitches* (notas MIDI codificadas entre 0 y 127) y tres caracter√≠sticas continuas por timestep (*step*, *duration* y *velocity*).  \n",
    "Primero, las notas pasan por una capa de *embedding* de 96 dimensiones, que aprende representaciones densas de las notas musicales. Estas se fusionan con las variables continuas para formar vectores de 99 features por paso temporal.\n",
    "\n",
    "A continuaci√≥n, una LSTM apilada de tres capas o las que se designen por par√°metro (**`hidden size`** = 320, **`dropout`**= 0.35) captura las dependencias temporales y la estructura secuencial de la m√∫sica. Del √∫ltimo *hidden state* se obtiene un **vector de contexto** de 320 dimensiones, que luego se normaliza mediante *layer Normalization* para estabilizar el entrenamiento.\n",
    "\n",
    "Finalmente, el modelo se divide en dos cabezas de salida:  \n",
    "- una de **clasificaci√≥n** (Linear 320 ‚Üí 128) que predice la siguiente nota MIDI,  \n",
    "- y otra de **regresi√≥n** (Linear 320 ‚Üí 3) que estima los valores continuos de *step*, *duration* y *velocity*.\n",
    "\n",
    "Este dise√±o permite generar melod√≠as donde se combinan eventos discretos (*pitches*) y propiedades temporales continuas, manteniendo coherencia r√≠tmica y expresiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "298e5228-3a73-47bd-8ae4-397709899277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"./Arquitectura MusicLSTM.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x169003fa590>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "# Ruta del PDF\n",
    "IFrame(\"./Arquitectura MusicLSTM.pdf\", width=800, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bb0e3d",
   "metadata": {},
   "source": [
    "# 4. Etapa Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ad1fca",
   "metadata": {},
   "source": [
    "## 4.1. Funciones para entrenar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cf7eb2",
   "metadata": {},
   "source": [
    "La clase `EarlyStopping` es una t√©cnica de regularizaci√≥n usada durante el entrenamiento para evitar el sobreajuste esto con el fin de evitar que memorice los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94f5afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stopping basado en una m√©trica escalar (modo 'min').\n",
    "    Guarda el mejor valor observado y cuenta √©pocas sin mejora.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=6, min_delta=0.0):\n",
    "        self.patience = int(patience)\n",
    "        self.min_delta = float(min_delta)\n",
    "        self.best = None\n",
    "        self.bad_epochs = 0\n",
    "\n",
    "    def step(self, value: float) -> bool:\n",
    "        \"\"\"\n",
    "        Devuelve True si hubo mejora y debe guardarse checkpoint.\n",
    "        \"\"\"\n",
    "        if self.best is None or (value < self.best - self.min_delta):\n",
    "            self.best = float(value)\n",
    "            self.bad_epochs = 0\n",
    "            return True\n",
    "        else:\n",
    "            self.bad_epochs += 1\n",
    "            return False\n",
    "\n",
    "    def should_stop(self) -> bool:\n",
    "        return self.bad_epochs >= self.patience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7b96be",
   "metadata": {},
   "source": [
    "La funci√≥n `train` realiza el entrenamiento completo del modelo con las siguientes caracter√≠sticas:\n",
    "\n",
    "**Par√°metros principales:**\n",
    "- `model`: Modelo de red neuronal (LSTM/RNN/GRU) a entrenar\n",
    "- `train_loader`: DataLoader con los datos de entrenamiento\n",
    "- `val_loader`: DataLoader con los datos de validaci√≥n\n",
    "- `device`: Dispositivo donde se ejecutar√° el entrenamiento (CPU o GPU)\n",
    "- `epochs`: N√∫mero m√°ximo de √©pocas de entrenamiento\n",
    "- `lr`: Tasa de aprendizaje (learning rate) para el optimizador AdamW\n",
    "\n",
    "**Funci√≥n de p√©rdida compuesta:**\n",
    "- `CrossEntropyLoss` con label smoothing (0.05) para predecir el pitch (variable categ√≥rica)\n",
    "- `Smooth L1 Loss` (Huber Loss) para predecir las variables continuas (step, duration, velocity)\n",
    "- `cont_loss_weight`: Factor que pondera la importancia de las variables continuas en la p√©rdida total\n",
    "\n",
    "**Early Stopping:**\n",
    "- `es_patience`: N√∫mero de √©pocas sin mejora antes de detener el entrenamiento\n",
    "- `es_min_delta`: Mejora m√≠nima requerida para considerar que hubo progreso\n",
    "- `best_ckpt_path`: Ruta donde se guardar√° el mejor modelo encontrado\n",
    "\n",
    "**T√©cnicas de regularizaci√≥n aplicadas:**\n",
    "- Gradient clipping (norm m√°xima de 1.0) para evitar gradientes explosivos\n",
    "- Label smoothing en la p√©rdida de clasificaci√≥n\n",
    "- Dropout en las capas recurrentes del modelo\n",
    "\n",
    "**Retorna:**\n",
    "- `history`: Diccionario con las m√©tricas de entrenamiento y validaci√≥n por √©poca, incluyendo la mejor √©poca encontrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ef2a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, device, epochs=40,\n",
    "          lr=5e-4, cont_loss_weight=50.0,\n",
    "          # par√°metros de early stopping\n",
    "          es_patience=6,\n",
    "          es_min_delta=0.0,\n",
    "          best_ckpt_path=\"OUTPUT/best_music_lstm.pth\",\n",
    "          verbose=True):\n",
    "\n",
    "    \"\"\" \n",
    "    Entrena el modelo con los datos de train_loader y val_loader.\n",
    "    Usa AdamW, CrossEntropy para pitch y MSE para continuos.\n",
    "    Guarda el mejor modelo seg√∫n la m√©trica val_total = val_CE + cont_loss_weight\n",
    "    history: diccionario con m√©tricas de entrenamiento y validaci√≥n.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    model.to(device)\n",
    "    opt = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    history = { \"train_loss\": [],\n",
    "                \"val_CE\": [],\n",
    "                \"val_MSE\": [],\n",
    "                \"val_total\": [],\n",
    "                \"best_epoch\": None,\n",
    "                \"best_val_total\": None,\n",
    "                \"best_ckpt_path\": best_ckpt_path}\n",
    "\n",
    "    # Inicializa EarlyStopping\n",
    "    es = EarlyStopping(patience=es_patience, min_delta=es_min_delta)\n",
    "    # Usar tqdm para mostrar progreso general\n",
    "    epoch_iterator = range(1, epochs + 1)\n",
    "    \n",
    "    for epoch in epoch_iterator:\n",
    "        # Entrenamiento\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        # Barra de progreso para batches de entrenamiento (una barra horizontal por √©poca que permanece)\n",
    "        train_iter = tqdm(train_loader, desc=f\"Epoch {epoch:>3}/{epochs} [Train]\", leave=True, ncols=100) if verbose else train_loader\n",
    "        \n",
    "        for (Xp, Xc), (yp, yc) in train_iter:\n",
    "            Xp = Xp.to(device)           \n",
    "            Xc = Xc.to(device)           \n",
    "            yp = yp.to(device)           \n",
    "            yc = yc.to(device)         \n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits, cont_pred = model(Xp, Xc)         # logits [B,L,V]; cont_pred [B,L,3]\n",
    "            # Usa directamente la salida del modelo\n",
    "            logits_last = logits               # (B, V)\n",
    "            cont_last   = cont_pred            # (B, 3)\n",
    "\n",
    "            ce  = F.cross_entropy(logits_last, yp, label_smoothing=0.05)    # CE para pitch\n",
    "            mse = F.smooth_l1_loss(cont_last, yc, beta=0.5)    #F.mse_loss(cont_last, yc)          # MSE para continuos (normalizados)\n",
    "            loss = ce + cont_loss_weight * mse\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "\n",
    "            running += loss.item()\n",
    "            \n",
    "            # Actualizar descripci√≥n de la barra\n",
    "            if verbose and hasattr(train_iter, 'set_postfix'):\n",
    "                train_iter.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        train_loss = running / max(1, len(train_loader))\n",
    "\n",
    "        # Validaci√≥n\n",
    "        model.eval()\n",
    "        val_ce = 0.0\n",
    "        val_mse = 0.0\n",
    "        with torch.no_grad():\n",
    "            # Barra de progreso para validaci√≥n (opcional, m√°s compacta)\n",
    "            val_iter = tqdm(val_loader, desc=f\"Epoch {epoch:>3}/{epochs} [Val]  \", leave=True, ncols=100) if verbose else val_loader\n",
    "            for (Xp, Xc), (yp, yc) in val_iter:\n",
    "                Xp = Xp.to(device)\n",
    "                Xc = Xc.to(device)\n",
    "                yp = yp.to(device)\n",
    "                yc = yc.to(device)\n",
    "\n",
    "                logits, cont_pred = model(Xp, Xc)\n",
    "                logits_last = logits          # (B, V)\n",
    "                cont_last   = cont_pred       # (B, 3)\n",
    "\n",
    "                ce  = F.cross_entropy(logits_last, yp, label_smoothing=0.05)\n",
    "                mse = F.mse_loss(cont_last, yc)\n",
    "                val_ce  += ce.item()\n",
    "                val_mse += mse.item()\n",
    "\n",
    "        val_ce  /= max(1, len(val_loader))\n",
    "        val_mse /= max(1, len(val_loader))\n",
    "       \n",
    "        val_total = val_ce + cont_loss_weight * val_mse\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_CE\"].append(val_ce)\n",
    "        history[\"val_MSE\"].append(val_mse)\n",
    "        history[\"val_total\"].append(val_total)\n",
    "\n",
    "        # Actualizar barra de progreso principal con m√©tricas\n",
    "        if verbose and hasattr(epoch_iterator, 'set_postfix'):\n",
    "            epoch_iterator.set_postfix({\n",
    "                'train_loss': f'{train_loss:.4f}',\n",
    "                'val_total': f'{val_total:.4f}',\n",
    "                'best': f'{history[\"best_val_total\"]:.4f}' if history[\"best_val_total\"] else 'N/A'\n",
    "            })\n",
    "\n",
    "        if verbose and not hasattr(epoch_iterator, 'set_postfix'):\n",
    "            print(f\"Epoch {epoch} | train_loss={train_loss:.4f} | \"\n",
    "                  f\"val_CE={val_ce:.4f} | val_MSE={val_mse:.5f} | \"\n",
    "                  f\"val_total={val_total:.4f}\")\n",
    "\n",
    "        # Checkpoint si mejora\n",
    "        if es.step(val_total):\n",
    "            torch.save({\"model_state\": model.state_dict()}, best_ckpt_path)\n",
    "            history[\"best_epoch\"] = epoch\n",
    "            history[\"best_val_total\"] = val_total\n",
    "            if verbose:\n",
    "                print(f\"  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en {best_ckpt_path}\")\n",
    "\n",
    "        # Parar si no mejora por 'patience'\n",
    "        if es.should_stop():\n",
    "            if verbose:\n",
    "                print(f\"  ‚Ü≥ Early stopping en epoch {epoch} (best_epoch={history['best_epoch']})\")\n",
    "            break\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa4933f",
   "metadata": {},
   "source": [
    "## 4.2. Funciones para generar las nuevas notas musicales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaee046",
   "metadata": {},
   "source": [
    "`sample_from_logits_topk` elige la siguiente nota de forma probabilistica usando las salidas (logits) del modelo.\n",
    "La salida del modelo entrega una distribucion de probabilidades sobre todas las posibles notas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6479a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_logits_topk(logits, k=10, temperature=1.0):\n",
    "    \"\"\"\n",
    "    logits: torch.Tensor [vocab] o numpy.ndarray [vocab]\n",
    "    k: n√∫mero de top-k a considerar\n",
    "    temperature: float > 0, controla la aleatoriedad del muestreo\n",
    "    (temperature -> 0: m√°s determinista, temperature -> ‚àû: m√°s aleatorio)\n",
    "    Retorna:\n",
    "    √çndice entero muestreado en top-k (con temperatura).\n",
    "    Si logits es numpy.ndarray, se convierte a torch.Tensor.\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    if not isinstance(logits, torch.Tensor):\n",
    "        logits = torch.from_numpy(logits)\n",
    "\n",
    "    # Evita k inv√°lido\n",
    "    vocab = logits.shape[-1]\n",
    "    k = max(1, min(int(k), int(vocab)))\n",
    "\n",
    "    # √öltimo paso de la secuencia si viene con eje extra\n",
    "    # (p.ej., [1, V] -> [V])\n",
    "    if logits.ndim > 1:\n",
    "        logits = logits.view(-1)\n",
    "\n",
    "    # Temperatura\n",
    "    if temperature is None or temperature <= 0:\n",
    "        temperature = 1.0\n",
    "    logits = logits / float(temperature)\n",
    "\n",
    "    # Top-k + muestreo\n",
    "    topk_vals, topk_idx = torch.topk(logits, k)          \n",
    "    topk_probs = torch.softmax(topk_vals, dim=-1)        \n",
    "    choice = torch.multinomial(topk_probs, 1)            \n",
    "    return int(topk_idx[choice].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaea221",
   "metadata": {},
   "source": [
    "La funci√≥n `generate_sequence` genera nuevas secuencias musicales de forma autoregresiva paso a paso.\n",
    "\n",
    "**Proceso de generaci√≥n:**\n",
    "\n",
    "1. **Inicializaci√≥n**: Toma una secuencia inicial (seed) como punto de partida que contiene:\n",
    "   - `seed_pitch_seq`: Secuencia de pitches (notas musicales) como enteros\n",
    "   - `seed_cont_seq`: Caracter√≠sticas continuas normalizadas (step, duration, velocity)\n",
    "\n",
    "2. **Generaci√≥n iterativa**: En cada paso:\n",
    "   - El modelo recibe los √∫ltimos `max_context` (32) elementos de la secuencia\n",
    "   - Predice la siguiente nota con sus caracter√≠sticas continuas\n",
    "   - La predicci√≥n se a√±ade al contexto para la siguiente iteraci√≥n\n",
    "\n",
    "3. **Muestreo controlado**:\n",
    "   - **Top-k sampling**: Solo considera las k notas m√°s probables (par√°metro `top_k`)\n",
    "   - **Temperature**: Controla la aleatoriedad del muestreo:\n",
    "     - Valores bajos (< 1.0): M√°s conservador, sigue patrones aprendidos\n",
    "     - Valores altos (> 1.0): M√°s creativo, genera variaciones inesperadas\n",
    "     - Valor de 1.0: Muestreo directo de la distribuci√≥n\n",
    "\n",
    "4. **Desnormalizaci√≥n**: Las caracter√≠sticas continuas predichas se convierten de vuelta a su escala original usando las estad√≠sticas guardadas durante el entrenamiento (`stats`).\n",
    "\n",
    "5. **Validaci√≥n**: Se asegura que todos los valores generados sean v√°lidos:\n",
    "   - Pitch: entre 0 y 127 (rango MIDI est√°ndar)\n",
    "   - Step: no negativo\n",
    "   - Duration: m√≠nimo 1 ms\n",
    "   - Velocity: entre 1 y 127\n",
    "\n",
    "**Retorna:**\n",
    "- Array numpy de forma [steps, 4] con columnas [pitch, step, duration, velocity] en escala real, listo para convertir a archivo MIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56059a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_sequence(model, device, seed_pitch_seq, seed_cont_seq, steps=200, \n",
    "                      idx2pitch=None, stats=None, temperature=1.0, top_k=10,\n",
    "                      max_context=32):\n",
    "    \"\"\"\n",
    "    Toma el modelo entrenado y una secuencia inicial (seed) de notas\n",
    "    (pitch_seq: np.ndarray [T_seed] de enteros; cont_seq: np\n",
    "    .ndarray [T_seed, 3] de continuos normalizados)\n",
    "    \n",
    "    Genera una secuencia de notas a partir de una secuencia inicial.\n",
    "    Devuelve: np.ndarray shape [T_gen, 4] con columnas [pitch, step, dur, vel]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Normalizaci√≥n defensiva de entradas\n",
    "    seed_pitch_seq = np.asarray(seed_pitch_seq, dtype=np.int64)          \n",
    "    seed_cont_seq  = np.asarray(seed_cont_seq,  dtype=np.float32)        \n",
    "    assert seed_cont_seq.ndim == 2 and seed_cont_seq.shape[1] == 3, \"seed_cont_seq debe ser [T,3]\"\n",
    "\n",
    "    # Construir tensores en el dispositivo sin listas de ndarrays:\n",
    "    def _mk_inputs(pitches_np, cont_np):\n",
    "        # recorta al contexto\n",
    "        pitches_np = pitches_np[-max_context:]\n",
    "        cont_np    = cont_np[-max_context:]\n",
    "        inp_pitch = torch.as_tensor(pitches_np, dtype=torch.long, device=device).unsqueeze(0)   # [1, L]\n",
    "        inp_cont  = torch.as_tensor(cont_np,    dtype=torch.float32, device=device).unsqueeze(0) # [1, L, 3]\n",
    "        return inp_pitch, inp_cont\n",
    "\n",
    "    # Copias de trabajo (para ir anexando)\n",
    "    cur_pitch = seed_pitch_seq.copy()\n",
    "    cur_cont  = seed_cont_seq.copy()\n",
    "\n",
    "    generated_rows = []  # acumularemos filas [pitch, step, dur, vel] \n",
    "\n",
    "    for _ in range(steps):\n",
    "        inp_pitch, inp_cont = _mk_inputs(cur_pitch, cur_cont)\n",
    "        logits, cont_pred = model(inp_pitch, inp_cont)  \n",
    "\n",
    "        # Tomar el √∫ltimo paso temporal\n",
    "        logits_last = logits.squeeze(0)                \n",
    "        cont_last   = cont_pred.squeeze(0).cpu().numpy() # (3,)  \n",
    "\n",
    "        # Muestreo discreto\n",
    "        next_pitch_idx = sample_from_logits_topk(logits_last, k=top_k, temperature=temperature)\n",
    "\n",
    "        # Desnormalizar los 3 continuos \n",
    "        if stats is not None:\n",
    "            step = (cont_last[0] * (float(stats[\"step_std\"]) + 1e-6)) + float(stats[\"step_mean\"])\n",
    "            dur  = (cont_last[1] * (float(stats[\"dur_std\"])  + 1e-6)) + float(stats[\"dur_mean\"])\n",
    "            vel  = (cont_last[2] * (float(stats[\"vel_std\"])  + 1e-6)) + float(stats[\"vel_mean\"])\n",
    "        else:\n",
    "            step, dur, vel = float(cont_last[0]), float(cont_last[1]), float(cont_last[2])\n",
    "\n",
    "        # Seguridad: valores v√°lidos\n",
    "        next_pitch = int(np.clip(next_pitch_idx, 0, 127))\n",
    "        step = max(0.0, float(step))\n",
    "        dur  = max(1e-3, float(dur))\n",
    "        vel  = float(np.clip(vel, 1.0, 127.0))\n",
    "\n",
    "        # Append a las listas de estado (en formato NORMALIZADO para el modelo)\n",
    "        # Nota: para la siguiente iteraci√≥n el modelo necesita los continuos NORMALIZADOS,\n",
    "        # por lo que guardamos adem√°s la versi√≥n normalizada:\n",
    "        if stats is not None:\n",
    "            step_n = (step - float(stats[\"step_mean\"])) / (float(stats[\"step_std\"]) + 1e-6)\n",
    "            dur_n  = (dur  - float(stats[\"dur_mean\"]))  / (float(stats[\"dur_std\"])  + 1e-6)\n",
    "            vel_n  = (vel  - float(stats[\"vel_mean\"]))  / (float(stats[\"vel_std\"])  + 1e-6)\n",
    "            cur_cont = np.vstack([cur_cont, [step_n, dur_n, vel_n]]).astype(np.float32)\n",
    "        else:\n",
    "            cur_cont = np.vstack([cur_cont, [step, dur, vel]]).astype(np.float32)\n",
    "\n",
    "        cur_pitch = np.append(cur_pitch, next_pitch).astype(np.int64)\n",
    "\n",
    "        # Guardar fila desnormalizada para el MIDI\n",
    "        generated_rows.append([next_pitch, step, dur, vel])\n",
    "\n",
    "    return np.asarray(generated_rows, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685b2bc2",
   "metadata": {},
   "source": [
    "# 5. Definici√≥n de _main_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab1aa425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Extrayendo secuencias crudas...\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=4225\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=3300\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2954\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2173\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3868\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2580\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3185\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2792\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2854\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=3395\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1850\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=885\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3239\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=3186\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2970\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1822\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2592\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2073\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1779\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2002\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2191\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1494\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2027\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1588\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=5268\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=5465\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=1374\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=917\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=1705\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=1443\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=3118\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=2461\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2418\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2555\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2150\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=993\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2050\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=551\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3267\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2449\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1447\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1200\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=872\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=781\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=563\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=495\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1515\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1135\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1372\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=952\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1088\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=900\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2673\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2480\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=806\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=509\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1721\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1673\n",
      "  secuencias extra√≠das: 25\n",
      "2. Estandarizando variables continuas ...\n",
      "  stats: {'step_mean': np.float32(0.098957), 'step_std': np.float32(0.18229377), 'dur_mean': np.float32(0.33029), 'dur_std': np.float32(0.41488776), 'vel_mean': np.float32(48.245155), 'vel_std': np.float32(17.51278)}\n",
      "3. Creando ventanas...\n",
      "  Train -> Xp_tr: (76482, 32) Xc_tr: (76482, 32, 3) yp_tr: (76482,)\n",
      "  Valid -> Xp_va: (22357, 32) Xc_va: (22357, 32, 3) yp_va: (22357,)\n",
      "vocab_size: 128\n",
      "4. Preparando DataLoaders...\n",
      "5. Construyendo y entrenando el modelo...\n",
      "   Training model on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 598/598 [00:12<00:00, 47.39it/s, loss=8.3080]\n",
      "Epoch   1/40 [Val]  : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 175/175 [00:01<00:00, 156.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | train_loss=9.1103 | val_CE=3.6365 | val_MSE=0.38996 | val_total=11.4357\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT2/best_music_lstm.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   2/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 598/598 [00:11<00:00, 51.03it/s, loss=7.1863]\n",
      "Epoch   2/40 [Val]  : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 175/175 [00:01<00:00, 110.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | train_loss=7.8735 | val_CE=3.5667 | val_MSE=0.37459 | val_total=11.0585\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT2/best_music_lstm.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   3/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 598/598 [00:12<00:00, 49.43it/s, loss=6.8835]\n",
      "Epoch   3/40 [Val]  : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 175/175 [00:01<00:00, 135.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | train_loss=7.2507 | val_CE=3.5081 | val_MSE=0.35082 | val_total=10.5244\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT2/best_music_lstm.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   4/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 598/598 [00:11<00:00, 52.18it/s, loss=6.2621]\n",
      "Epoch   4/40 [Val]  : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 175/175 [00:01<00:00, 156.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | train_loss=6.7138 | val_CE=3.4881 | val_MSE=0.34723 | val_total=10.4327\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT2/best_music_lstm.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   5/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 598/598 [00:12<00:00, 49.17it/s, loss=5.2254]\n",
      "Epoch   5/40 [Val]  : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 175/175 [00:01<00:00, 114.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | train_loss=6.2564 | val_CE=3.4964 | val_MSE=0.34878 | val_total=10.4720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   6/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 598/598 [00:11<00:00, 51.27it/s, loss=4.6866]\n",
      "Epoch   6/40 [Val]  : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 175/175 [00:01<00:00, 153.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | train_loss=5.8580 | val_CE=3.4839 | val_MSE=0.34189 | val_total=10.3217\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT2/best_music_lstm.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   7/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 598/598 [00:11<00:00, 50.62it/s, loss=6.0721]\n",
      "Epoch   7/40 [Val]  : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 175/175 [00:01<00:00, 107.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | train_loss=5.4935 | val_CE=3.5046 | val_MSE=0.35784 | val_total=10.6613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   8/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 598/598 [00:11<00:00, 50.88it/s, loss=5.1938]\n",
      "Epoch   8/40 [Val]  : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 175/175 [00:01<00:00, 154.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | train_loss=5.1747 | val_CE=3.5139 | val_MSE=0.34244 | val_total=10.3628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   9/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 598/598 [00:11<00:00, 51.08it/s, loss=5.8142]\n",
      "Epoch   9/40 [Val]  : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 175/175 [00:01<00:00, 113.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | train_loss=4.8768 | val_CE=3.5711 | val_MSE=0.34814 | val_total=10.5340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  10/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 598/598 [00:11<00:00, 50.81it/s, loss=4.5088]\n",
      "Epoch  10/40 [Val]  : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 175/175 [00:01<00:00, 150.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train_loss=4.6229 | val_CE=3.5966 | val_MSE=0.34958 | val_total=10.5881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  11/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 598/598 [00:11<00:00, 50.32it/s, loss=4.5111]\n",
      "Epoch  11/40 [Val]  : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 175/175 [00:01<00:00, 118.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | train_loss=4.3919 | val_CE=3.6455 | val_MSE=0.36303 | val_total=10.9061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  12/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 598/598 [00:12<00:00, 48.56it/s, loss=4.2094]\n",
      "Epoch  12/40 [Val]  : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 175/175 [00:01<00:00, 115.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | train_loss=4.1802 | val_CE=3.6829 | val_MSE=0.36680 | val_total=11.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  13/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 598/598 [00:11<00:00, 52.32it/s, loss=3.9344]\n",
      "Epoch  13/40 [Val]  : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 175/175 [00:01<00:00, 152.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | train_loss=3.9913 | val_CE=3.7247 | val_MSE=0.35921 | val_total=10.9088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  14/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 598/598 [00:11<00:00, 50.28it/s, loss=3.8953]\n",
      "Epoch  14/40 [Val]  : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 175/175 [00:01<00:00, 111.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | train_loss=3.8343 | val_CE=3.7741 | val_MSE=0.36394 | val_total=11.0529\n",
      "  ‚Ü≥ Early stopping en epoch 14 (best_epoch=6)\n",
      "6. Generando ejemplos...\n",
      "[Gen 1] Usando semilla index: 33948\n",
      "MIDI guardado en: OUTPUT2/generated_music_lstm_1.mid (Acoustic Grand Piano)\n",
      "[Gen 1] MIDI guardado en: OUTPUT2\\generated_music_lstm_1.mid\n",
      "[Gen 2] Usando semilla index: 38110\n",
      "MIDI guardado en: OUTPUT2/generated_music_lstm_2.mid (Acoustic Grand Piano)\n",
      "[Gen 2] MIDI guardado en: OUTPUT2\\generated_music_lstm_2.mid\n",
      "[Gen 3] Usando semilla index: 24343\n",
      "MIDI guardado en: OUTPUT2/generated_music_lstm_3.mid (Acoustic Grand Piano)\n",
      "[Gen 3] MIDI guardado en: OUTPUT2\\generated_music_lstm_3.mid\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"1. Extrayendo secuencias crudas...\")\n",
    "    raw_sequences = extract_raw_note_sequences(ROOT_DIR, instrument_name= INSTRUMENT_NAME, composer_name=COMPOSER)\n",
    "    print(f\"  secuencias extra√≠das: {len(raw_sequences)}\")\n",
    "\n",
    "    train_sequences, val_sequences = train_test_split(raw_sequences, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "    print(\"2. Estandarizando variables continuas ...\")\n",
    "    standardized_sequences, stats = standardize_note_sequences(train_sequences)\n",
    "    print(\"  stats:\", stats)\n",
    "\n",
    "    def apply_standardization(seqs, stats):\n",
    "        out = []\n",
    "        for seq in seqs:\n",
    "            s = seq.copy()\n",
    "            s[:,1] = (s[:,1]-stats[\"step_mean\"])/(stats[\"step_std\"]+1e-6)\n",
    "            s[:,2] = (s[:,2]-stats[\"dur_mean\"] )/(stats[\"dur_std\"] +1e-6)\n",
    "            s[:,3] = (s[:,3]-stats[\"vel_mean\"] )/(stats[\"vel_std\"] +1e-6)\n",
    "            out.append(s)\n",
    "        return out\n",
    "\n",
    "    val_standardized = apply_standardization(val_sequences, stats)\n",
    "\n",
    "    print(\"3. Creando ventanas...\")\n",
    "    (Xp_tr, Xc_tr), (yp_tr, yc_tr) = create_windows(standardized_sequences, seq_len=SEQ_LEN)\n",
    "    (Xp_va, Xc_va), (yp_va, yc_va) = create_windows(val_standardized,       seq_len=SEQ_LEN)\n",
    "\n",
    "    print(\"  Train -> Xp_tr:\", Xp_tr.shape, \"Xc_tr:\", Xc_tr.shape, \"yp_tr:\", yp_tr.shape)\n",
    "    print(\"  Valid -> Xp_va:\", Xp_va.shape, \"Xc_va:\", Xc_va.shape, \"yp_va:\", yp_va.shape)\n",
    "\n",
    "\n",
    "    # construir vocab (opcional\n",
    "    if Xp_tr.shape[0] == 0:\n",
    "        raise RuntimeError(\"No hay muestras. Aumenta datos o reduce SEQ_LEN.\")\n",
    "    max_pitch = int(np.max(Xp_tr))\n",
    "    vocab_size = max(128, max_pitch + 1)\n",
    "    print(\"vocab_size:\", vocab_size)\n",
    "\n",
    "    # Dataset de PyTorch\n",
    "    print(\"4. Preparando DataLoaders...\")\n",
    "    train_ds = MusicWindowsDataset(Xp_tr, Xc_tr, yp_tr, yc_tr)\n",
    "    val_ds   = MusicWindowsDataset(Xp_va,   Xc_va,   yp_va,   yc_va)\n",
    "    loader   = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "    vloader  = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "    # Modelo y entrenamiento\n",
    "    print(\"5. Construyendo y entrenando el modelo...\")\n",
    "    model = MusicLSTM(vocab_size=vocab_size, emb_dim=EMB_DIM, cont_dim=3, hidden_size= HIDDEN_SIZE, num_layers= NUM_LAYERS,dropout=DROPOUT) # Ajustado num_layers\n",
    "    print(\"   Training model on device:\", DEVICE)\n",
    "    history = train(\n",
    "        model,\n",
    "        train_loader=loader,\n",
    "        val_loader=vloader,\n",
    "        device=DEVICE,\n",
    "        epochs=EPOCHS,\n",
    "        lr=LR,\n",
    "        cont_loss_weight= PESO_LOSS_CONT,\n",
    "        es_patience= PATIENCE,                \n",
    "        es_min_delta= MIN_DELTA,           \n",
    "        best_ckpt_path=(OUTPUT_DIR / \"best_music_lstm.pth\").as_posix(),\n",
    "    )\n",
    "\n",
    "    # Guardar modelo y stats\n",
    "    # Cargar mejor estado antes de generar\n",
    "    best_ckpt = torch.load((OUTPUT_DIR / \"best_music_lstm.pth\").as_posix(), map_location=DEVICE)\n",
    "    model.load_state_dict(best_ckpt[\"model_state\"])\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    #  Generaci√≥n de ejemplos\n",
    "    print(\"6. Generando ejemplos...\")\n",
    "    total_samples = Xp_tr.shape[0]\n",
    "   \n",
    "    # Elegimos √≠ndices de semillas distintos si hay suficientes, o con reposici√≥n si no\n",
    "    idx_pool = list(range(total_samples))\n",
    "    if total_samples >= NUM_SEQS:\n",
    "        seed_indices = random.sample(idx_pool, NUM_SEQS)  # sin reemplazo\n",
    "    else:\n",
    "        seed_indices = [random.choice(idx_pool) for _ in range(NUM_SEQS)]  # con reemplazo\n",
    "    \n",
    "    for j, idx in enumerate(seed_indices, start=1):\n",
    "        seed_pitch = Xp_tr[idx].tolist()\n",
    "        seed_cont  = Xc_tr[idx]\n",
    "        print(f\"[Gen {j}] Usando semilla index: {idx}\")\n",
    "    \n",
    "        generated = generate_sequence(\n",
    "            model, DEVICE,\n",
    "            seed_pitch, seed_cont,\n",
    "            steps=STEPS_PER_SEQ,\n",
    "            idx2pitch=None,\n",
    "            stats=stats,\n",
    "            temperature=TEMPERATURE,\n",
    "            top_k=TOP_K)\n",
    "        \n",
    "        if generated.shape[0] > 200:\n",
    "          generated = generated[-200:, :]\n",
    "\n",
    "        # TODO: Alerta / diagrama / histograma de distribuci√≥n\n",
    "        midi_path = OUTPUT_DIR / f\"generated_music_lstm_{j}.mid\"\n",
    "        save_sequence_to_midi(generated, output_path=midi_path.as_posix(), instrument_name=INSTRUMENT_NAME)\n",
    "        print(f\"[Gen {j}] MIDI guardado en: {midi_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9146687c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo: 3 minutos y 17.07 segundos\n"
     ]
    }
   ],
   "source": [
    "fin = time.time()\n",
    "print_time_execution(inicio, fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38aef6f",
   "metadata": {},
   "source": [
    "# 6. Conversi√≥n archivos .mid a .wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86529d9a",
   "metadata": {},
   "source": [
    "### Tabla de Compatibilidad Multiplataforma\n",
    "\n",
    "| Componente | Windows | macOS | Linux |\n",
    "|-----------|---------|-------|-------|\n",
    "| **Biblioteca FluidSynth** | `libfluidsynth-3.dll` | `libfluidsynth.dylib` | `libfluidsynth.so` |\n",
    "| **Driver de Audio** | `dsound` | `coreaudio` | `alsa` |\n",
    "| **Ubicaci√≥n t√≠pica biblioteca** | `C:\\Tools\\FluidSynth\\bin\\` | `/opt/homebrew/lib/`<br>`/usr/local/lib/` | `/usr/lib/`<br>`/usr/lib64/` |\n",
    "| **Ubicaci√≥n t√≠pica soundfont** | `.\\soundfonts\\` | `/opt/homebrew/share/soundfonts/`<br>`/usr/local/share/soundfonts/` | `/usr/share/soundfonts/`<br>`/usr/share/sounds/sf2/` |\n",
    "| **Gestor de paquetes** | Manual | Homebrew | apt/yum |\n",
    "\n",
    "**El c√≥digo detecta autom√°ticamente** tu sistema operativo y usa las configuraciones correctas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d402a6",
   "metadata": {},
   "source": [
    "### Inicio R√°pido por Sistema Operativo\n",
    "\n",
    "#### Para usuarios de **macOS** (como t√∫):\n",
    "```bash\n",
    "# 1. Instalar FluidSynth\n",
    "brew install fluid-synth\n",
    "\n",
    "# 2. Descargar soundfont\n",
    "mkdir -p soundfonts\n",
    "curl -o soundfonts/FluidR3_GM.sf2 https://member.keymusician.com/Member/FluidR3_GM/FluidR3_GM.sf2\n",
    "\n",
    "# 3. Ejecutar las celdas 13, 57 y 59 del notebook\n",
    "```\n",
    "\n",
    "#### Para usuarios de **Linux**:\n",
    "```bash\n",
    "# 1. Instalar FluidSynth y soundfont\n",
    "sudo apt-get update\n",
    "sudo apt-get install fluidsynth libfluidsynth-dev fluid-soundfont-gm\n",
    "\n",
    "# 2. El soundfont ya est√° instalado en /usr/share/sounds/sf2/\n",
    "# 3. Ejecutar las celdas 13, 57 y 59 del notebook\n",
    "```\n",
    "\n",
    "#### Para usuarios de **Windows**:\n",
    "```powershell\n",
    "# 1. Descargar FluidSynth desde GitHub y extraer a C:\\Tools\\FluidSynth\\\n",
    "# 2. Descargar soundfont manualmente y guardar en .\\soundfonts\\FluidR3_GM.sf2\n",
    "# 3. Ejecutar las celdas 13, 57 y 59 del notebook\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f15924",
   "metadata": {},
   "source": [
    "## 6.1. Configuraci√≥n de FluidSynth (Multiplataforma)\n",
    "\n",
    "Esta secci√≥n configura FluidSynth para convertir archivos MIDI a WAV. El c√≥digo es **compatible con Windows, macOS y Linux**.\n",
    "\n",
    "### Instalaci√≥n de FluidSynth por sistema operativo:\n",
    "\n",
    "#### **macOS**\n",
    "```bash\n",
    "# Con Homebrew\n",
    "brew install fluid-synth\n",
    "\n",
    "# Verificar instalaci√≥n\n",
    "which fluidsynth\n",
    "```\n",
    "\n",
    "#### **Linux (Ubuntu/Debian)**\n",
    "```bash\n",
    "# Instalar FluidSynth y librer√≠as de desarrollo\n",
    "sudo apt-get update\n",
    "sudo apt-get install fluidsynth libfluidsynth-dev\n",
    "\n",
    "# Opcional: Instalar soundfont\n",
    "sudo apt-get install fluid-soundfont-gm\n",
    "```\n",
    "\n",
    "#### **Windows**\n",
    "1. Descargar FluidSynth desde: https://github.com/FluidSynth/fluidsynth/releases\n",
    "2. Extraer a `C:\\Tools\\FluidSynth\\`\n",
    "3. Asegurarse que `libfluidsynth-3.dll` est√© en `C:\\Tools\\FluidSynth\\bin\\`\n",
    "\n",
    "### Soundfonts necesarios:\n",
    "\n",
    "Para renderizar audio, necesitas un archivo `.sf2` (soundfont):\n",
    "- **Descarga recomendada**: [FluidR3_GM.sf2](https://member.keymusician.com/Member/FluidR3_GM/FluidR3_GM.sf2)\n",
    "- **Ubicaci√≥n**: Guardar en `./soundfonts/FluidR3_GM.sf2`\n",
    "- **Tama√±o**: ~142 MB\n",
    "\n",
    "El c√≥digo busca autom√°ticamente soundfonts en las ubicaciones est√°ndar de cada sistema operativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4f028f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì FluidSynth cargado correctamente desde: C:\\Tools\\FluidSynth\\bin\\libfluidsynth-3.dll\n"
     ]
    }
   ],
   "source": [
    "# --- Bootstrap FluidSynth (multiplataforma) ---\n",
    "if os.name == \"nt\":  # Windows\n",
    "    DLL_DIR = r\"C:\\Tools\\FluidSynth\\bin\"  # carpeta donde pusiste libfluidsynth-3.dll\n",
    "    if hasattr(os, \"add_dll_directory\"):\n",
    "        os.add_dll_directory(DLL_DIR)\n",
    "    os.environ[\"FLUIDSYNTH_LIBRARY\"] = os.path.join(DLL_DIR, \"libfluidsynth-3.dll\")\n",
    "elif sys.platform == \"darwin\":  # macOS\n",
    "    # En macOS, FluidSynth se instala con: brew install fluid-synth\n",
    "    # La biblioteca t√≠picamente est√° en /opt/homebrew/lib (Apple Silicon) o /usr/local/lib (Intel)\n",
    "    possible_paths = [\n",
    "        \"/opt/homebrew/lib/libfluidsynth.dylib\",  # Apple Silicon\n",
    "        \"/usr/local/lib/libfluidsynth.dylib\",      # Intel Mac\n",
    "        \"/opt/local/lib/libfluidsynth.dylib\"       # MacPorts\n",
    "    ]\n",
    "    \n",
    "    fluidsynth_lib = None\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            fluidsynth_lib = path\n",
    "            break\n",
    "    \n",
    "    if fluidsynth_lib:\n",
    "        os.environ[\"FLUIDSYNTH_LIBRARY\"] = fluidsynth_lib\n",
    "    else:\n",
    "        print(\" FluidSynth no encontrado. Inst√°lalo con: brew install fluid-synth\")\n",
    "        os.environ[\"FLUIDSYNTH_LIBRARY\"] = \"\"  # Evitar KeyError\n",
    "else:  # Linux\n",
    "    # En Linux, t√≠picamente est√° en /usr/lib\n",
    "    possible_paths = [\n",
    "        \"/usr/lib/x86_64-linux-gnu/libfluidsynth.so\",\n",
    "        \"/usr/lib64/libfluidsynth.so\",\n",
    "        \"/usr/lib/libfluidsynth.so\"\n",
    "    ]\n",
    "    \n",
    "    fluidsynth_lib = None\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            fluidsynth_lib = path\n",
    "            break\n",
    "    \n",
    "    if fluidsynth_lib:\n",
    "        os.environ[\"FLUIDSYNTH_LIBRARY\"] = fluidsynth_lib\n",
    "    else:\n",
    "        print(\" FluidSynth no encontrado. Inst√°lalo con: sudo apt-get install libfluidsynth-dev\")\n",
    "        os.environ[\"FLUIDSYNTH_LIBRARY\"] = \"\"  # Evitar KeyError\n",
    "\n",
    "# (opcional) smoke test de la DLL/dylib para fallar pronto si algo cambi√≥\n",
    "if os.environ.get(\"FLUIDSYNTH_LIBRARY\") and os.path.exists(os.environ[\"FLUIDSYNTH_LIBRARY\"]):\n",
    "    from ctypes import CDLL\n",
    "    try:\n",
    "        CDLL(os.environ[\"FLUIDSYNTH_LIBRARY\"])\n",
    "        print(f\"‚úì FluidSynth cargado correctamente desde: {os.environ['FLUIDSYNTH_LIBRARY']}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error al cargar FluidSynth: {e}\")\n",
    "elif not os.environ.get(\"FLUIDSYNTH_LIBRARY\"):\n",
    "    print(\" FLUIDSYNTH_LIBRARY no est√° configurado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96d5c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_midi_to_wav(midi_path: str, wav_path: str, sf2_path: str, samplerate: int = 44100):\n",
    "    \"\"\"\n",
    "    Convierte un archivo MIDI a WAV usando FluidSynth.\n",
    "    \n",
    "    Args:\n",
    "        midi_path: Ruta al archivo MIDI de entrada\n",
    "        wav_path: Ruta al archivo WAV de salida\n",
    "        sf2_path: Ruta al archivo soundfont (.sf2)\n",
    "        samplerate: Frecuencia de muestreo (default: 44100 Hz)\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    \n",
    "    # Validar que existe el soundfont\n",
    "    if sf2_path is None or not os.path.exists(sf2_path):\n",
    "        print(f\"Error: No se encontr√≥ el archivo soundfont: {sf2_path}\")\n",
    "        print(\"   Ejecuta la celda 13 nuevamente para configurar el soundfont\")\n",
    "        return\n",
    "    \n",
    "    # Detectar el driver de audio correcto seg√∫n la plataforma\n",
    "    if os.name == \"nt\":  # Windows\n",
    "        audio_driver = \"dsound\"\n",
    "    elif sys.platform == \"darwin\":  # macOS\n",
    "        audio_driver = \"coreaudio\"\n",
    "    else:  # Linux\n",
    "        audio_driver = \"alsa\"\n",
    "    \n",
    "    try:\n",
    "        # Usar pretty_midi directamente que maneja mejor FluidSynth\n",
    "        pm = pretty_midi.PrettyMIDI(midi_path)\n",
    "        \n",
    "        # Renderizar audio usando FluidSynth\n",
    "        audio = pm.fluidsynth(fs=samplerate, sf2_path=sf2_path)\n",
    "        \n",
    "        # Normalizaci√≥n suave y conversi√≥n a PCM16\n",
    "        peak = float(np.max(np.abs(audio))) if audio.size > 0 else 1.0\n",
    "        audio = (audio / (peak if peak > 0 else 1.0)) * 0.99\n",
    "        audio_int16 = (np.clip(audio, -1, 1) * 32767).astype(np.int16)\n",
    "        \n",
    "        # Guardar archivo WAV\n",
    "        write(wav_path, samplerate, audio_int16)\n",
    "        print(f\"   ‚úì Archivo WAV generado exitosamente: {wav_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error al renderizar {midi_path}: {e}\")\n",
    "        print(f\"   Driver de audio detectado: {audio_driver}\")\n",
    "        print(f\"   Soundfont usado: {sf2_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59dc6034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7. Renderizando archivos MIDI a WAV...\n",
      "   Encontrados 3 archivos MIDI para convertir\n",
      "   Usando soundfont: ./soundfonts/FluidR3_GM.sf2\n",
      "\n",
      "   [1/3] Renderizando generated_music_lstm_1.mid ...\n",
      "   ‚úì Archivo WAV generado exitosamente: OUTPUT2/generated_music_lstm_1.wav\n",
      "\n",
      "   [2/3] Renderizando generated_music_lstm_2.mid ...\n",
      "   ‚úì Archivo WAV generado exitosamente: OUTPUT2/generated_music_lstm_2.wav\n",
      "\n",
      "   [3/3] Renderizando generated_music_lstm_3.mid ...\n",
      "   ‚úì Archivo WAV generado exitosamente: OUTPUT2/generated_music_lstm_3.wav\n",
      "\n",
      "‚úì Conversi√≥n completada. Archivos WAV guardados en: OUTPUT2\n",
      "Tiempo: 0.67 segundos\n"
     ]
    }
   ],
   "source": [
    "# Leer la carpeta OUTPUT y renderizar cada MIDI a WAV\n",
    "inicio = time.time()\n",
    "print(\"7. Renderizando archivos MIDI a WAV...\")\n",
    "\n",
    "# Validar que tenemos un soundfont antes de intentar renderizar\n",
    "if SF2 is None:\n",
    "    print(\"\\n No se puede renderizar a WAV sin un archivo soundfont.\")\n",
    "    print(\"   Por favor, ejecuta la celda 13 nuevamente y sigue las instrucciones para obtener un soundfont.\")\n",
    "    print(\"\\n   Opci√≥n r√°pida para macOS:\")\n",
    "    print(\"   1. Descarga desde: https://member.keymusician.com/Member/FluidR3_GM/FluidR3_GM.sf2\")\n",
    "    print(\"   2. Gu√°rdalo en: ./soundfonts/FluidR3_GM.sf2\")\n",
    "    print(\"   3. Ejecuta esta celda nuevamente\")\n",
    "else:\n",
    "    midi_files = glob.glob(os.path.join(OUTPUT_DIR.as_posix(), \"generated_music_lstm_*.mid\"))\n",
    "    \n",
    "    if len(midi_files) == 0:\n",
    "        print(\"   No se encontraron archivos MIDI para convertir.\")\n",
    "    else:\n",
    "        print(f\"   Encontrados {len(midi_files)} archivos MIDI para convertir\")\n",
    "        print(f\"   Usando soundfont: {SF2}\")\n",
    "        \n",
    "        j = 1\n",
    "        for midi_file in midi_files:\n",
    "            wav_file = OUTPUT_DIR / f\"generated_music_lstm_{j}.wav\"\n",
    "            print(f\"\\n   [{j}/{len(midi_files)}] Renderizando {os.path.basename(midi_file)} ...\")\n",
    "            render_midi_to_wav(midi_file, wav_file.as_posix(), SF2, samplerate=44100)\n",
    "            j += 1\n",
    "        \n",
    "        print(f\"\\n‚úì Conversi√≥n completada. Archivos WAV guardados en: {OUTPUT_DIR}\")\n",
    "\n",
    "fin = time.time()\n",
    "print_time_execution(inicio, fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6355783a-0eeb-41d8-abd2-3ae707106cec",
   "metadata": {},
   "source": [
    "***\n",
    "## Referencias\n",
    "[¬π] **FluidSynth, sintetizador SoundFont** Disponible en: [fluidsynth.org/](https://www.fluidsynth.org/)\n",
    "\n",
    "[¬≤] **Generation configurations: temperature, top-k, top-p, and test time compute** Disponible en: [huyenchip.com/](https://huyenchip.com/2024/01/16/sampling.html?utm_source=chatgpt.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13995d07",
   "metadata": {},
   "source": [
    "# Celda usada Font de los Markdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca98c8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- Fuentes recomendadas para estilo matem√°tico -->\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=STIX+Two+Text:ital,wght@0,400;0,700;1,400;1,700&display=swap\" rel=\"stylesheet\">\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=STIX+Two+Math:ital,wght@0,400;0,700;1,400;1,700&display=swap\" rel=\"stylesheet\">\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&display=swap\" rel=\"stylesheet\">\n",
       "\n",
       "<style>\n",
       "  /* --- Markdown cl√°sico (Notebook) --- */\n",
       "  div.text_cell_render.rendered_html p,\n",
       "  div.text_cell_render.rendered_html h1,\n",
       "  div.text_cell_render.rendered_html h2,\n",
       "  div.text_cell_render.rendered_html h3,\n",
       "  div.text_cell_render.rendered_html li {\n",
       "    font-family: 'STIX Two Text', serif !important;\n",
       "  }\n",
       "\n",
       "  /* MathJax (f√≥rmulas) */\n",
       "  .MathJax, .MathJax_Display {\n",
       "    font-family: 'STIX Two Math', serif !important;\n",
       "  }\n",
       "\n",
       "  /* C√≥digo */\n",
       "  div.text_cell_render.rendered_html code,\n",
       "  div.text_cell_render.rendered_html pre {\n",
       "    font-family: 'Inconsolata', monospace !important;\n",
       "  }\n",
       "\n",
       "  /* --- JupyterLab --- */\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon p,\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon h1,\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon h2,\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon h3,\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon li {\n",
       "    font-family: 'STIX Two Text', serif !important;\n",
       "  }\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon code,\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon pre {\n",
       "    font-family: 'Inconsolata', monospace !important;\n",
       "  }\n",
       "  .jp-Notebook .MathJax,\n",
       "  .jp-Notebook .MathJax_Display {\n",
       "    font-family: 'STIX Two Math', serif !important;\n",
       "  }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<!-- Fuentes recomendadas para estilo matem√°tico -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=STIX+Two+Text:ital,wght@0,400;0,700;1,400;1,700&display=swap\" rel=\"stylesheet\">\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=STIX+Two+Math:ital,wght@0,400;0,700;1,400;1,700&display=swap\" rel=\"stylesheet\">\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "<style>\n",
    "  /* --- Markdown cl√°sico (Notebook) --- */\n",
    "  div.text_cell_render.rendered_html p,\n",
    "  div.text_cell_render.rendered_html h1,\n",
    "  div.text_cell_render.rendered_html h2,\n",
    "  div.text_cell_render.rendered_html h3,\n",
    "  div.text_cell_render.rendered_html li {\n",
    "    font-family: 'STIX Two Text', serif !important;\n",
    "  }\n",
    "\n",
    "  /* MathJax (f√≥rmulas) */\n",
    "  .MathJax, .MathJax_Display {\n",
    "    font-family: 'STIX Two Math', serif !important;\n",
    "  }\n",
    "\n",
    "  /* C√≥digo */\n",
    "  div.text_cell_render.rendered_html code,\n",
    "  div.text_cell_render.rendered_html pre {\n",
    "    font-family: 'Inconsolata', monospace !important;\n",
    "  }\n",
    "\n",
    "  /* --- JupyterLab --- */\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon p,\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon h1,\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon h2,\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon h3,\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon li {\n",
    "    font-family: 'STIX Two Text', serif !important;\n",
    "  }\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon code,\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon pre {\n",
    "    font-family: 'Inconsolata', monospace !important;\n",
    "  }\n",
    "  .jp-Notebook .MathJax,\n",
    "  .jp-Notebook .MathJax_Display {\n",
    "    font-family: 'STIX Two Math', serif !important;\n",
    "  }\n",
    "</style>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (jlabclean)",
   "language": "python",
   "name": "jlabclean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
