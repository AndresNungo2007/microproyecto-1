{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b672c30",
   "metadata": {},
   "source": [
    "![Universidad_de_los_Andes_30.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHgAAAAkCAYAAABCKP5eAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAA3hSURBVHhe7ZsJmFVlGcffucywzAADoYKgCAiCgAjJk9nilmnZppUtakWYpZVhiWaWZKI9meRCLtliO6aISYWUpUElpoImCQLDJmDsBgKzcWdO/9+555s593Ducqa5NPbM/3n+z51z7rnnnO97l+9dvimzVpT162c9a2utulsXG9pUZsO8JhvSmLZBXrMN7NLFBjY2WnV5uR3ieVaVbrIu+jSdb06lrD6dtp0VXWxXutm26JqtZZ5tavLsJX2/vqtna1ONtn232V49Z3/mcZ04GEDAV5aV2UT9cbzkdZiOqyW4lP9tAAnJBuqbwYPMhhxhdrj+ru5lJsHa3n1m218x2/Cy2fpNZhs3m9XVBz8MQc/QlfZvsUb3X9Kjhz1QV2fP+F+24hDxRPFFca1YIZ4uvio+KRbCW0V+p7cpOTQTNkT8m3+UjdeJbxaXii9xokh0Fd8u8v7/4EQeSCr2fnGN+CwnckFyzaaE4Y05xrzLJpn34N3mbV1sXv0q89JrWvnYLPPqVmSfa6wxb+9y856YY94NU80762TzelYeeH/Yq8pu0GcUZ4p8P9U/MusjItyF/lF+SOUsLf7CPyo9fi7Wit38o2ygaIzjU/5R8UAxuOeP/KP8qBR5xvf8oxzIstSJx+nqG2WJT5g9P9/s1mvNztGU9+trVo6+BKhvMLtgitlt9wYnAmDR3TXcE8ebXX2p2bwfm22Tbj2qqbh8slmP7sGFpcEeEeu/3D8qPa4Q3yJqNjousgQ86Typ3EfMBvUPTuTAwqfMtmw3u1OCaygwvK5ysqe/yWzGV+XmC9y3CAwQLxG/K6LlXxYPFwFjwQO8QewtfkU8W3Tgbyd8lqZ3iHeIt4j8xkFqbleKd4uf5YRwqniXOEN8PSeEiSLnneqznOAyvyV+nBMh8JtpIu8sE7JjRAfeBUWZLl4tlov58Dbx2+J1/lE23igyNz8UzxHLsgRcLOY+ajZ2pBaKLbL0FcHJgwMmjolnMleJnxdx3/gGJvqbIpOMNX9GvF5kAvkO4ZwmAgQ3W1TE4Lt2+Sx/zQQzRSZvh8h6foKoEdtgkehinAg+IH5d5N7MI5Mqn+U/G4bBZON+a8R3ibwzSgguEh8TeY+tnMgDFPQRsVlcx4kQGNvjIs9m3f+ViDG0rot3XJ+9psZx/+rM+iwX7PXuZd60KfHXxfHoo1qf1cY1+CqR78f4RxlLY7AEOwid75ho8B0RgXAPAiJ8zYUia5dU0xc+QDjrxfv8I7M/i/8SUQyAMnDf0f5RK7BGJQZ+YDRBbBKdxedag3kWnoTv5Nf89XunOEsE+dZgLZR+oOoWxuga/Afx4cyfPh4UVya24H16/Gbp2XGj5GeGmi0oJrYtHRAagogbxxyRyX+neIrYKDIB/USyBcX+9m7xiyJucbgYhwUi6d1vxA+KoWikBSeJvMOf/KMDwdJys7hExMsAvM6xIkItJoiUz/SFusg/OhAoGV4HBWJMko4NSyzgPdKh3RruuEDAzy2LT4s6AJ4TcXmstXgGVBFBMWaU4hMiKRhW8VGRa+KwXMRNPy0+ILJWRtEj+ESJougp/l1kbWfN/pzokO93UbhoHU8RBxSP9ZlxoPgIeUBiAW/elomoyYdHDssI/PFcOpUc7uXjUo+kqBPnikwqFny/CMjFIdb0JREX99fgXC6w3p8vkpt+SIxa8crgk8ArCqz0KPEnIi4dt+qwWmTMWF8hbBC5FkWJg0zNFPr6YyIg/Iu4s00CPkxOrkIr3oRgJZyPE2sfMIG7xEkiE/lh8b8RNoHGkSIFlN9yQmBNZwKwYIIpAiDWfCLQOKAgSvr8gAVhMZFRKyK4wdKJoLGgsMBY77Go94kyCT9ecEAgPxMZL16Ed4hbAgBxAkpKUPYxkfcKg5iD57JGM3dfEM9PLGCqVv0PzVjxCdIl0qBFeesoiUDAQTS4WGTSiZpxi6QFgMjx9yKuFhAtckxgQrDF3y+IDkro7HfiT0WpZguIfrk/7pu0Bdfm3CWuOKyyuFglj75r/aWIYgCew5rLc3k+7p4AjWgdIfDeLAsbxfeIBEms4+TPvI/LPwjMbhU5zzrNPQmQosDyUQTuz7vw3sQUPAfgrcggSBuVlPrxRRlrUYvLUBRtl1wQHOTALYpRn5Kd3a8Mskl6fOwZ8h2KOXf/U6ZGSJMHIzUFa4LCnaLoG+Xev5Y56kSpkNiCdyvLGorTE6hRj1fykE5LHamIdqLDIbGACaqGEzIEGHV05nM5KXwnOhySC1irH9Gzg7PmdhIw1STWSsi6+L/CeSK5ASx1bZtCjBY4v8pF6bVdkVjA+5R80DZ0GDww87msfQTMKq4QzmeBFb2kuFikeAGJnnNFtu0BZIAfpNBCtN+uSCxgAit6wQ5E1IRqL5LR/X+AyhKRvEuF3OS/JpFYwARUPauCA6FPb6m37rJthxJMl7y8tkFeTOmS5I/CBH8XyC06LhILuFLZYrg33FvCpg9M8IWQSwieym4H2nvkkeSyY8U4YHEUMSgikDdSn6UZUQwoIgA6PH/M/GnninFzhS/jnWjz3SOyCeBOcbKYy92SmtK3Jg+n4UFDIt8SQKvxGyJjYezU1uOup6Fyjch1t4vkxH4HnjzYZzHdpEsvzD6uXWGe8l//9w/dk/1dlEV0k3CN7hoG4sDkslODokLLPUR2cIRru4B7UKYMX8fvKEQUAkUC6sJcT9mRQgu/x10H+UILEBTVq/BzwqRoEy1d0iygCeLGQYGEKpf7DYUOB+5P3Zsx8h0Vfz757UNiWMjUFGmeuPs4Tk5sweH1F1DJKg9a1NsZUmkwRcRNsgicIVJ1olrD+1OiGy8CrJTaMppLrZl4n04OveG4vVNRUNniHvSJiWypjCFcnhNt4iMAV/2isUG4yaQjVH7PWo5Vuznmeqwby3JZAosdlodCRkFpkzFSI2dDAGOi6UEDBY9CM8GB0iuVMiIhhE2Qime4L5GAG6TbBFVRyBp9lKirRC2a3RkAK8Z18qSbREqXfE+fGNBEpzEPaOjzPRPyA7FQxwYBuDIk5UIsC0G4jYGkTrmAEBAq1oViuX1hLBWusU+7j340YDzUr7EyF8xFwZh4J0qSbEgAxAW4X4DSAhTS7UhhMwBehcWSnnJdIgHvetVsSChFcuhNtVbgbUuAcPoQ7rcyMe7YFemxBJoJgOJ9krSDHjFrI3CNCcCkARoNbqNBIbgdHcyvm+OzRLcdJ9yYjwMm496F+nUYzwefzAs5NNuQN3FCeK8YVCYySCxgV9gIozrQ0Qr3+u0LVApNBtEtqFgNwK8gYNY0gi+Ef7xIm48GO03+QsA94waxXKyL0UC26zjdZZtOW4EFA9euzAfctpMNM07gR8yCV7pNdGAZALQIeW86VTQx2Hbk71VLJGCi5+HhZleAPsG6XOVWpPZFOPol4AjDHSNcpwSse0TNNNmrRdwhXR0sNB+cC+ZetC3ZjwUJaBwQcKI5C8HNTjEb/8OmQoeKOIPuEO+G9RMPEF3TIwZ4HNqHXMuSdZnIUjE80csqCva3xUbhLNh9tjOIDh2iloiLAgRfrH8Aa8PqKHvS5uP8CBHLzgUUgXQHsGZzP0dyYXrUYJQYqsQnghsHwRCCygf6xA4oHl6MXi8BGuVM0jECu7DCo9AEbgiaGAULntFWbcyCs+D+xTjC5KBP5QKkaFPeBRcUSqPWjWBxaS47z7drgrWL0iiunQ1zbLALkzwXcA1K0xbQ4wZ4pLidH2EQ3NHgB+xGweqLCXG4hmyBnjYYn5Jfa/kh/2vUFvRSkEU1a0AhJxhCQ4O/ZhQDBkvTHlBAcFbLrkQI2K7q3p5UwlkI6RMWA6LbTMNw0S3/MhP3ryYEcy7axU275SAJSLmcZeJNCu1U+X7w+WmR+MA9k0821Ll5AGzldbV71m8XDK5L6XICER9tTXNIkyhf9sXR5UCz7GlHyNmmm33LLBYEEVgixQb2PzHhpEsIEo2legPIRdmLxLZXok12dGAxRLWkG3FALSmOgPmic/VhoByunYLSxOQSBUFgRW6Kp6GIQ55Nzs5eLb/iFAHpEN0sFGGeyLgZG/OGzNwWXfwn5wk4iR34Dl+K17suVVbmD9wf1EampQ1Y8kLmvxdcuhSHR7T8s1kgwHoJPC5VIApmIiG7HR2wKpJ9LJkABNeMuvCfCWwkdy6cJYeAg/EQDvJEFIG1ifwwDgQruEMmhi05ccA7sN+a9yLwYr3mHL/jnEtTHHg3ziOMcJ5LysM4UCQ8Cxv5Thb5ZzMqXG77DWAueA7lTJ7J/4WgXMwyebHb6IcC81uuZ8yYKd9j9Qsx91QqZddqwqdNGGOpp+fKByRwQEsVlH9yqlRIr1ZFIS4GNdL/U5WVbs04KIRFlJtrwguBp6DVBEC5IlIGzXUIPq5K1BGA1RJZowAoc1gRokBxsVQ+XXkzChSfMbv7ZQGRnq00aIMEFVtHjmPNgkx9edGc+O8basy7a7p5smy0vUmKQ0WpNLF2J4pC1Skn2dQtz9iq/autOU5oYV5xsXkDDjWvfmX2+T3LzJs107zRI8xTFFdfUW6/rqxsqRd34iAimibtW/ikzdj0rKKwMn9/78MyPfLAWPDP341ygqvkgrcqBFq81Gz6TLOxZ5p30VVW8/IWu+mII230/rSdW1tb8B+aO1ECFFxtvXXWPZ1WLpay07xmGyeLHOaV2QA53V7X3Gyp2++15vJye6VbhW3Q3Zb3rLQlI0fYvL79be3s2XnXlU6UHGb/AWUuY+lI6Ug8AAAAAElFTkSuQmCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0b1b4a",
   "metadata": {},
   "source": [
    "***\n",
    "# **Microproyecto 1**\n",
    "\n",
    "## Descripci√≥n del problema:\n",
    "\n",
    "El problema a resolver consiste en generar nuevas secuencias de notas musicales basadas en el estilo de los artistas existentes, mencionados en la r√∫brica del taller haciendo uso de archivos .mid como fuente de datos esto con el fin de entrenar un modelo que sea capaz de aprender de las diferentes caracter√≠sticas y posteriormente producir nuevas composiciones donde mantenga coherencia musical.\n",
    "\n",
    "## Objetivo:\n",
    "\n",
    "Con esta actividad se busca que el estudiante pueda poner en pr√°ctica el uso de modelos de redes neuronales para trabajar con datos secuenciales. Tras realizar esta actividad se espera que el estudiante est√© en capacidad de:\n",
    "1. Estructurar datos secuenciales de forma que pueden ser usados por modelos de redes neuronales.\n",
    "2. Desarrollar soluciones de machine learning para datos secuenciales en distintos dominios.\n",
    "3. Entrenar modelos de machine learning con m√∫ltiples salidas.\n",
    "4. Entrenar modelos de machine learning con una funci√≥n de costo compuesta.\n",
    "5. Utilizar el modelo entrenado para generar nuevas secuencias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727c2e24",
   "metadata": {},
   "source": [
    "***\n",
    "## Integrantes Equipo 20\n",
    "- Andr√©s Felipe √ëungo Fern√°ndez\n",
    "- Andr√©s Juli√°n Gonzalez Barrera\n",
    "- Hernando Jose Jimenez D√≠az\n",
    "- Gloria In√©s L√≥pez Urbano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5fded7",
   "metadata": {},
   "source": [
    "***\n",
    "# √çndice\n",
    "\n",
    "El *notebook* aborda el microproyecto con la siguiente estructura:\n",
    "\n",
    "| üîπ | Secci√≥n        |\n",
    "|----|----------------|\n",
    "| 1Ô∏è.   | **Instalaci√≥n e importe de librer√≠as** |\n",
    "| 1Ô∏è.1Ô∏è  | Importar librer√≠as |\n",
    "| 1Ô∏è.2Ô∏è. | Definici√≥n variables globales |\n",
    "| 1Ô∏è.3Ô∏è. | Definici√≥n de semillas |\n",
    "| 2Ô∏è.   | **Carga y procesamiento de los datos**  |\n",
    "| 2Ô∏è.1Ô∏è. | Extracci√≥n caracter√≠sticas de los archivos .mid  |\n",
    "| 2Ô∏è.2Ô∏è. | Estandarizar variables cuantitativas  |\n",
    "| 2Ô∏è.3Ô∏è. | Generar secuencias de entrenamiento _requeridas para LSTM_  |\n",
    "| 2Ô∏è.4Ô∏è. | Funci√≥n Guardar secuencias a MIDI  |\n",
    "| 3Ô∏è. | **PyTorch** |\n",
    "| 3Ô∏è.1Ô∏è. | Dataset PyTorch  |\n",
    "| 3Ô∏è.2Ô∏è. | Definici√≥n del modelo   |\n",
    "| 4Ô∏è. | **Etapa Entrenamiento**   |\n",
    "| 4Ô∏è.1Ô∏è. | Funciones para entrenar   |\n",
    "| 4Ô∏è.2Ô∏è. | Funciones para generar las nuevas notas musicales   |\n",
    "| 5Ô∏è. | **Definici√≥n de _main_**  |\n",
    "| 6Ô∏è. | **Conversi√≥n archivos .mid a .wav**   |\n",
    "| 7Ô∏è. | **An√°lisis de resultados y discusi√≥n**   |\n",
    "| 8. | **Conclusi√≥n**   |\n",
    "| 9. | **Referencias**   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16f7b63",
   "metadata": {},
   "source": [
    "# 1. Instalaci√≥n e importe de librer√≠as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7deab13",
   "metadata": {},
   "source": [
    "Versi√≥n usada de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4453010d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.11\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc59e49",
   "metadata": {},
   "source": [
    "Para la ejecuci√≥n de este Notebook, se recomienda realizar instalaci√≥n de las librer√≠as mencionadas a continuaci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c44f70ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch\n",
    "#!pip install pretty_midi\n",
    "#!pip install mido\n",
    "#!pip install pyFluidSynth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c8813b",
   "metadata": {},
   "source": [
    "## 1.1 Importar librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19a8b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaci√≥n de librer√≠as del sistema\n",
    "import sys, glob, os, time\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "from importlib.metadata import version\n",
    "\n",
    "# Gesti√≥n de archivos\n",
    "from scipy.io.wavfile import write\n",
    "from pathlib import Path\n",
    "\n",
    "# Importaci√≥n de librer√≠a de DL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Dataloader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Separaci√≥n de datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Librer√≠as para MIDI y audio\n",
    "import fluidsynth as pyfluidsynth\n",
    "import pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55019f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy :  1.26.4\n",
      "pandas :  2.3.2\n",
      "scikit-learn :  1.7.1\n",
      "matplotlib :  3.10.5\n",
      "joblib :  1.5.1\n"
     ]
    }
   ],
   "source": [
    "# Ignorar las warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Versiones utilizadas\n",
    "librerias = [\"numpy\",\n",
    "            \"pandas\",\n",
    "            \"scikit-learn\",\n",
    "            \"matplotlib\",\n",
    "            \"joblib\"]\n",
    "for library in librerias:\n",
    "  print(library, \": \", version(library))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d50cab2",
   "metadata": {},
   "source": [
    "## 1.2 Definici√≥n variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa73c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rutas\n",
    "ROOT_DIR =  \"./Dataset/music_artist\"\n",
    "OUTPUT_DIR = Path(\"./OUTPUT2\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SF2 = \"./soundfonts/FluidR3_GM.sf2\"  # Ruta soundfont\n",
    "\n",
    "# Par√°metros de lotes de entrenamiento\n",
    "SEQ_LEN = 32 # Block size\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 40\n",
    "LR = 5e-4\n",
    "PESO_LOSS_CONT = 20\n",
    "PATIENCE = 8\n",
    "MIN_DELTA = 1e-3\n",
    "\n",
    "# P√°rametros redes\n",
    "HIDDEN_SIZE = 320\n",
    "NUM_LAYERS = 3\n",
    "DROPOUT = 0.35\n",
    "EMB_DIM = 96\n",
    "\n",
    "# Elecciones usuario\n",
    "MODEL_TYPE = \"LSTM\"  # opciones: \"RNN\", \"LSTM\", \"GRU\"\n",
    "INSTRUMENT_NAME = \"Acoustic Grand Piano\"\n",
    "COMPOSER = \"schubert\"  # este es el artista que tiene m√°s datos\n",
    "\n",
    "# Par√°metros de generaci√≥n de secuencias\n",
    "NUM_SEQS       = 3  # N√∫mero de secuencias a generar\n",
    "STEPS_PER_SEQ  = 200  # Notas que debe tener cada secuencia\n",
    "TEMPERATURE    = 0.65  # Temperatura\n",
    "TOP_K = 20  # Metodolog√≠a para delimitar el dominio de notas a elegir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c87fd776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones globales √∫tiles\n",
    "# Esta funci√≥n permite informar cu√°nto tiempo tarda en correr cada modelo. Prop√≥sito: solo informativo para referencia al momento de ejecutar el Notebook.\n",
    "def print_time_execution(inicio, fin):\n",
    "    str_log = \"\"\n",
    "    duracion = fin - inicio\n",
    "    if duracion > 60:\n",
    "        minutos = duracion // 60\n",
    "        segundos = duracion % 60\n",
    "        str_log = f\"Tiempo: {minutos:.0f} minutos y {segundos:.2f} segundos\"\n",
    "    else:\n",
    "        str_log = f\"Tiempo: {duracion:.2f} segundos\"\n",
    "    print(str_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744cf26d",
   "metadata": {},
   "source": [
    "## 1.3 Definici√≥n de semillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e212aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 13\n",
    "random.seed(RANDOM_STATE); np.random.seed(RANDOM_STATE); torch.manual_seed(RANDOM_STATE)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(RANDOM_STATE)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c7c52f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aee225b",
   "metadata": {},
   "source": [
    "# 2. Carga y procesamiento de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a118b4b",
   "metadata": {},
   "source": [
    "## 2.1. Extracci√≥n caracter√≠sticas de los archivos .mid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a8a0e7",
   "metadata": {},
   "source": [
    "En esta secci√≥n se realiza la selecci√≥n del primer instrumento encontrado y extracci√≥n notas del instrumento seleccionado. Como resultado se extraen las siguientes caracter√≠sticas por cada nota le√≠da:   \n",
    "- Pitch: representa la nota musical.\n",
    "- Step: es el espacio de tiempo que hay entre la nota anterior y la nota actual.\n",
    "- Duraction: Es la diferencia de tiempo en el que termina la nota actual (end) menos el inicio de la nota (start).\n",
    "- Velocity: es la velocidad de la nota musical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a72f87e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7083be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_raw_note_sequences(root_dir, instrument_name=None, program_number=None, composer_name=None):\n",
    "    raw_sequences = []\n",
    "    candidates = [composer_name] if composer_name else [ d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "    for composer in candidates:\n",
    "        folder = os.path.join(root_dir, composer)\n",
    "        midi_files = glob.glob(os.path.join(folder, \"*.mid\"))\n",
    "\n",
    "        for mf in midi_files:\n",
    "            try:\n",
    "                pm = pretty_midi.PrettyMIDI(mf)\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo leer {mf}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Selecci√≥n instrumento\n",
    "            chosen_instruments = []\n",
    "            for i, inst in enumerate(pm.instruments):\n",
    "                name = pretty_midi.program_to_instrument_name(inst.program)\n",
    "                print(f\"[{i}] prog={inst.program:>2} name={name} notas={len(inst.notes)}\")\n",
    "                if instrument_name is not None:\n",
    "                    inst_name = pretty_midi.program_to_instrument_name(inst.program)\n",
    "                    if inst_name.lower() == instrument_name.lower():\n",
    "                        chosen_instruments.append(inst)\n",
    "                elif program_number is not None:\n",
    "                    if inst.program == program_number:\n",
    "                        chosen_instruments.append(inst)\n",
    "\n",
    "            # Si no hubo match expl√≠cito y no se especific√≥ filtro, tomamos el primero (comportamiento viejo)\n",
    "            if instrument_name is None and program_number is None:\n",
    "                chosen_instruments = pm.instruments[:1]  \n",
    "\n",
    "            if not chosen_instruments:\n",
    "                # Nada que extraer en este archivo para el instrumento pedido\n",
    "                continue\n",
    "\n",
    "            # Extraer notas SOLO del/los instrumentos elegidos \n",
    "            notes = []\n",
    "            for inst in chosen_instruments:\n",
    "                for note_mus in inst.notes:\n",
    "                    start = note_mus.start\n",
    "                    end = note_mus.end\n",
    "                    duration = end - start\n",
    "                    velocity = note_mus.velocity\n",
    "                    notes.append((start, note_mus.pitch, duration, velocity))\n",
    "\n",
    "            if not notes:\n",
    "                continue\n",
    "\n",
    "            # Ordenar por inicio y construir [pitch, step, duration, velocity]\n",
    "            notes.sort(key=lambda x: x[0])\n",
    "            note_feats = []\n",
    "            prev_start = notes[0][0]\n",
    "            for start, pitch, duration, velocity in notes:\n",
    "                step = start - prev_start\n",
    "                prev_start = start\n",
    "                note_feats.append([pitch, step, duration, velocity])\n",
    "\n",
    "            if note_feats:\n",
    "                raw_sequences.append(np.array(note_feats, dtype=np.float32))\n",
    "\n",
    "    return raw_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293f1c6c",
   "metadata": {},
   "source": [
    "## 2.2. Estandarizar variables cuantitativas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c1bd8",
   "metadata": {},
   "source": [
    "Este paso es necesario dado que los modelos de red neuronal son muy sensibles a las escalas de los datos. Al no estandarizar las variables continuas, el modelo no aprender√° correctamente las relaciones entre variables.\n",
    "La presente estandarizaci√≥n lleva todas las variables continuas a extraer el promedio y la desviaci√≥n estandar normalizando cada valor individual, siguiendo la f√≥rmula del z-score:\n",
    "`norm_x = (x - mean) / std`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7c36d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_note_sequences(sequences):\n",
    "    \"\"\"\n",
    "    Estandariza las variables continuas (step, duration, velocity)\n",
    "    y mantiene el pitch intacto para usarlo luego con embeddings.\n",
    "    \"\"\"\n",
    "    all_steps, all_durations, all_velocities = [], [], []\n",
    "\n",
    "    # Recolectar todas las variables continuas para calcular media y std global\n",
    "    for seq in sequences:\n",
    "        all_steps.extend(seq[:, 1])\n",
    "        all_durations.extend(seq[:, 2])\n",
    "        all_velocities.extend(seq[:, 3])\n",
    "\n",
    "    # Estad√≠sticas globales\n",
    "    step_mean, step_std = np.mean(all_steps), np.std(all_steps)\n",
    "    dur_mean, dur_std = np.mean(all_durations), np.std(all_durations)\n",
    "    vel_mean, vel_std = np.mean(all_velocities), np.std(all_velocities)\n",
    "\n",
    "    standardized = []\n",
    "    for seq in sequences:\n",
    "        seq_std = seq.copy()\n",
    "        # No tocar pitch (columna 0)\n",
    "        seq_std[:, 1] = (seq[:, 1] - step_mean) / (step_std + 1e-6)\n",
    "        seq_std[:, 2] = (seq[:, 2] - dur_mean) / (dur_std + 1e-6)\n",
    "        seq_std[:, 3] = (seq[:, 3] - vel_mean) / (vel_std + 1e-6)\n",
    "        standardized.append(seq_std)\n",
    "\n",
    "    stats = {\"step_mean\": step_mean, \"step_std\": step_std,\n",
    "            \"dur_mean\": dur_mean, \"dur_std\": dur_std,\n",
    "            \"vel_mean\": vel_mean, \"vel_std\": vel_std}\n",
    "\n",
    "    return standardized, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4187d670",
   "metadata": {},
   "source": [
    "## 2.3. Generar secuencias de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9641529a",
   "metadata": {},
   "source": [
    "Esta secci√≥n realiza la conversi√≥n de una secuencia larga de notas en muestras peque√±as de longitud fija llamadas ventanas o secuencias de entrenamiento.\n",
    "La entrada de datos debe tener estandarizadas las variables continuas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9e3e041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(sequences, seq_len=32):\n",
    "    \"\"\"\n",
    "    Crea pares (X, y) para entrenamiento a partir de las secuencias estandarizadas.\n",
    "    X: secuencia de longitud seq_len\n",
    "    y: la nota siguiente\n",
    "    La variable pitch se mantiene intacto dado que es una variable categ√≥rica que se usar√° con embeddings.\n",
    "    \"\"\"\n",
    "    X_pitch, X_cont, y_pitch, y_cont = [], [], [], []\n",
    "\n",
    "    for seq in sequences:\n",
    "        if len(seq) < seq_len + 1:\n",
    "            continue\n",
    "\n",
    "        # Dividir en ventanas\n",
    "        for i in range(len(seq) - seq_len):\n",
    "            window = seq[i:i+seq_len]\n",
    "            target = seq[i+seq_len]\n",
    "\n",
    "            # Separar pitch (entero) y las features continuas\n",
    "            X_pitch.append(window[:, 0].astype(np.int64))     # pitch\n",
    "            X_cont.append(window[:, 1:].astype(np.float32))   # step, duration, velocity\n",
    "            y_pitch.append(int(target[0]))                    # pitch de la siguiente nota\n",
    "            y_cont.append(target[1:].astype(np.float32))      # step, duration, velocity siguientes\n",
    "\n",
    "    # Convertir a arrays numpy\n",
    "    X_pitch = np.array(X_pitch, dtype=np.int64)\n",
    "    X_cont = np.array(X_cont, dtype=np.float32)\n",
    "    y_pitch = np.array(y_pitch, dtype=np.int64)\n",
    "    y_cont = np.array(y_cont, dtype=np.float32)\n",
    "\n",
    "    return (X_pitch, X_cont), (y_pitch, y_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024d29a7",
   "metadata": {},
   "source": [
    "## 2.4. Funci√≥n Guardar secuencias a MIDI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b3d7e4",
   "metadata": {},
   "source": [
    "La funci√≥n `save_sequence_to_midi` permite tomar las secuencias estandarizadas y generar de nuevo el archivo .mid con el fin de validar que no se haya corrompido las notas musicales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b9bc967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sequence_to_midi(seq, output_path=\"generated.mid\", instrument_name=\"Acoustic Grand Piano\"):\n",
    "    \"\"\"\n",
    "    seq: np.array (N,4) con columnas [pitch, step, duration, velocity] en ESCALA REAL.\n",
    "    \"\"\"\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    try:\n",
    "        program_number = pretty_midi.instrument_name_to_program(instrument_name)\n",
    "    except ValueError:\n",
    "        program_number = 0\n",
    "    instrument = pretty_midi.Instrument(program=program_number)\n",
    "\n",
    "    # Asegurar valores v√°lidos\n",
    "    pitch    = seq[:, 0].astype(int)\n",
    "    step     = np.maximum(seq[:, 1].astype(float), 0.0)\n",
    "    duration = np.maximum(seq[:, 2].astype(float), 0.01)\n",
    "    velocity = np.clip(seq[:, 3].astype(float), 0, 127).astype(int)\n",
    "\n",
    "    # Reconstruir tiempos absolutos\n",
    "    t = 0.0\n",
    "    for p, s, d, v in zip(pitch, step, duration, velocity):\n",
    "        t += s\n",
    "        note = pretty_midi.Note(velocity=int(v), pitch=int(p), start=float(t), end=float(t + d))\n",
    "        instrument.notes.append(note)\n",
    "\n",
    "    pm.instruments.append(instrument)\n",
    "    pm.write(output_path)\n",
    "    print(f\"MIDI guardado en: {output_path} ({instrument_name})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d62040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_std_sequence_to_midi(seq_std, stats, output_path=\"reconstructed.mid\", instrument_name=\"Acoustic Grand Piano\"):\n",
    "    \"\"\"\n",
    "    seq_std: np.array (N,4) [pitch, stepZ, durationZ, velocityZ] estandarizados.\n",
    "    stats: dict con medias/stds {'step_mean','step_std','dur_mean','dur_std','vel_mean','vel_std'}\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    # Desestandarizar\n",
    "    pitch    = seq_std[:, 0]\n",
    "    step     = seq_std[:, 1] * stats[\"step_std\"] + stats[\"step_mean\"]\n",
    "    duration = seq_std[:, 2] * stats[\"dur_std\"] + stats[\"dur_mean\"]\n",
    "    velocity = seq_std[:, 3] * stats[\"vel_std\"] + stats[\"vel_mean\"]\n",
    "    seq_real = np.stack([pitch, step, duration, velocity], axis=1)\n",
    "    # Reutilizar la can√≥nica\n",
    "    save_sequence_to_midi(seq_real, output_path=output_path, instrument_name=instrument_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5277aa5e",
   "metadata": {},
   "source": [
    "# 3. PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2e1b0c",
   "metadata": {},
   "source": [
    "## 3.1. Dataset PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c302e1",
   "metadata": {},
   "source": [
    "Preparar datos musicales en un formato (dataset) aceptable para que el modelo en torch pueda consumirlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "148b0ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicWindowsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset personalizado para las ventanas de m√∫sica.\n",
    "    Proporciona pares ((Xp, Xc), (yp, yc)) donde:\n",
    "    - Xp: secuencia de pitches (enteros)\n",
    "    - Xc: secuencia de caracter√≠sticas continuas (step, duration, velocity)\n",
    "    - yp: pitch objetivo (entero)\n",
    "    - yc: caracter√≠sticas continuas objetivo (step, duration, velocity)\n",
    "    \"\"\"\n",
    "    def __init__(self, Xp, Xc, yp, yc):\n",
    "        self.Xp = Xp\n",
    "        self.Xc = Xc\n",
    "        self.yp = yp\n",
    "        self.yc = yc\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Xp)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        import torch\n",
    "        Xp = torch.as_tensor(self.Xp[i], dtype=torch.long)        # [L]\n",
    "        Xc = torch.as_tensor(self.Xc[i], dtype=torch.float32)     # [L,3]\n",
    "        yp = torch.as_tensor(self.yp[i], dtype=torch.long)        # []\n",
    "        yc = torch.as_tensor(self.yc[i], dtype=torch.float32)     # [3]\n",
    "        return (Xp, Xc), (yp, yc)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc992c",
   "metadata": {},
   "source": [
    "## 3.2 Definici√≥n del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75ce95d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Modelo LSTM para predecir la siguiente nota y sus caracter√≠sticas continuas.\n",
    "    Input:\n",
    "    - secuencia de pitches (enteros) -> Embedding\n",
    "    - secuencia de caracter√≠sticas continuas (step, duration, velocity)\n",
    "    Output:\n",
    "    - pitch siguiente (logits para cada clase)\n",
    "    - caracter√≠sticas continuas siguientes (regresi√≥n)\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, emb_dim=64, cont_dim=3, hidden_size=256, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=None)\n",
    "        self.emb_drop = nn.Dropout(0.15)\n",
    "        self.input_dim = emb_dim + cont_dim\n",
    "        self.lstm = nn.LSTM(self.input_dim, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.ln = nn.LayerNorm(hidden_size)  # Capa de normalizaci√≥n\n",
    "        self.pitch_out = nn.Linear(hidden_size, vocab_size)\n",
    "        self.cont_out  = nn.Linear(hidden_size, cont_dim)\n",
    "\n",
    "    def forward(self, pitch_seq, cont_seq):\n",
    "        \"\"\"\n",
    "        pitch_seq: LongTensor (B, seq_len)\n",
    "        cont_seq: FloatTensor (B, seq_len, cont_dim)\n",
    "        returns:\n",
    "            pitch_logits: (B, vocab_size)\n",
    "            cont_pred: (B, cont_dim)\n",
    "        \"\"\"\n",
    "        emb = self.emb(pitch_seq)                # (B, seq_len, emb_dim)\n",
    "        x = torch.cat([emb, cont_seq], dim=-1)   # (B, seq_len, emb+cont)\n",
    "        out, (h, c) = self.lstm(x)               # out: (B, seq_len, hidden)\n",
    "        last = out[:, -1, :]\n",
    "        last = self.ln(last)\n",
    "        pitch_logits = self.pitch_out(last)\n",
    "        cont_pred    = self.cont_out(last)\n",
    "        return pitch_logits, cont_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ceddb",
   "metadata": {},
   "source": [
    "## 3.3 Diagrama de arquitectura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb42db50",
   "metadata": {},
   "source": [
    "### Pendiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bb0e3d",
   "metadata": {},
   "source": [
    "# 4. Etapa Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ad1fca",
   "metadata": {},
   "source": [
    "## 4.1. Funciones para entrenar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cf7eb2",
   "metadata": {},
   "source": [
    "La clase `EarlyStopping` es una t√©cnica de regularizaci√≥n usada durante el entrenamiento para evitar el sobreajuste esto con el fin de evitar que memorice los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94f5afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stopping basado en una m√©trica escalar (modo 'min').\n",
    "    Guarda el mejor valor observado y cuenta √©pocas sin mejora.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=6, min_delta=0.0):\n",
    "        self.patience = int(patience)\n",
    "        self.min_delta = float(min_delta)\n",
    "        self.best = None\n",
    "        self.bad_epochs = 0\n",
    "\n",
    "    def step(self, value: float) -> bool:\n",
    "        \"\"\"\n",
    "        Devuelve True si hubo mejora y debe guardarse checkpoint.\n",
    "        \"\"\"\n",
    "        if self.best is None or (value < self.best - self.min_delta):\n",
    "            self.best = float(value)\n",
    "            self.bad_epochs = 0\n",
    "            return True\n",
    "        else:\n",
    "            self.bad_epochs += 1\n",
    "            return False\n",
    "\n",
    "    def should_stop(self) -> bool:\n",
    "        return self.bad_epochs >= self.patience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7b96be",
   "metadata": {},
   "source": [
    "TODO: COMPLETAR detalles de esta funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ef2a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, device, epochs=40,\n",
    "          lr=5e-4, cont_loss_weight=50.0,\n",
    "          # par√°metros de early stopping\n",
    "          es_patience=6,\n",
    "          es_min_delta=0.0,\n",
    "          best_ckpt_path=\"OUTPUT/best_music_lstm.pth\",\n",
    "          verbose=True):\n",
    "\n",
    "    \"\"\" \n",
    "    Entrena el modelo con los datos de train_loader y val_loader.\n",
    "    Usa AdamW, CrossEntropy para pitch y MSE para continuos.\n",
    "    Guarda el mejor modelo seg√∫n la m√©trica val_total = val_CE + cont_loss_weight\n",
    "    history: diccionario con m√©tricas de entrenamiento y validaci√≥n.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    model.to(device)\n",
    "    opt = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    history = { \"train_loss\": [],\n",
    "                \"val_CE\": [],\n",
    "                \"val_MSE\": [],\n",
    "                \"val_total\": [],\n",
    "                \"best_epoch\": None,\n",
    "                \"best_val_total\": None,\n",
    "                \"best_ckpt_path\": best_ckpt_path}\n",
    "\n",
    "    # Inicializa EarlyStopping\n",
    "    es = EarlyStopping(patience=es_patience, min_delta=es_min_delta)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Entrenamiento\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        for (Xp, Xc), (yp, yc) in train_loader:\n",
    "            Xp = Xp.to(device)           \n",
    "            Xc = Xc.to(device)           \n",
    "            yp = yp.to(device)           \n",
    "            yc = yc.to(device)         \n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits, cont_pred = model(Xp, Xc)         # logits [B,L,V]; cont_pred [B,L,3]\n",
    "            # Usa directamente la salida del modelo\n",
    "            logits_last = logits               # (B, V)\n",
    "            cont_last   = cont_pred            # (B, 3)\n",
    "\n",
    "            ce  = F.cross_entropy(logits_last, yp, label_smoothing=0.05)    # CE para pitch\n",
    "            mse = F.smooth_l1_loss(cont_last, yc, beta=0.5)    #F.mse_loss(cont_last, yc)          # MSE para continuos (normalizados)\n",
    "            loss = ce + cont_loss_weight * mse\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "\n",
    "            running += loss.item()\n",
    "\n",
    "        train_loss = running / max(1, len(train_loader))\n",
    "\n",
    "        # Validaci√≥n\n",
    "        model.eval()\n",
    "        val_ce = 0.0\n",
    "        val_mse = 0.0\n",
    "        with torch.no_grad():\n",
    "            for (Xp, Xc), (yp, yc) in val_loader:\n",
    "                Xp = Xp.to(device)\n",
    "                Xc = Xc.to(device)\n",
    "                yp = yp.to(device)\n",
    "                yc = yc.to(device)\n",
    "\n",
    "                logits, cont_pred = model(Xp, Xc)\n",
    "                logits_last = logits          # (B, V)\n",
    "                cont_last   = cont_pred       # (B, 3)\n",
    "\n",
    "                ce  = F.cross_entropy(logits_last, yp, label_smoothing=0.05)\n",
    "                mse = F.mse_loss(cont_last, yc)\n",
    "                val_ce  += ce.item()\n",
    "                val_mse += mse.item()\n",
    "\n",
    "        val_ce  /= max(1, len(val_loader))\n",
    "        val_mse /= max(1, len(val_loader))\n",
    "       \n",
    "        val_total = val_ce + cont_loss_weight * val_mse\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_CE\"].append(val_ce)\n",
    "        history[\"val_MSE\"].append(val_mse)\n",
    "        history[\"val_total\"].append(val_total)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch} | train_loss={train_loss:.4f} | \"\n",
    "                  f\"val_CE={val_ce:.4f} | val_MSE={val_mse:.5f} | \"\n",
    "                  f\"val_total={val_total:.4f}\")\n",
    "\n",
    "        # Checkpoint si mejora\n",
    "        if es.step(val_total):\n",
    "            torch.save({\"model_state\": model.state_dict()}, best_ckpt_path)\n",
    "            history[\"best_epoch\"] = epoch\n",
    "            history[\"best_val_total\"] = val_total\n",
    "            if verbose:\n",
    "                print(f\"  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en {best_ckpt_path}\")\n",
    "\n",
    "        # Parar si no mejora por 'patience'\n",
    "        if es.should_stop():\n",
    "            if verbose:\n",
    "                print(f\"  ‚Ü≥ Early stopping en epoch {epoch} (best_epoch={history['best_epoch']})\")\n",
    "            break\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa4933f",
   "metadata": {},
   "source": [
    "## 4.2. Funciones para generar las nuevas notas musicales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaee046",
   "metadata": {},
   "source": [
    "`sample_from_logits_topk` elige la siguiente nota de forma probabilistica usando las salidas (logits) del modelo.\n",
    "La salida del modelo entrega una distribucion de probabilidades sobre todas las posibles notas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6479a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_logits_topk(logits, k=10, temperature=1.0):\n",
    "    \"\"\"\n",
    "    logits: torch.Tensor [vocab] o numpy.ndarray [vocab]\n",
    "    k: n√∫mero de top-k a considerar\n",
    "    temperature: float > 0, controla la aleatoriedad del muestreo\n",
    "    (temperature -> 0: m√°s determinista, temperature -> ‚àû: m√°s aleatorio)\n",
    "    Retorna:\n",
    "    √çndice entero muestreado en top-k (con temperatura).\n",
    "    Si logits es numpy.ndarray, se convierte a torch.Tensor.\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    if not isinstance(logits, torch.Tensor):\n",
    "        logits = torch.from_numpy(logits)\n",
    "\n",
    "    # Evita k inv√°lido\n",
    "    vocab = logits.shape[-1]\n",
    "    k = max(1, min(int(k), int(vocab)))\n",
    "\n",
    "    # √öltimo paso de la secuencia si viene con eje extra\n",
    "    # (p.ej., [1, V] -> [V])\n",
    "    if logits.ndim > 1:\n",
    "        logits = logits.view(-1)\n",
    "\n",
    "    # Temperatura\n",
    "    if temperature is None or temperature <= 0:\n",
    "        temperature = 1.0\n",
    "    logits = logits / float(temperature)\n",
    "\n",
    "    # Top-k + muestreo\n",
    "    topk_vals, topk_idx = torch.topk(logits, k)          \n",
    "    topk_probs = torch.softmax(topk_vals, dim=-1)        \n",
    "    choice = torch.multinomial(topk_probs, 1)            \n",
    "    return int(topk_idx[choice].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaea221",
   "metadata": {},
   "source": [
    "La siguiente funci√≥n permite generar nuevas notas paso a paso.\n",
    "TODO: completar m√°s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56059a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_sequence(model, device, seed_pitch_seq, seed_cont_seq, steps=200, \n",
    "                      idx2pitch=None, stats=None, temperature=1.0, top_k=10,\n",
    "                      max_context=32):\n",
    "    \"\"\"\n",
    "    Toma el modelo entrenado y una secuencia inicial (seed) de notas\n",
    "    (pitch_seq: np.ndarray [T_seed] de enteros; cont_seq: np\n",
    "    .ndarray [T_seed, 3] de continuos normalizados)\n",
    "    \n",
    "    Genera una secuencia de notas a partir de una secuencia inicial.\n",
    "    Devuelve: np.ndarray shape [T_gen, 4] con columnas [pitch, step, dur, vel]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Normalizaci√≥n defensiva de entradas\n",
    "    seed_pitch_seq = np.asarray(seed_pitch_seq, dtype=np.int64)          \n",
    "    seed_cont_seq  = np.asarray(seed_cont_seq,  dtype=np.float32)        \n",
    "    assert seed_cont_seq.ndim == 2 and seed_cont_seq.shape[1] == 3, \"seed_cont_seq debe ser [T,3]\"\n",
    "\n",
    "    # Construir tensores en el dispositivo sin listas de ndarrays:\n",
    "    def _mk_inputs(pitches_np, cont_np):\n",
    "        # recorta al contexto\n",
    "        pitches_np = pitches_np[-max_context:]\n",
    "        cont_np    = cont_np[-max_context:]\n",
    "        inp_pitch = torch.as_tensor(pitches_np, dtype=torch.long, device=device).unsqueeze(0)   # [1, L]\n",
    "        inp_cont  = torch.as_tensor(cont_np,    dtype=torch.float32, device=device).unsqueeze(0) # [1, L, 3]\n",
    "        return inp_pitch, inp_cont\n",
    "\n",
    "    # Copias de trabajo (para ir anexando)\n",
    "    cur_pitch = seed_pitch_seq.copy()\n",
    "    cur_cont  = seed_cont_seq.copy()\n",
    "\n",
    "    generated_rows = []  # acumularemos filas [pitch, step, dur, vel] \n",
    "\n",
    "    for _ in range(steps):\n",
    "        inp_pitch, inp_cont = _mk_inputs(cur_pitch, cur_cont)\n",
    "        logits, cont_pred = model(inp_pitch, inp_cont)  \n",
    "\n",
    "        # Tomar el √∫ltimo paso temporal\n",
    "        logits_last = logits.squeeze(0)                \n",
    "        cont_last   = cont_pred.squeeze(0).cpu().numpy() # (3,)  \n",
    "\n",
    "        # Muestreo discreto\n",
    "        next_pitch_idx = sample_from_logits_topk(logits_last, k=top_k, temperature=temperature)\n",
    "\n",
    "        # Desnormalizar los 3 continuos \n",
    "        if stats is not None:\n",
    "            step = (cont_last[0] * (float(stats[\"step_std\"]) + 1e-6)) + float(stats[\"step_mean\"])\n",
    "            dur  = (cont_last[1] * (float(stats[\"dur_std\"])  + 1e-6)) + float(stats[\"dur_mean\"])\n",
    "            vel  = (cont_last[2] * (float(stats[\"vel_std\"])  + 1e-6)) + float(stats[\"vel_mean\"])\n",
    "        else:\n",
    "            step, dur, vel = float(cont_last[0]), float(cont_last[1]), float(cont_last[2])\n",
    "\n",
    "        # Seguridad: valores v√°lidos\n",
    "        next_pitch = int(np.clip(next_pitch_idx, 0, 127))\n",
    "        step = max(0.0, float(step))\n",
    "        dur  = max(1e-3, float(dur))\n",
    "        vel  = float(np.clip(vel, 1.0, 127.0))\n",
    "\n",
    "        # Append a las listas de estado (en formato NORMALIZADO para el modelo)\n",
    "        # Nota: para la siguiente iteraci√≥n el modelo necesita los continuos NORMALIZADOS,\n",
    "        # por lo que guardamos adem√°s la versi√≥n normalizada:\n",
    "        if stats is not None:\n",
    "            step_n = (step - float(stats[\"step_mean\"])) / (float(stats[\"step_std\"]) + 1e-6)\n",
    "            dur_n  = (dur  - float(stats[\"dur_mean\"]))  / (float(stats[\"dur_std\"])  + 1e-6)\n",
    "            vel_n  = (vel  - float(stats[\"vel_mean\"]))  / (float(stats[\"vel_std\"])  + 1e-6)\n",
    "            cur_cont = np.vstack([cur_cont, [step_n, dur_n, vel_n]]).astype(np.float32)\n",
    "        else:\n",
    "            cur_cont = np.vstack([cur_cont, [step, dur, vel]]).astype(np.float32)\n",
    "\n",
    "        cur_pitch = np.append(cur_pitch, next_pitch).astype(np.int64)\n",
    "\n",
    "        # Guardar fila desnormalizada para el MIDI\n",
    "        generated_rows.append([next_pitch, step, dur, vel])\n",
    "\n",
    "    return np.asarray(generated_rows, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685b2bc2",
   "metadata": {},
   "source": [
    "# 5. Definici√≥n de _main_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab1aa425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Extrayendo secuencias crudas...\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=4225\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=3300\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2954\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2173\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3868\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2580\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3185\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2792\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2854\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=3395\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1850\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=885\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3239\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=3186\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2970\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1822\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2592\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2073\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1779\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2002\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2191\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1494\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2027\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1588\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=5268\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=5465\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=1374\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=917\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=1705\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=1443\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=3118\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=2461\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2418\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2555\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2150\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=993\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2050\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=551\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3267\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2449\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1447\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1200\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=872\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=781\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=563\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=495\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1515\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1135\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1372\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=952\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1088\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=900\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2673\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2480\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=806\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=509\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1721\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1673\n",
      "  secuencias extra√≠das: 25\n",
      "2. Estandarizando variables continuas ...\n",
      "  stats: {'step_mean': 0.098957, 'step_std': 0.18229377, 'dur_mean': 0.33029, 'dur_std': 0.41488776, 'vel_mean': 48.245155, 'vel_std': 17.51278}\n",
      "3. Creando ventanas...\n",
      "  Train -> Xp_tr: (76482, 32) Xc_tr: (76482, 32, 3) yp_tr: (76482,)\n",
      "  Valid -> Xp_va: (22357, 32) Xc_va: (22357, 32, 3) yp_va: (22357,)\n",
      "vocab_size: 128\n",
      "4. Preparando DataLoaders...\n",
      "5. Construyendo y entrenando el modelo...\n",
      "   Training model on device: cuda\n",
      "Epoch 1 | train_loss=9.1252 | val_CE=3.6348 | val_MSE=0.38678 | val_total=11.3705\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT2/best_music_lstm.pth\n",
      "Epoch 2 | train_loss=7.8668 | val_CE=3.5697 | val_MSE=0.36497 | val_total=10.8691\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT2/best_music_lstm.pth\n",
      "Epoch 3 | train_loss=7.2399 | val_CE=3.5021 | val_MSE=0.35425 | val_total=10.5870\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT2/best_music_lstm.pth\n",
      "Epoch 4 | train_loss=6.7260 | val_CE=3.4959 | val_MSE=0.35074 | val_total=10.5106\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT2/best_music_lstm.pth\n",
      "Epoch 5 | train_loss=6.2699 | val_CE=3.4687 | val_MSE=0.34682 | val_total=10.4052\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT2/best_music_lstm.pth\n",
      "Epoch 6 | train_loss=5.8486 | val_CE=3.4629 | val_MSE=0.35236 | val_total=10.5100\n",
      "Epoch 7 | train_loss=5.4846 | val_CE=3.4644 | val_MSE=0.34674 | val_total=10.3993\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT2/best_music_lstm.pth\n",
      "Epoch 8 | train_loss=5.1661 | val_CE=3.4987 | val_MSE=0.35151 | val_total=10.5290\n",
      "Epoch 9 | train_loss=4.8664 | val_CE=3.5496 | val_MSE=0.35591 | val_total=10.6677\n",
      "Epoch 10 | train_loss=4.5977 | val_CE=3.5945 | val_MSE=0.35894 | val_total=10.7734\n",
      "Epoch 11 | train_loss=4.3853 | val_CE=3.6313 | val_MSE=0.35295 | val_total=10.6903\n",
      "Epoch 12 | train_loss=4.1677 | val_CE=3.6519 | val_MSE=0.34919 | val_total=10.6356\n",
      "Epoch 13 | train_loss=3.9767 | val_CE=3.7010 | val_MSE=0.36598 | val_total=11.0205\n",
      "Epoch 14 | train_loss=3.8138 | val_CE=3.7270 | val_MSE=0.35635 | val_total=10.8540\n",
      "Epoch 15 | train_loss=3.6556 | val_CE=3.8009 | val_MSE=0.36248 | val_total=11.0506\n",
      "  ‚Ü≥ Early stopping en epoch 15 (best_epoch=7)\n",
      "6. Generando ejemplos...\n",
      "[Gen 1] Usando semilla index: 33948\n",
      "MIDI guardado en: OUTPUT2/generated_music_lstm_1.mid (Acoustic Grand Piano)\n",
      "[Gen 1] MIDI guardado en: OUTPUT2\\generated_music_lstm_1.mid\n",
      "[Gen 2] Usando semilla index: 38110\n",
      "MIDI guardado en: OUTPUT2/generated_music_lstm_2.mid (Acoustic Grand Piano)\n",
      "[Gen 2] MIDI guardado en: OUTPUT2\\generated_music_lstm_2.mid\n",
      "[Gen 3] Usando semilla index: 24343\n",
      "MIDI guardado en: OUTPUT2/generated_music_lstm_3.mid (Acoustic Grand Piano)\n",
      "[Gen 3] MIDI guardado en: OUTPUT2\\generated_music_lstm_3.mid\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"1. Extrayendo secuencias crudas...\")\n",
    "    raw_sequences = extract_raw_note_sequences(ROOT_DIR, instrument_name= INSTRUMENT_NAME, composer_name=COMPOSER)\n",
    "    print(f\"  secuencias extra√≠das: {len(raw_sequences)}\")\n",
    "\n",
    "    train_sequences, val_sequences = train_test_split(raw_sequences, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "    print(\"2. Estandarizando variables continuas ...\")\n",
    "    standardized_sequences, stats = standardize_note_sequences(train_sequences)\n",
    "    print(\"  stats:\", stats)\n",
    "\n",
    "    def apply_standardization(seqs, stats):\n",
    "        out = []\n",
    "        for seq in seqs:\n",
    "            s = seq.copy()\n",
    "            s[:,1] = (s[:,1]-stats[\"step_mean\"])/(stats[\"step_std\"]+1e-6)\n",
    "            s[:,2] = (s[:,2]-stats[\"dur_mean\"] )/(stats[\"dur_std\"] +1e-6)\n",
    "            s[:,3] = (s[:,3]-stats[\"vel_mean\"] )/(stats[\"vel_std\"] +1e-6)\n",
    "            out.append(s)\n",
    "        return out\n",
    "\n",
    "    val_standardized = apply_standardization(val_sequences, stats)\n",
    "\n",
    "    print(\"3. Creando ventanas...\")\n",
    "    (Xp_tr, Xc_tr), (yp_tr, yc_tr) = create_windows(standardized_sequences, seq_len=SEQ_LEN)\n",
    "    (Xp_va, Xc_va), (yp_va, yc_va) = create_windows(val_standardized,       seq_len=SEQ_LEN)\n",
    "\n",
    "    print(\"  Train -> Xp_tr:\", Xp_tr.shape, \"Xc_tr:\", Xc_tr.shape, \"yp_tr:\", yp_tr.shape)\n",
    "    print(\"  Valid -> Xp_va:\", Xp_va.shape, \"Xc_va:\", Xc_va.shape, \"yp_va:\", yp_va.shape)\n",
    "\n",
    "\n",
    "    # construir vocab (opcional\n",
    "    if Xp_tr.shape[0] == 0:\n",
    "        raise RuntimeError(\"No hay muestras. Aumenta datos o reduce SEQ_LEN.\")\n",
    "    max_pitch = int(np.max(Xp_tr))\n",
    "    vocab_size = max(128, max_pitch + 1)\n",
    "    print(\"vocab_size:\", vocab_size)\n",
    "\n",
    "    # Dataset de PyTorch\n",
    "    print(\"4. Preparando DataLoaders...\")\n",
    "    train_ds = MusicWindowsDataset(Xp_tr, Xc_tr, yp_tr, yc_tr)\n",
    "    val_ds   = MusicWindowsDataset(Xp_va,   Xc_va,   yp_va,   yc_va)\n",
    "    loader   = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "    vloader  = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "    # Modelo y entrenamiento\n",
    "    print(\"5. Construyendo y entrenando el modelo...\")\n",
    "    model = MusicLSTM(vocab_size=vocab_size, emb_dim=EMB_DIM, cont_dim=3, hidden_size= HIDDEN_SIZE, num_layers= NUM_LAYERS,dropout=DROPOUT) # Ajustado num_layers\n",
    "    print(\"   Training model on device:\", DEVICE)\n",
    "    history = train(\n",
    "        model,\n",
    "        train_loader=loader,\n",
    "        val_loader=vloader,\n",
    "        device=DEVICE,\n",
    "        epochs=EPOCHS,\n",
    "        lr=LR,\n",
    "        cont_loss_weight= PESO_LOSS_CONT,\n",
    "        es_patience= PATIENCE,                \n",
    "        es_min_delta= MIN_DELTA,           \n",
    "        best_ckpt_path=(OUTPUT_DIR / \"best_music_lstm.pth\").as_posix(),\n",
    "    )\n",
    "\n",
    "    # Guardar modelo y stats\n",
    "    # Cargar mejor estado antes de generar\n",
    "    best_ckpt = torch.load((OUTPUT_DIR / \"best_music_lstm.pth\").as_posix(), map_location=DEVICE)\n",
    "    model.load_state_dict(best_ckpt[\"model_state\"])\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    #  Generaci√≥n de ejemplos\n",
    "    print(\"6. Generando ejemplos...\")\n",
    "    total_samples = Xp_tr.shape[0]\n",
    "   \n",
    "    # Elegimos √≠ndices de semillas distintos si hay suficientes, o con reposici√≥n si no\n",
    "    idx_pool = list(range(total_samples))\n",
    "    if total_samples >= NUM_SEQS:\n",
    "        seed_indices = random.sample(idx_pool, NUM_SEQS)  # sin reemplazo\n",
    "    else:\n",
    "        seed_indices = [random.choice(idx_pool) for _ in range(NUM_SEQS)]  # con reemplazo\n",
    "    \n",
    "    for j, idx in enumerate(seed_indices, start=1):\n",
    "        seed_pitch = Xp_tr[idx].tolist()\n",
    "        seed_cont  = Xc_tr[idx]\n",
    "        print(f\"[Gen {j}] Usando semilla index: {idx}\")\n",
    "    \n",
    "        generated = generate_sequence(\n",
    "            model, DEVICE,\n",
    "            seed_pitch, seed_cont,\n",
    "            steps=STEPS_PER_SEQ,\n",
    "            idx2pitch=None,\n",
    "            stats=stats,\n",
    "            temperature=TEMPERATURE,\n",
    "            top_k=TOP_K)\n",
    "        \n",
    "        if generated.shape[0] > 200:\n",
    "          generated = generated[-200:, :]\n",
    "\n",
    "        # TODO: Alerta / diagrama / histograma de distribuci√≥n\n",
    "        midi_path = OUTPUT_DIR / f\"generated_music_lstm_{j}.mid\"\n",
    "        save_sequence_to_midi(generated, output_path=midi_path.as_posix(), instrument_name=INSTRUMENT_NAME)\n",
    "        print(f\"[Gen {j}] MIDI guardado en: {midi_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9146687c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo: 1 minutos y 41.67 segundos\n"
     ]
    }
   ],
   "source": [
    "fin = time.time()\n",
    "print_time_execution(inicio, fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38aef6f",
   "metadata": {},
   "source": [
    "# 6. Conversi√≥n archivos .mid a .wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f15924",
   "metadata": {},
   "source": [
    "Cargar DLLs externas.\n",
    "TODO: explicar como se realiza la instalacion de FluidSynth en windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4f028f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CDLL 'C:\\Tools\\FluidSynth\\bin\\libfluidsynth-3.dll', handle 7ffbb3900000 at 0x2c128f81310>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Bootstrap FluidSynth (Windows, persistente por sesi√≥n de kernel) ---\n",
    "import os\n",
    "if os.name == \"nt\":\n",
    "    DLL_DIR = r\"C:\\Tools\\FluidSynth\\bin\"  # carpeta donde pusiste libfluidsynth-3.dll\n",
    "    if hasattr(os, \"add_dll_directory\"):\n",
    "        os.add_dll_directory(DLL_DIR)\n",
    "    os.environ[\"FLUIDSYNTH_LIBRARY\"] = os.path.join(DLL_DIR, \"libfluidsynth-3.dll\")\n",
    "\n",
    "# (opcional) smoke test de la DLL para fallar pronto si algo cambi√≥\n",
    "from ctypes import CDLL\n",
    "CDLL(os.environ[\"FLUIDSYNTH_LIBRARY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96d5c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_midi_to_wav(midi_path: str, wav_path: str, sf2_path: str, samplerate: int = 44100):\n",
    "\n",
    "    fs = pyfluidsynth.Synth(samplerate=samplerate)\n",
    "    try:\n",
    "        fs.start(driver=\"dsound\" if os.name == \"nt\" else \"alsa\")\n",
    "    except Exception:\n",
    "        fs.start()  # fallback gen√©rico\n",
    "\n",
    "    sfid = fs.sfload(sf2_path)\n",
    "    fs.program_select(0, sfid, 0, 0)\n",
    "\n",
    "    pm = pretty_midi.PrettyMIDI(midi_path)\n",
    "\n",
    "    # Renderizamos manualmente los eventos del track 0\n",
    "    # (PrettyMIDI puede reproducir directo, pero aqu√≠ controlamos la cadena)\n",
    "    audio = pm.fluidsynth(fs=samplerate, sf2_path=sf2_path)  # interfaz estable\n",
    "    # Normalizaci√≥n suave y a PCM16\n",
    "    peak = float(np.max(np.abs(audio))) if audio.size else 1.0\n",
    "    audio = (audio / (peak if peak > 0 else 1.0)) * 0.99\n",
    "    audio_int16 = (np.clip(audio, -1, 1) * 32767).astype(np.int16)\n",
    "    write(wav_path, samplerate, audio_int16)\n",
    "    fs.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59dc6034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7. Renderizando archivos MIDI a WAV...\n",
      "Renderizando OUTPUT2\\generated_music_lstm_1.mid a OUTPUT2\\generated_music_lstm_1.wav ...\n",
      "Renderizando OUTPUT2\\generated_music_lstm_2.mid a OUTPUT2\\generated_music_lstm_2.wav ...\n",
      "Renderizando OUTPUT2\\generated_music_lstm_3.mid a OUTPUT2\\generated_music_lstm_3.wav ...\n",
      "Tiempo: 0.53 segundos\n"
     ]
    }
   ],
   "source": [
    "# Leer la carpeta OUTPUT y renderizar cada MIDI a WAV\n",
    "inicio = time.time()\n",
    "print(\"7. Renderizando archivos MIDI a WAV...\")\n",
    "midi_files = glob.glob(os.path.join(OUTPUT_DIR.as_posix(), \"generated_music_lstm_*.mid\"))\n",
    "\n",
    "j = 1\n",
    "for midi_file in midi_files:\n",
    "    wav_file = OUTPUT_DIR / f\"generated_music_lstm_{j}.wav\"\n",
    "    #wav_file = midi_file.replace(\".mid\", \".wav\")\n",
    "    print(f\"Renderizando {midi_file} a {wav_file} ...\")\n",
    "    render_midi_to_wav(midi_file, wav_file, SF2, samplerate=44100)\n",
    "    j += 1\n",
    "\n",
    "fin = time.time()\n",
    "print_time_execution(inicio, fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13995d07",
   "metadata": {},
   "source": [
    "# Celda usada Font de los Markdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca98c8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- Fuentes recomendadas para estilo matem√°tico -->\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=STIX+Two+Text:ital,wght@0,400;0,700;1,400;1,700&display=swap\" rel=\"stylesheet\">\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=STIX+Two+Math:ital,wght@0,400;0,700;1,400;1,700&display=swap\" rel=\"stylesheet\">\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&display=swap\" rel=\"stylesheet\">\n",
       "\n",
       "<style>\n",
       "  /* --- Markdown cl√°sico (Notebook) --- */\n",
       "  div.text_cell_render.rendered_html p,\n",
       "  div.text_cell_render.rendered_html h1,\n",
       "  div.text_cell_render.rendered_html h2,\n",
       "  div.text_cell_render.rendered_html h3,\n",
       "  div.text_cell_render.rendered_html li {\n",
       "    font-family: 'STIX Two Text', serif !important;\n",
       "  }\n",
       "\n",
       "  /* MathJax (f√≥rmulas) */\n",
       "  .MathJax, .MathJax_Display {\n",
       "    font-family: 'STIX Two Math', serif !important;\n",
       "  }\n",
       "\n",
       "  /* C√≥digo */\n",
       "  div.text_cell_render.rendered_html code,\n",
       "  div.text_cell_render.rendered_html pre {\n",
       "    font-family: 'Inconsolata', monospace !important;\n",
       "  }\n",
       "\n",
       "  /* --- JupyterLab --- */\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon p,\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon h1,\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon h2,\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon h3,\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon li {\n",
       "    font-family: 'STIX Two Text', serif !important;\n",
       "  }\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon code,\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon pre {\n",
       "    font-family: 'Inconsolata', monospace !important;\n",
       "  }\n",
       "  .jp-Notebook .MathJax,\n",
       "  .jp-Notebook .MathJax_Display {\n",
       "    font-family: 'STIX Two Math', serif !important;\n",
       "  }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<!-- Fuentes recomendadas para estilo matem√°tico -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=STIX+Two+Text:ital,wght@0,400;0,700;1,400;1,700&display=swap\" rel=\"stylesheet\">\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=STIX+Two+Math:ital,wght@0,400;0,700;1,400;1,700&display=swap\" rel=\"stylesheet\">\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "<style>\n",
    "  /* --- Markdown cl√°sico (Notebook) --- */\n",
    "  div.text_cell_render.rendered_html p,\n",
    "  div.text_cell_render.rendered_html h1,\n",
    "  div.text_cell_render.rendered_html h2,\n",
    "  div.text_cell_render.rendered_html h3,\n",
    "  div.text_cell_render.rendered_html li {\n",
    "    font-family: 'STIX Two Text', serif !important;\n",
    "  }\n",
    "\n",
    "  /* MathJax (f√≥rmulas) */\n",
    "  .MathJax, .MathJax_Display {\n",
    "    font-family: 'STIX Two Math', serif !important;\n",
    "  }\n",
    "\n",
    "  /* C√≥digo */\n",
    "  div.text_cell_render.rendered_html code,\n",
    "  div.text_cell_render.rendered_html pre {\n",
    "    font-family: 'Inconsolata', monospace !important;\n",
    "  }\n",
    "\n",
    "  /* --- JupyterLab --- */\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon p,\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon h1,\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon h2,\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon h3,\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon li {\n",
    "    font-family: 'STIX Two Text', serif !important;\n",
    "  }\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon code,\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon pre {\n",
    "    font-family: 'Inconsolata', monospace !important;\n",
    "  }\n",
    "  .jp-Notebook .MathJax,\n",
    "  .jp-Notebook .MathJax_Display {\n",
    "    font-family: 'STIX Two Math', serif !important;\n",
    "  }\n",
    "</style>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_312_CUDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
