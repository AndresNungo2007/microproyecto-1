{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Universidad_de_los_Andes_30.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# **Microproyecto 1**\n",
    "\n",
    "## Descripci√≥n del problema:\n",
    "\n",
    "El problema a resolver consiste en generar nuevas secuencias de notas musicales basadas en el estilo de los artistas existentes, mencionados en la r√∫brica del taller haciendo uso de archivos .mid como fuente de datos esto con el fin de entrenar un modelo que sea capaz de aprender de las diferentes caracter√≠sticas y posteriormente producir nuevas composiciones donde mantenga coherencia musical.\n",
    "\n",
    "## Objetivo:\n",
    "\n",
    "Con esta actividad se busca que el estudiante pueda poner en pr√°ctica el uso de modelos de redes neuronales para trabajar con datos secuenciales. Tras realizar esta actividad se espera que el estudiante est√© en capacidad de:\n",
    "1. Estructurar datos secuenciales de forma que pueden ser usados por modelos de redes neuronales.\n",
    "2. Desarrollar soluciones de machine learning para datos secuenciales en distintos dominios.\n",
    "3. Entrenar modelos de machine learning con m√∫ltiples salidas.\n",
    "4. Entrenar modelos de machine learning con una funci√≥n de costo compuesta.\n",
    "5. Utilizar el modelo entrenado para generar nuevas secuencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Integrantes Equipo 20\n",
    "- Andr√©s Felipe √ëungo Fern√°ndez\n",
    "- Andr√©s Juli√°n Gonzalez Barrera\n",
    "- Hernando Jose Jimenez D√≠az\n",
    "- Gloria In√©s L√≥pez Urbano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# √çndice\n",
    "\n",
    "El *notebook* aborda el microproyecto con la siguiente estructura:\n",
    "\n",
    "| üîπ | Secci√≥n        |\n",
    "|----|----------------|\n",
    "| 1Ô∏è.   | Instalaci√≥n e importe de librer√≠as |\n",
    "| 1Ô∏è.1Ô∏è  | Importar librer√≠as |\n",
    "| 1Ô∏è.2Ô∏è. | Definici√≥n variables globales |\n",
    "| 2Ô∏è.   | Carga y procesamiento de los datos       |\n",
    "| 2Ô∏è.1Ô∏è. | Extracci√≥n caracter√≠sticas de los archivos .mid       |\n",
    "| 2Ô∏è.2Ô∏è. | Estandarizar variables cuantitativas       |\n",
    "| 2Ô∏è.3Ô∏è. | Generar secuencias de entrenamiento _requeridas para LSTM_       |\n",
    "| 2Ô∏è.4Ô∏è. | Funci√≥n Guardar secuencias a MIDI       |\n",
    "| 3Ô∏è. | **Definici√≥n de *pipelines* de procesamiento y modelamiento**          |\n",
    "| 3Ô∏è.1Ô∏è. | **Definici√≥n de funciones y grillas**   |\n",
    "| 4Ô∏è. | **Desarrollo del modelo**   |\n",
    "| 4Ô∏è.1Ô∏è. | **B√∫squeda de hiperpar√°metros**   |\n",
    "| 4Ô∏è.2Ô∏è. | **Funciones para re-entrenamiento**   |\n",
    "| 4Ô∏è.3Ô∏è. | **Definici√≥n de _main_**   |\n",
    "| 5Ô∏è. | **An√°lisis de resultados y discusi√≥n**   |\n",
    "| 6Ô∏è. | **Conclusi√≥n**   |\n",
    "| 7Ô∏è. | **Referencias**   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalaci√≥n e importe de librer√≠as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versi√≥n usada de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la ejecuci√≥n de este Notebook, se recomienda realizar instalaci√≥n de las librer√≠as mencionadas a continuaci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IW1eQD90BIgG",
    "outputId": "e262966a-1613-46c1-ecd9-f57aa3bb2d5d"
   },
   "outputs": [],
   "source": [
    "#!pip install torch\n",
    "#!pip install pretty_midi\n",
    "#!pip install mido\n",
    "#!pip install pyFluidSynth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar DLLs externas.\n",
    "TODO: explicar como se realiza la instalacion de FluidSynth en windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CDLL 'C:\\msys64\\mingw64\\bin\\libfluidsynth-3.dll', handle 7ff938490000 at 0x1f263ed1c10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bootstrap FluidSynth \n",
    "import os\n",
    "if os.name == \"nt\" and hasattr(os, \"add_dll_directory\"):\n",
    "    candidates = [\n",
    "        r\"C:\\msys64\\mingw64\\bin\",\n",
    "        r\"C:\\Program Files\\FluidSynth\\bin\",\n",
    "        r\"C:\\Tools\\FluidSynth\\bin\",\n",
    "    ]\n",
    "    for dll_dir in candidates:\n",
    "        if os.path.exists(dll_dir):\n",
    "            os.add_dll_directory(dll_dir)\n",
    "            os.environ.setdefault(\"FLUIDSYNTH_LIBRARY\", os.path.join(dll_dir, \"libfluidsynth-3.dll\"))\n",
    "            break\n",
    "\n",
    "# Smoke test de la DLL para fallar pronto si algo cambi√≥\n",
    "from ctypes import CDLL\n",
    "CDLL(os.environ[\"FLUIDSYNTH_LIBRARY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WY-yhu2NgFf6"
   },
   "source": [
    "## 1.1 Importar librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_J3PzSeYEF4S"
   },
   "outputs": [],
   "source": [
    "# Importaci√≥n de librer√≠as del sistema\n",
    "import sys, glob\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "from importlib.metadata import version\n",
    "\n",
    "# Gesti√≥n de archivos\n",
    "from scipy.io.wavfile import write\n",
    "from pathlib import Path\n",
    "\n",
    "# Importaci√≥n de librer√≠a de DL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Dataloader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Separaci√≥n de datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Librer√≠as para MIDI y audio\n",
    "import fluidsynth as pyfluidsynth\n",
    "import pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy :  1.26.4\n",
      "pandas :  2.3.2\n",
      "scikit-learn :  1.7.2\n",
      "matplotlib :  3.10.6\n",
      "joblib :  1.5.1\n"
     ]
    }
   ],
   "source": [
    "# Ignorar las warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Versiones utilizadas\n",
    "librerias = [\"numpy\",\n",
    "            \"pandas\",\n",
    "            \"scikit-learn\",\n",
    "            \"matplotlib\",\n",
    "            \"joblib\"]\n",
    "for library in librerias:\n",
    "  print(library, \": \", version(library))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPTN5Y8YgIjn"
   },
   "source": [
    "## 1.2 Definici√≥n variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BU-R44U_GJ3O"
   },
   "outputs": [],
   "source": [
    "#Rutas\n",
    "ROOT_DIR =  \"./Dataset/music_artist\"  # \"/content/drive/MyDrive/Colab Notebooks/Dataset/TEST\"  Carpetas de compositores\n",
    "OUTPUT_DIR = Path(\"./OUTPUT\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SF2 = \"./soundfonts/FluidR3_GM.sf2\"  # Ruta soundfont\n",
    "\n",
    "# Par√°metros de lotes de entrenmaiento\n",
    "SEQ_LEN = 32 # Block size\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 40\n",
    "LR = 3e-4\n",
    "PESO_LOSS_CONT = 25\n",
    "\n",
    "# P√°rametros redes\n",
    "HIDDEN_SIZE = 384\n",
    "NUM_LAYERS = 4\n",
    "DROPOUT = 0.3\n",
    "PATIENCE = 10\n",
    "MIN_DELTA = 1e-3\n",
    "\n",
    "MODEL_TYPE = \"LSTM\"  # opciones: \"RNN\", \"LSTM\", \"GRU\"\n",
    "INSTRUMENT_NAME = \"Acoustic Grand Piano\"\n",
    "COMPOSER = \"schubert\"  # este es el artista que tiene m√°s datos\n",
    "\n",
    "# Par√°metros de generaci√≥n de secuencias\n",
    "NUM_SEQS       = 3  # N√∫mero de secuencias a generar\n",
    "STEPS_PER_SEQ  = 200  # Notas que debe tener cada secuencia\n",
    "TEMPERATURE    = 0.6  # Temperatura\n",
    "TOP_K = 10  # Metodolog√≠a para delimitar el dominio de notas a elegir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Definici√≥n de semillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 13\n",
    "random.seed(RANDOM_STATE); np.random.seed(RANDOM_STATE); torch.manual_seed(RANDOM_STATE)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(RANDOM_STATE)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "beKjgq-gGSI6",
    "outputId": "764903b1-722b-490c-d606-c5f8b7d8f6ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFgUa-JNgPMd"
   },
   "source": [
    "# 2. Carga y procesamiento de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJrvj5YdhVoo"
   },
   "source": [
    "## 2.1. Extracci√≥n caracter√≠sticas de los archivos .mid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta secci√≥n se realiza la selecci√≥n del primer instrumento encontrado y extracci√≥n notas del instrumento seleccionado. Como resultado se extraen las siguientes caracter√≠sticas por cada nota le√≠da:   \n",
    "- Pitch: representa la nota musical.\n",
    "- Step: es el espacio de tiempo que hay entre la nota anterior y la nota actual.\n",
    "- Duraction: Es la diferencia de tiempo en el que termina la nota actual (end) menos el inicio de la nota (start).\n",
    "- Velocity: es la velocidad de la nota musical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_raw_note_sequences(root_dir, instrument_name=None, program_number=None, composer_name=None):\n",
    "    raw_sequences = []\n",
    "    candidates = [composer_name] if composer_name else [ d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "    for composer in candidates:\n",
    "        folder = os.path.join(root_dir, composer)\n",
    "        midi_files = glob.glob(os.path.join(folder, \"*.mid\"))\n",
    "\n",
    "        for mf in midi_files:\n",
    "            try:\n",
    "                pm = pretty_midi.PrettyMIDI(mf)\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo leer {mf}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Selecci√≥n instrumento\n",
    "            chosen_instruments = []\n",
    "            for i, inst in enumerate(pm.instruments):\n",
    "                name = pretty_midi.program_to_instrument_name(inst.program)\n",
    "                print(f\"[{i}] prog={inst.program:>2} name={name} notas={len(inst.notes)}\")\n",
    "                if instrument_name is not None:\n",
    "                    inst_name = pretty_midi.program_to_instrument_name(inst.program)\n",
    "                    if inst_name.lower() == instrument_name.lower():\n",
    "                        chosen_instruments.append(inst)\n",
    "                elif program_number is not None:\n",
    "                    if inst.program == program_number:\n",
    "                        chosen_instruments.append(inst)\n",
    "\n",
    "            # Si no hubo match expl√≠cito y no se especific√≥ filtro, tomamos el primero (comportamiento viejo)\n",
    "            if instrument_name is None and program_number is None:\n",
    "                chosen_instruments = pm.instruments[:1]  \n",
    "\n",
    "            if not chosen_instruments:\n",
    "                # Nada que extraer en este archivo para el instrumento pedido\n",
    "                continue\n",
    "\n",
    "            # Extraer notas SOLO del/los instrumentos elegidos \n",
    "            notes = []\n",
    "            for inst in chosen_instruments:\n",
    "                for note_mus in inst.notes:\n",
    "                    start = note_mus.start\n",
    "                    end = note_mus.end\n",
    "                    duration = end - start\n",
    "                    velocity = note_mus.velocity\n",
    "                    notes.append((start, note_mus.pitch, duration, velocity))\n",
    "\n",
    "            if not notes:\n",
    "                continue\n",
    "\n",
    "            # Ordenar por inicio y construir [pitch, step, duration, velocity]\n",
    "            notes.sort(key=lambda x: x[0])\n",
    "            note_feats = []\n",
    "            prev_start = notes[0][0]\n",
    "            for start, pitch, duration, velocity in notes:\n",
    "                step = start - prev_start\n",
    "                prev_start = start\n",
    "                note_feats.append([pitch, step, duration, velocity])\n",
    "\n",
    "            if note_feats:\n",
    "                raw_sequences.append(np.array(note_feats, dtype=np.float32))\n",
    "\n",
    "    return raw_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C04D1njqhYFn"
   },
   "source": [
    "## 2.2. Estandarizar variables cuantitativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este paso es necesario dado que los modelos de red neuronal son muy sensibles a las escalas de los datos. Al no estandarizar las variables continuas, el modelo no aprender√° correctamente las relaciones entre variables.\n",
    "La presente estandarizaci√≥n lleva todas las variables continuas a extraer el promedio y la desviaci√≥n estandar normalizando cada valor individual, siguiendo la f√≥rmula del z-score:\n",
    "`norm_x = (x - mean) / std`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Jv0A8oHWKEne"
   },
   "outputs": [],
   "source": [
    "def standardize_note_sequences(sequences):\n",
    "    \"\"\"\n",
    "    Estandariza las variables continuas (step, duration, velocity)\n",
    "    y mantiene el pitch intacto para usarlo luego con embeddings.\n",
    "    \"\"\"\n",
    "    all_steps, all_durations, all_velocities = [], [], []\n",
    "\n",
    "    # Recolectar todas las variables continuas para calcular media y std global\n",
    "    for seq in sequences:\n",
    "        all_steps.extend(seq[:, 1])\n",
    "        all_durations.extend(seq[:, 2])\n",
    "        all_velocities.extend(seq[:, 3])\n",
    "\n",
    "    # Estad√≠sticas globales\n",
    "    step_mean, step_std = np.mean(all_steps), np.std(all_steps)\n",
    "    dur_mean, dur_std = np.mean(all_durations), np.std(all_durations)\n",
    "    vel_mean, vel_std = np.mean(all_velocities), np.std(all_velocities)\n",
    "\n",
    "    standardized = []\n",
    "    for seq in sequences:\n",
    "        seq_std = seq.copy()\n",
    "        # No tocar pitch (columna 0)\n",
    "        seq_std[:, 1] = (seq[:, 1] - step_mean) / (step_std + 1e-6)\n",
    "        seq_std[:, 2] = (seq[:, 2] - dur_mean) / (dur_std + 1e-6)\n",
    "        seq_std[:, 3] = (seq[:, 3] - vel_mean) / (vel_std + 1e-6)\n",
    "        standardized.append(seq_std)\n",
    "\n",
    "    stats = {\"step_mean\": step_mean, \"step_std\": step_std,\n",
    "            \"dur_mean\": dur_mean, \"dur_std\": dur_std,\n",
    "            \"vel_mean\": vel_mean, \"vel_std\": vel_std}\n",
    "\n",
    "    return standardized, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1n9XyNyhcej"
   },
   "source": [
    "## 2.3. Generar secuencias de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta secci√≥n realiza la conversi√≥n de una secuencia larga de notas en muestras peque√±as de longitud fija llamadas ventanas o secuencias de entrenamiento.\n",
    "La entrada de datos debe tener estandarizadas las variables continuas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VWsFUkyhS404"
   },
   "outputs": [],
   "source": [
    "def create_windows(sequences, seq_len=32):\n",
    "    \"\"\"\n",
    "    Crea pares (X, y) para entrenamiento a partir de las secuencias estandarizadas.\n",
    "    X: secuencia de longitud seq_len\n",
    "    y: la nota siguiente\n",
    "    La variable pitch se mantiene intacto dado que es una variable categ√≥rica que se usar√° con embeddings.\n",
    "    \"\"\"\n",
    "    X_pitch, X_cont, y_pitch, y_cont = [], [], [], []\n",
    "\n",
    "    for seq in sequences:\n",
    "        if len(seq) < seq_len + 1:\n",
    "            continue\n",
    "\n",
    "        # Dividir en ventanas\n",
    "        for i in range(len(seq) - seq_len):\n",
    "            window = seq[i:i+seq_len]\n",
    "            target = seq[i+seq_len]\n",
    "\n",
    "            # Separar pitch (entero) y las features continuas\n",
    "            X_pitch.append(window[:, 0].astype(np.int64))     # pitch\n",
    "            X_cont.append(window[:, 1:].astype(np.float32))   # step, duration, velocity\n",
    "            y_pitch.append(int(target[0]))                    # pitch de la siguiente nota\n",
    "            y_cont.append(target[1:].astype(np.float32))      # step, duration, velocity siguientes\n",
    "\n",
    "    # Convertir a arrays numpy\n",
    "    X_pitch = np.array(X_pitch, dtype=np.int64)\n",
    "    X_cont = np.array(X_cont, dtype=np.float32)\n",
    "    y_pitch = np.array(y_pitch, dtype=np.int64)\n",
    "    y_cont = np.array(y_cont, dtype=np.float32)\n",
    "\n",
    "    return (X_pitch, X_cont), (y_pitch, y_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vH4IXLREhjSW"
   },
   "source": [
    "## 2.4. Funci√≥n Guardar secuencias a MIDI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funci√≥n `save_sequence_to_midi` permite tomar las secuencias estandarizadas y generar de nuevo el archivo .mid con el fin de validar que no se haya corrompido las notas musicales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kkQMkq6idGIz"
   },
   "outputs": [],
   "source": [
    "def save_sequence_to_midi(seq, output_path=\"generated.mid\", instrument_name=\"Acoustic Grand Piano\"):\n",
    "    \"\"\"\n",
    "    seq: np.array (N,4) con columnas [pitch, step, duration, velocity] en ESCALA REAL.\n",
    "    \"\"\"\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    try:\n",
    "        program_number = pretty_midi.instrument_name_to_program(instrument_name)\n",
    "    except ValueError:\n",
    "        program_number = 0\n",
    "    instrument = pretty_midi.Instrument(program=program_number)\n",
    "\n",
    "    # Asegurar valores v√°lidos\n",
    "    pitch    = seq[:, 0].astype(int)\n",
    "    step     = np.maximum(seq[:, 1].astype(float), 0.0)\n",
    "    duration = np.maximum(seq[:, 2].astype(float), 0.01)\n",
    "    velocity = np.clip(seq[:, 3].astype(float), 0, 127).astype(int)\n",
    "\n",
    "    # Reconstruir tiempos absolutos\n",
    "    t = 0.0\n",
    "    for p, s, d, v in zip(pitch, step, duration, velocity):\n",
    "        t += s\n",
    "        note = pretty_midi.Note(velocity=int(v), pitch=int(p), start=float(t), end=float(t + d))\n",
    "        instrument.notes.append(note)\n",
    "\n",
    "    pm.instruments.append(instrument)\n",
    "    pm.write(output_path)\n",
    "    print(f\"MIDI guardado en: {output_path} ({instrument_name})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_std_sequence_to_midi(seq_std, stats, output_path=\"reconstructed.mid\", instrument_name=\"Acoustic Grand Piano\"):\n",
    "    \"\"\"\n",
    "    seq_std: np.array (N,4) [pitch, stepZ, durationZ, velocityZ] estandarizados.\n",
    "    stats: dict con medias/stds {'step_mean','step_std','dur_mean','dur_std','vel_mean','vel_std'}\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    # Desestandarizar\n",
    "    pitch    = seq_std[:, 0]\n",
    "    step     = seq_std[:, 1] * stats[\"step_std\"] + stats[\"step_mean\"]\n",
    "    duration = seq_std[:, 2] * stats[\"dur_std\"] + stats[\"dur_mean\"]\n",
    "    velocity = seq_std[:, 3] * stats[\"vel_std\"] + stats[\"vel_mean\"]\n",
    "    seq_real = np.stack([pitch, step, duration, velocity], axis=1)\n",
    "    # Reutilizar la can√≥nica\n",
    "    save_sequence_to_midi(seq_real, output_path=output_path, instrument_name=instrument_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasar de MIDI a WAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_midi_to_wav(midi_path: str, wav_path: str, sf2_path: str, samplerate: int = 44100):\n",
    "\n",
    "    fs = pyfluidsynth.Synth(samplerate=samplerate)\n",
    "    try:\n",
    "        fs.start(driver=\"dsound\" if os.name == \"nt\" else \"alsa\")\n",
    "    except Exception:\n",
    "        fs.start()  # fallback gen√©rico\n",
    "\n",
    "    sfid = fs.sfload(sf2_path)\n",
    "    fs.program_select(0, sfid, 0, 0)\n",
    "\n",
    "    pm = pretty_midi.PrettyMIDI(midi_path)\n",
    "\n",
    "    # Renderizamos manualmente los eventos del track 0\n",
    "    # (PrettyMIDI puede reproducir directo, pero aqu√≠ controlamos la cadena)\n",
    "    audio = pm.fluidsynth(fs=samplerate, sf2_path=sf2_path)  # interfaz estable\n",
    "    # Normalizaci√≥n suave y a PCM16\n",
    "    peak = float(np.max(np.abs(audio))) if audio.size else 1.0\n",
    "    audio = (audio / (peak if peak > 0 else 1.0)) * 0.99\n",
    "    audio_int16 = (np.clip(audio, -1, 1) * 32767).astype(np.int16)\n",
    "    write(wav_path, samplerate, audio_int16)\n",
    "    fs.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDtYzja2g0S3"
   },
   "source": [
    "#  Dataset pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4KJLzr0Xg0CI"
   },
   "outputs": [],
   "source": [
    "class MusicWindowsDataset(Dataset):\n",
    "    def __init__(self, Xp, Xc, yp, yc):\n",
    "        self.Xp = Xp\n",
    "        self.Xc = Xc\n",
    "        self.yp = yp\n",
    "        self.yc = yc\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Xp)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        import torch\n",
    "        Xp = torch.as_tensor(self.Xp[i], dtype=torch.long)        # [L]\n",
    "        Xc = torch.as_tensor(self.Xc[i], dtype=torch.float32)     # [L,3]\n",
    "        yp = torch.as_tensor(self.yp[i], dtype=torch.long)        # []\n",
    "        yc = torch.as_tensor(self.yc[i], dtype=torch.float32)     # [3]\n",
    "        return (Xp, Xc), (yp, yc)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No5bj9H_gUW7"
   },
   "source": [
    "# Test modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "p1x6IR8wfQj8"
   },
   "outputs": [],
   "source": [
    "class MusicLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=64, cont_dim=3, hidden_size=256, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=None)\n",
    "        self.input_dim = emb_dim + cont_dim\n",
    "        self.lstm = nn.LSTM(self.input_dim, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.pitch_out = nn.Linear(hidden_size, vocab_size)  # clasificaci√≥n pitch\n",
    "        self.cont_out = nn.Linear(hidden_size, cont_dim)     # regresi√≥n step,duration,velocity\n",
    "\n",
    "    def forward(self, pitch_seq, cont_seq):\n",
    "        \"\"\"\n",
    "        pitch_seq: LongTensor (B, seq_len)\n",
    "        cont_seq: FloatTensor (B, seq_len, cont_dim)\n",
    "        returns:\n",
    "            pitch_logits: (B, vocab_size)\n",
    "            cont_pred: (B, cont_dim)\n",
    "        \"\"\"\n",
    "        emb = self.emb(pitch_seq)                # (B, seq_len, emb_dim)\n",
    "        x = torch.cat([emb, cont_seq], dim=-1)   # (B, seq_len, emb+cont)\n",
    "        out, (h, c) = self.lstm(x)               # out: (B, seq_len, hidden)\n",
    "        last = out[:, -1, :]                     # (B, hidden)\n",
    "        pitch_logits = self.pitch_out(last)      # (B, vocab_size)\n",
    "        cont_pred = self.cont_out(last)          # (B, cont_dim)\n",
    "        return pitch_logits, cont_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagrama de arquitectura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pendiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qN3alkGGgWhe"
   },
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stopping basado en una m√©trica escalar (modo 'min').\n",
    "    Guarda el mejor valor observado y cuenta √©pocas sin mejora.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=6, min_delta=0.0):\n",
    "        self.patience = int(patience)\n",
    "        self.min_delta = float(min_delta)\n",
    "        self.best = None\n",
    "        self.bad_epochs = 0\n",
    "\n",
    "    def step(self, value: float) -> bool:\n",
    "        \"\"\"\n",
    "        Devuelve True si hubo mejora y debe guardarse checkpoint.\n",
    "        \"\"\"\n",
    "        if self.best is None or (value < self.best - self.min_delta):\n",
    "            self.best = float(value)\n",
    "            self.bad_epochs = 0\n",
    "            return True\n",
    "        else:\n",
    "            self.bad_epochs += 1\n",
    "            return False\n",
    "\n",
    "    def should_stop(self) -> bool:\n",
    "        return self.bad_epochs >= self.patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "f-ekixiAfR_B"
   },
   "outputs": [],
   "source": [
    "def train(model,train_loader,\n",
    "          val_loader,\n",
    "          device,\n",
    "          epochs=40,\n",
    "          lr=5e-4,\n",
    "          cont_loss_weight=50.0,\n",
    "          # üîπ par√°metros de early stopping\n",
    "          es_patience=6,\n",
    "          es_min_delta=0.0,\n",
    "          best_ckpt_path=\"OUTPUT/best_music_lstm.pth\",\n",
    "          verbose=True):\n",
    "\n",
    "\n",
    "\n",
    "    model.to(device)\n",
    "    opt = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    history = { \"train_loss\": [],\n",
    "                \"val_CE\": [],\n",
    "                \"val_MSE\": [],\n",
    "                \"val_total\": [],\n",
    "                \"best_epoch\": None,\n",
    "                \"best_val_total\": None,\n",
    "                \"best_ckpt_path\": best_ckpt_path}\n",
    "\n",
    "    # Inicializa EarlyStopping\n",
    "    es = EarlyStopping(patience=es_patience, min_delta=es_min_delta)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Entrenamiento\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        for (Xp, Xc), (yp, yc) in train_loader:\n",
    "            Xp = Xp.to(device)           \n",
    "            Xc = Xc.to(device)           \n",
    "            yp = yp.to(device)           \n",
    "            yc = yc.to(device)         \n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits, cont_pred = model(Xp, Xc)         # logits [B,L,V]; cont_pred [B,L,3]\n",
    "            # Usa directamente la salida del modelo\n",
    "            logits_last = logits               # (B, V)\n",
    "            cont_last   = cont_pred            # (B, 3)\n",
    "\n",
    "            ce  = F.cross_entropy(logits_last, yp)    # CE para pitch\n",
    "            mse = F.mse_loss(cont_last, yc)           # MSE para continuos (normalizados)\n",
    "            loss = ce + cont_loss_weight * mse\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "\n",
    "            running += loss.item()\n",
    "\n",
    "        train_loss = running / max(1, len(train_loader))\n",
    "\n",
    "        # Validaci√≥n\n",
    "        model.eval()\n",
    "        val_ce = 0.0\n",
    "        val_mse = 0.0\n",
    "        with torch.no_grad():\n",
    "            for (Xp, Xc), (yp, yc) in val_loader:\n",
    "                Xp = Xp.to(device)\n",
    "                Xc = Xc.to(device)\n",
    "                yp = yp.to(device)\n",
    "                yc = yc.to(device)\n",
    "\n",
    "                logits, cont_pred = model(Xp, Xc)\n",
    "                logits_last = logits          # (B, V)\n",
    "                cont_last   = cont_pred       # (B, 3)\n",
    "\n",
    "                ce  = F.cross_entropy(logits_last, yp)\n",
    "                mse = F.mse_loss(cont_last, yc)\n",
    "                val_ce  += ce.item()\n",
    "                val_mse += mse.item()\n",
    "\n",
    "        val_ce  /= max(1, len(val_loader))\n",
    "        val_mse /= max(1, len(val_loader))\n",
    "       \n",
    "        val_total = val_ce + cont_loss_weight * val_mse\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_CE\"].append(val_ce)\n",
    "        history[\"val_MSE\"].append(val_mse)\n",
    "        history[\"val_total\"].append(val_total)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch} | train_loss={train_loss:.4f} | \"\n",
    "                  f\"val_CE={val_ce:.4f} | val_MSE={val_mse:.5f} | \"\n",
    "                  f\"val_total={val_total:.4f}\")\n",
    "\n",
    "        # Checkpoint si mejora\n",
    "        if es.step(val_total):\n",
    "            torch.save({\"model_state\": model.state_dict()}, best_ckpt_path)\n",
    "            history[\"best_epoch\"] = epoch\n",
    "            history[\"best_val_total\"] = val_total\n",
    "            if verbose:\n",
    "                print(f\"  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en {best_ckpt_path}\")\n",
    "\n",
    "        # Parar si no mejora por 'patience'\n",
    "        if es.should_stop():\n",
    "            if verbose:\n",
    "                print(f\"  ‚Ü≥ Early stopping en epoch {epoch} (best_epoch={history['best_epoch']})\")\n",
    "            break\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImKXlCTVgYa5"
   },
   "source": [
    "# Generacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1ufTV-9JfX4E"
   },
   "outputs": [],
   "source": [
    "#sample_from_logits\n",
    "def sample_from_logits_topk(logits, k=10, temperature=1.0):\n",
    "    \"\"\"\n",
    "    logits: torch.Tensor [vocab] o numpy.ndarray [vocab]\n",
    "    Devuelve: √≠ndice entero muestreado en top-k (con temperatura).\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    if not isinstance(logits, torch.Tensor):\n",
    "        logits = torch.from_numpy(logits)\n",
    "\n",
    "    # Evita k inv√°lido\n",
    "    vocab = logits.shape[-1]\n",
    "    k = max(1, min(int(k), int(vocab)))\n",
    "\n",
    "    # √öltimo paso de la secuencia si viene con eje extra\n",
    "    # (p.ej., [1, V] -> [V])\n",
    "    if logits.ndim > 1:\n",
    "        logits = logits.view(-1)\n",
    "\n",
    "    # Temperatura\n",
    "    if temperature is None or temperature <= 0:\n",
    "        temperature = 1.0\n",
    "    logits = logits / float(temperature)\n",
    "\n",
    "    # Top-k + muestreo\n",
    "    topk_vals, topk_idx = torch.topk(logits, k)          \n",
    "    topk_probs = torch.softmax(topk_vals, dim=-1)        \n",
    "    choice = torch.multinomial(topk_probs, 1)            \n",
    "    return int(topk_idx[choice].item())\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_sequence(model, device,\n",
    "                      seed_pitch_seq,   \n",
    "                      seed_cont_seq,    \n",
    "                      steps=200,\n",
    "                      idx2pitch=None,\n",
    "                      stats=None,\n",
    "                      temperature=1.0,\n",
    "                      top_k=10,\n",
    "                      max_context=32):\n",
    "    \"\"\"\n",
    "    Devuelve: np.ndarray shape [T_gen, 4] con columnas [pitch, step, dur, vel]\n",
    "              (en tu mismo formato downstream).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Normalizaci√≥n defensiva de entradas\n",
    "    seed_pitch_seq = np.asarray(seed_pitch_seq, dtype=np.int64)          \n",
    "    seed_cont_seq  = np.asarray(seed_cont_seq,  dtype=np.float32)        \n",
    "    assert seed_cont_seq.ndim == 2 and seed_cont_seq.shape[1] == 3, \"seed_cont_seq debe ser [T,3]\"\n",
    "\n",
    "    # Construir tensores en el dispositivo sin listas de ndarrays:\n",
    "    def _mk_inputs(pitches_np, cont_np):\n",
    "        # recorta al contexto\n",
    "        pitches_np = pitches_np[-max_context:]\n",
    "        cont_np    = cont_np[-max_context:]\n",
    "        inp_pitch = torch.as_tensor(pitches_np, dtype=torch.long, device=device).unsqueeze(0)   # [1, L]\n",
    "        inp_cont  = torch.as_tensor(cont_np,    dtype=torch.float32, device=device).unsqueeze(0) # [1, L, 3]\n",
    "        return inp_pitch, inp_cont\n",
    "\n",
    "    # Copias de trabajo (para ir anexando)\n",
    "    cur_pitch = seed_pitch_seq.copy()\n",
    "    cur_cont  = seed_cont_seq.copy()\n",
    "\n",
    "    generated_rows = []  # acumularemos filas [pitch, step, dur, vel] \n",
    "\n",
    "    for _ in range(steps):\n",
    "        inp_pitch, inp_cont = _mk_inputs(cur_pitch, cur_cont)\n",
    "        logits, cont_pred = model(inp_pitch, inp_cont)  \n",
    "\n",
    "        # Tomar el √∫ltimo paso temporal\n",
    "        logits_last = logits.squeeze(0)                \n",
    "        cont_last   = cont_pred.squeeze(0).cpu().numpy() # (3,)  \n",
    "\n",
    "        # Muestreo discreto\n",
    "        next_pitch_idx = sample_from_logits_topk(logits_last, k=top_k, temperature=temperature)\n",
    "\n",
    "        # Desnormalizar los 3 continuos \n",
    "        if stats is not None:\n",
    "            step = (cont_last[0] * (float(stats[\"step_std\"]) + 1e-6)) + float(stats[\"step_mean\"])\n",
    "            dur  = (cont_last[1] * (float(stats[\"dur_std\"])  + 1e-6)) + float(stats[\"dur_mean\"])\n",
    "            vel  = (cont_last[2] * (float(stats[\"vel_std\"])  + 1e-6)) + float(stats[\"vel_mean\"])\n",
    "        else:\n",
    "            step, dur, vel = float(cont_last[0]), float(cont_last[1]), float(cont_last[2])\n",
    "\n",
    "        # Seguridad: valores v√°lidos\n",
    "        next_pitch = int(np.clip(next_pitch_idx, 0, 127))\n",
    "        step = max(0.0, float(step))\n",
    "        dur  = max(1e-3, float(dur))\n",
    "        vel  = float(np.clip(vel, 1.0, 127.0))\n",
    "\n",
    "        # Append a las listas de estado (en formato NORMALIZADO para el modelo)\n",
    "        # Nota: para la siguiente iteraci√≥n el modelo necesita los continuos NORMALIZADOS,\n",
    "        # por lo que guardamos adem√°s la versi√≥n normalizada:\n",
    "        if stats is not None:\n",
    "            step_n = (step - float(stats[\"step_mean\"])) / (float(stats[\"step_std\"]) + 1e-6)\n",
    "            dur_n  = (dur  - float(stats[\"dur_mean\"]))  / (float(stats[\"dur_std\"])  + 1e-6)\n",
    "            vel_n  = (vel  - float(stats[\"vel_mean\"]))  / (float(stats[\"vel_std\"])  + 1e-6)\n",
    "            cur_cont = np.vstack([cur_cont, [step_n, dur_n, vel_n]]).astype(np.float32)\n",
    "        else:\n",
    "            cur_cont = np.vstack([cur_cont, [step, dur, vel]]).astype(np.float32)\n",
    "\n",
    "        cur_pitch = np.append(cur_pitch, next_pitch).astype(np.int64)\n",
    "\n",
    "        # Guardar fila desnormalizada para el MIDI\n",
    "        generated_rows.append([next_pitch, step, dur, vel])\n",
    "\n",
    "    return np.asarray(generated_rows, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5fFn6iYgaUw"
   },
   "source": [
    "# Pipeline completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZSwCOwbfiQ4",
    "outputId": "6a88845d-4c25-4ac3-812e-601f5c7fed42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Extrayendo secuencias crudas...\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=4225\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=3300\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2954\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2173\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3868\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2580\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3185\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2792\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2854\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=3395\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1850\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=885\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3239\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=3186\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2970\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1822\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2592\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2073\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1779\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2002\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2191\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1494\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2027\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1588\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=5268\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=5465\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=1374\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=917\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=1705\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=1443\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=3118\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=2461\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2418\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2555\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2150\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=993\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2050\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=551\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3267\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2449\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1447\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1200\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=872\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=781\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=563\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=495\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1515\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1135\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1372\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=952\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1088\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=900\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2673\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2480\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=806\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=509\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1721\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1673\n",
      "  secuencias extra√≠das: 25\n",
      "2) Estandarizando (pitch se mantiene intacto)...\n",
      "  stats: {'step_mean': np.float32(0.098957), 'step_std': np.float32(0.18229377), 'dur_mean': np.float32(0.33029), 'dur_std': np.float32(0.41488776), 'vel_mean': np.float32(48.245155), 'vel_std': np.float32(17.51278)}\n",
      "3) Creando ventanas...\n",
      "  Train -> Xp_tr: (76482, 32) Xc_tr: (76482, 32, 3) yp_tr: (76482,)\n",
      "  Valid -> Xp_va: (22357, 32) Xc_va: (22357, 32, 3) yp_va: (22357,)\n",
      "vocab_size: 128\n",
      "Training model on device: cuda\n",
      "Epoch 1 | train_loss=19.6833 | val_CE=4.0480 | val_MSE=0.40123 | val_total=14.0788\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT/best_music_lstm.pth\n",
      "Epoch 2 | train_loss=15.9296 | val_CE=3.9626 | val_MSE=0.36559 | val_total=13.1023\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT/best_music_lstm.pth\n",
      "Epoch 3 | train_loss=14.5958 | val_CE=3.9466 | val_MSE=0.34659 | val_total=12.6112\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT/best_music_lstm.pth\n",
      "Epoch 4 | train_loss=13.4714 | val_CE=3.8426 | val_MSE=0.35331 | val_total=12.6753\n",
      "Epoch 5 | train_loss=12.5125 | val_CE=3.7795 | val_MSE=0.34149 | val_total=12.3166\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT/best_music_lstm.pth\n",
      "Epoch 6 | train_loss=11.5667 | val_CE=3.7467 | val_MSE=0.34530 | val_total=12.3792\n",
      "Epoch 7 | train_loss=10.8050 | val_CE=3.7398 | val_MSE=0.33943 | val_total=12.2257\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT/best_music_lstm.pth\n",
      "Epoch 8 | train_loss=9.9444 | val_CE=3.6868 | val_MSE=0.34275 | val_total=12.2555\n",
      "Epoch 9 | train_loss=9.2893 | val_CE=3.6921 | val_MSE=0.35256 | val_total=12.5061\n",
      "Epoch 10 | train_loss=8.6128 | val_CE=3.6761 | val_MSE=0.34888 | val_total=12.3980\n",
      "Epoch 11 | train_loss=8.0083 | val_CE=3.6645 | val_MSE=0.35249 | val_total=12.4767\n",
      "Epoch 12 | train_loss=7.6440 | val_CE=3.6349 | val_MSE=0.36010 | val_total=12.6373\n",
      "Epoch 13 | train_loss=7.0615 | val_CE=3.6637 | val_MSE=0.35745 | val_total=12.6000\n",
      "Epoch 14 | train_loss=6.6289 | val_CE=3.6481 | val_MSE=0.35375 | val_total=12.4919\n",
      "Epoch 15 | train_loss=6.2694 | val_CE=3.6307 | val_MSE=0.35725 | val_total=12.5620\n",
      "Epoch 16 | train_loss=5.8939 | val_CE=3.6358 | val_MSE=0.36386 | val_total=12.7323\n",
      "Epoch 17 | train_loss=5.5824 | val_CE=3.6850 | val_MSE=0.37069 | val_total=12.9522\n",
      "  ‚Ü≥ Early stopping en epoch 17 (best_epoch=7)\n",
      "[Gen 1] Usando semilla index: 33948\n",
      "MIDI guardado en: OUTPUT/generated_music_lstm_1.mid (Acoustic Grand Piano)\n",
      "[Gen 1] WAV guardado en:  OUTPUT\\generated_music_lstm_1.wav\n",
      "[Gen 1] MIDI guardado en: OUTPUT\\generated_music_lstm_1.mid\n",
      "[Gen 2] Usando semilla index: 38110\n",
      "MIDI guardado en: OUTPUT/generated_music_lstm_2.mid (Acoustic Grand Piano)\n",
      "[Gen 2] WAV guardado en:  OUTPUT\\generated_music_lstm_2.wav\n",
      "[Gen 2] MIDI guardado en: OUTPUT\\generated_music_lstm_2.mid\n",
      "[Gen 3] Usando semilla index: 24343\n",
      "MIDI guardado en: OUTPUT/generated_music_lstm_3.mid (Acoustic Grand Piano)\n",
      "[Gen 3] WAV guardado en:  OUTPUT\\generated_music_lstm_3.wav\n",
      "[Gen 3] MIDI guardado en: OUTPUT\\generated_music_lstm_3.mid\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"1) Extrayendo secuencias crudas...\")\n",
    "    raw_sequences = extract_raw_note_sequences(ROOT_DIR, instrument_name= INSTRUMENT_NAME, composer_name=COMPOSER)\n",
    "    print(f\"  secuencias extra√≠das: {len(raw_sequences)}\")\n",
    "\n",
    "    train_sequences, val_sequences = train_test_split(raw_sequences, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "    print(\"2) Estandarizando (pitch se mantiene intacto)...\")\n",
    "    standardized_sequences, stats = standardize_note_sequences(train_sequences)\n",
    "    print(\"  stats:\", stats)\n",
    "\n",
    "    def apply_standardization(seqs, stats):\n",
    "        out = []\n",
    "        for seq in seqs:\n",
    "            s = seq.copy()\n",
    "            s[:,1] = (s[:,1]-stats[\"step_mean\"])/(stats[\"step_std\"]+1e-6)\n",
    "            s[:,2] = (s[:,2]-stats[\"dur_mean\"] )/(stats[\"dur_std\"] +1e-6)\n",
    "            s[:,3] = (s[:,3]-stats[\"vel_mean\"] )/(stats[\"vel_std\"] +1e-6)\n",
    "            out.append(s)\n",
    "        return out\n",
    "\n",
    "    val_standardized = apply_standardization(val_sequences, stats)\n",
    "    print(\"3) Creando ventanas...\")\n",
    "    (Xp_tr, Xc_tr), (yp_tr, yc_tr) = create_windows(standardized_sequences, seq_len=SEQ_LEN)\n",
    "    (Xp_va, Xc_va), (yp_va, yc_va) = create_windows(val_standardized,       seq_len=SEQ_LEN)\n",
    "\n",
    "    print(\"  Train -> Xp_tr:\", Xp_tr.shape, \"Xc_tr:\", Xc_tr.shape, \"yp_tr:\", yp_tr.shape)\n",
    "    print(\"  Valid -> Xp_va:\", Xp_va.shape, \"Xc_va:\", Xc_va.shape, \"yp_va:\", yp_va.shape)\n",
    "\n",
    "\n",
    "    # construir vocab (opcional\n",
    "    if Xp_tr.shape[0] == 0:\n",
    "        raise RuntimeError(\"No hay muestras. Aumenta datos o reduce SEQ_LEN.\")\n",
    "    max_pitch = int(np.max(Xp_tr))\n",
    "    vocab_size = max(128, max_pitch + 1)\n",
    "    print(\"vocab_size:\", vocab_size)\n",
    "\n",
    "    # dataset\n",
    "    train_ds = MusicWindowsDataset(Xp_tr, Xc_tr, yp_tr, yc_tr)\n",
    "    val_ds   = MusicWindowsDataset(Xp_va,   Xc_va,   yp_va,   yc_va)\n",
    "    loader   = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "    vloader  = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "    # modelo\n",
    "    model = MusicLSTM(vocab_size=vocab_size, emb_dim=64, cont_dim=3, hidden_size= HIDDEN_SIZE, num_layers= NUM_LAYERS,dropout=DROPOUT) # Ajustado num_layers\n",
    "    print(\"Training model on device:\", DEVICE)\n",
    "    history = train(\n",
    "        model,\n",
    "        train_loader=loader,\n",
    "        val_loader=vloader,\n",
    "        device=DEVICE,\n",
    "        epochs=EPOCHS,\n",
    "        lr=LR,\n",
    "        cont_loss_weight= PESO_LOSS_CONT,\n",
    "        es_patience= PATIENCE,                \n",
    "        es_min_delta= MIN_DELTA,           \n",
    "        best_ckpt_path=(OUTPUT_DIR / \"best_music_lstm.pth\").as_posix(),\n",
    "    )\n",
    "\n",
    "    # Guardar modelo y stats\n",
    "    # Cargar mejor estado antes de generar\n",
    "    best_ckpt = torch.load((OUTPUT_DIR / \"best_music_lstm.pth\").as_posix(), map_location=DEVICE)\n",
    "    model.load_state_dict(best_ckpt[\"model_state\"])\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    #  Generaci√≥n de ejemplos\n",
    " \n",
    "    total_samples = Xp_tr.shape[0]\n",
    "   \n",
    "    # Elegimos √≠ndices de semillas distintos si hay suficientes, o con reposici√≥n si no\n",
    "    idx_pool = list(range(total_samples))\n",
    "    if total_samples >= NUM_SEQS:\n",
    "        seed_indices = random.sample(idx_pool, NUM_SEQS)  # sin reemplazo\n",
    "    else:\n",
    "        seed_indices = [random.choice(idx_pool) for _ in range(NUM_SEQS)]  # con reemplazo\n",
    "    \n",
    "    for j, idx in enumerate(seed_indices, start=1):\n",
    "        seed_pitch = Xp_tr[idx].tolist()\n",
    "        seed_cont  = Xc_tr[idx]\n",
    "        print(f\"[Gen {j}] Usando semilla index: {idx}\")\n",
    "    \n",
    "        generated = generate_sequence(\n",
    "            model, DEVICE,\n",
    "            seed_pitch, seed_cont,\n",
    "            steps=STEPS_PER_SEQ,\n",
    "            idx2pitch=None,\n",
    "            stats=stats,\n",
    "            temperature=TEMPERATURE,\n",
    "            top_k=TOP_K)\n",
    "        \n",
    "        if generated.shape[0] > 200:\n",
    "          generated = generated[-200:, :]\n",
    "    \n",
    "        midi_path = OUTPUT_DIR / f\"generated_music_lstm_{j}.mid\"\n",
    "        wav_path = OUTPUT_DIR / f\"generated_music_lstm_{j}.wav\"\n",
    "        \n",
    "        save_sequence_to_midi(generated, output_path=midi_path.as_posix(), instrument_name=INSTRUMENT_NAME)\n",
    "        \n",
    "        try:\n",
    "            render_midi_to_wav(midi_path.as_posix(), wav_path.as_posix(), SF2, samplerate=44100)\n",
    "            print(f\"[Gen {j}] WAV guardado en:  {wav_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Gen {j}] No se pudo generar WAV (revisa pyfluidsynth/DLL/SF2): {e}\")\n",
    "        \n",
    "        print(f\"[Gen {j}] MIDI guardado en: {midi_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Celda usada Font de los Markdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- Fuentes recomendadas para estilo matem√°tico -->\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=STIX+Two+Text:ital,wght@0,400;0,700;1,400;1,700&display=swap\" rel=\"stylesheet\">\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=STIX+Two+Math:ital,wght@0,400;0,700;1,400;1,700&display=swap\" rel=\"stylesheet\">\n",
       "<link href=\"https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&display=swap\" rel=\"stylesheet\">\n",
       "\n",
       "<style>\n",
       "  /* --- Markdown cl√°sico (Notebook) --- */\n",
       "  div.text_cell_render.rendered_html p,\n",
       "  div.text_cell_render.rendered_html h1,\n",
       "  div.text_cell_render.rendered_html h2,\n",
       "  div.text_cell_render.rendered_html h3,\n",
       "  div.text_cell_render.rendered_html li {\n",
       "    font-family: 'STIX Two Text', serif !important;\n",
       "  }\n",
       "\n",
       "  /* MathJax (f√≥rmulas) */\n",
       "  .MathJax, .MathJax_Display {\n",
       "    font-family: 'STIX Two Math', serif !important;\n",
       "  }\n",
       "\n",
       "  /* C√≥digo */\n",
       "  div.text_cell_render.rendered_html code,\n",
       "  div.text_cell_render.rendered_html pre {\n",
       "    font-family: 'Inconsolata', monospace !important;\n",
       "  }\n",
       "\n",
       "  /* --- JupyterLab --- */\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon p,\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon h1,\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon h2,\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon h3,\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon li {\n",
       "    font-family: 'STIX Two Text', serif !important;\n",
       "  }\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon code,\n",
       "  .jp-Notebook .jp-RenderedHTMLCommon pre {\n",
       "    font-family: 'Inconsolata', monospace !important;\n",
       "  }\n",
       "  .jp-Notebook .MathJax,\n",
       "  .jp-Notebook .MathJax_Display {\n",
       "    font-family: 'STIX Two Math', serif !important;\n",
       "  }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<!-- Fuentes recomendadas para estilo matem√°tico -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=STIX+Two+Text:ital,wght@0,400;0,700;1,400;1,700&display=swap\" rel=\"stylesheet\">\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=STIX+Two+Math:ital,wght@0,400;0,700;1,400;1,700&display=swap\" rel=\"stylesheet\">\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "<style>\n",
    "  /* --- Markdown cl√°sico (Notebook) --- */\n",
    "  div.text_cell_render.rendered_html p,\n",
    "  div.text_cell_render.rendered_html h1,\n",
    "  div.text_cell_render.rendered_html h2,\n",
    "  div.text_cell_render.rendered_html h3,\n",
    "  div.text_cell_render.rendered_html li {\n",
    "    font-family: 'STIX Two Text', serif !important;\n",
    "  }\n",
    "\n",
    "  /* MathJax (f√≥rmulas) */\n",
    "  .MathJax, .MathJax_Display {\n",
    "    font-family: 'STIX Two Math', serif !important;\n",
    "  }\n",
    "\n",
    "  /* C√≥digo */\n",
    "  div.text_cell_render.rendered_html code,\n",
    "  div.text_cell_render.rendered_html pre {\n",
    "    font-family: 'Inconsolata', monospace !important;\n",
    "  }\n",
    "\n",
    "  /* --- JupyterLab --- */\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon p,\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon h1,\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon h2,\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon h3,\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon li {\n",
    "    font-family: 'STIX Two Text', serif !important;\n",
    "  }\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon code,\n",
    "  .jp-Notebook .jp-RenderedHTMLCommon pre {\n",
    "    font-family: 'Inconsolata', monospace !important;\n",
    "  }\n",
    "  .jp-Notebook .MathJax,\n",
    "  .jp-Notebook .MathJax_Display {\n",
    "    font-family: 'STIX Two Math', serif !important;\n",
    "  }\n",
    "</style>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "iJrvj5YdhVoo",
    "C04D1njqhYFn",
    "w1n9XyNyhcej",
    "GtygejbZhgP-",
    "vH4IXLREhjSW"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (jlabclean)",
   "language": "python",
   "name": "jlabclean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
