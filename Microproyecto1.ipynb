{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IW1eQD90BIgG",
    "outputId": "e262966a-1613-46c1-ecd9-f57aa3bb2d5d"
   },
   "outputs": [],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3qMMYFXMBgxe",
    "outputId": "c795ad7b-f346-4455-e70d-a6f832dc6c39"
   },
   "outputs": [],
   "source": [
    "#!pip install pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CwOU59cOBqHA",
    "outputId": "2a037d31-79e2-4237-d960-a977dc93152c"
   },
   "outputs": [],
   "source": [
    "#!pip install mido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3ObmPXrCK_z"
   },
   "source": [
    "## Si es Gooogle colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKwqyl42CMPV",
    "outputId": "2d3f4677-f52b-4f48-de02-7eae82177470"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJAlithrCXJ5",
    "outputId": "5050e97a-b66c-4a87-c063-c8709ba2dfdd"
   },
   "outputs": [],
   "source": [
    "#!ls /content/drive/MyDrive/\"Colab Notebooks\"/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CDLL 'C:\\tools\\fluidsynth\\bin\\libfluidsynth-3.dll', handle 7ffc6cd80000 at 0x157fd1f5950>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Bootstrap FluidSynth (Windows, persistente por sesi√≥n de kernel) ---\n",
    "import os\n",
    "if os.name == \"nt\":\n",
    "    DLL_DIR = r\"C:\\tools\\fluidsynth\\bin\"  # carpeta donde pusiste libfluidsynth-3.dll\n",
    "    if hasattr(os, \"add_dll_directory\"):\n",
    "        os.add_dll_directory(DLL_DIR)\n",
    "    os.environ[\"FLUIDSYNTH_LIBRARY\"] = os.path.join(DLL_DIR, \"libfluidsynth-3.dll\")\n",
    "\n",
    "# (opcional) smoke test de la DLL para fallar pronto si algo cambi√≥\n",
    "from ctypes import CDLL\n",
    "CDLL(os.environ[\"FLUIDSYNTH_LIBRARY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fluidsynth as pyfluidsynth\n",
    "import pretty_midi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WY-yhu2NgFf6"
   },
   "source": [
    "# Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_J3PzSeYEF4S"
   },
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import os, sys\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from scipy.io.wavfile import write\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPTN5Y8YgIjn"
   },
   "source": [
    "# Configuracion variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BU-R44U_GJ3O"
   },
   "outputs": [],
   "source": [
    "ROOT_DIR =  \"./Dataset/music_artist\"  # \"/content/drive/MyDrive/Colab Notebooks/Dataset/TEST\"   # <-- directorio ra√≠z con carpetas de compositores\n",
    "OUTPUT_DIR = Path(\"./OUTPUT\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SEQ_LEN = 32 # Block size\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_SIZE = 384\n",
    "EPOCHS = 40\n",
    "LR = 3e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_TYPE = \"LSTM\"  # opciones: \"RNN\", \"LSTM\", \"GRU\"\n",
    "INSTRUMENT_NAME = \"Acoustic Grand Piano\"\n",
    "COMPOSER = \"schubert\"  # este es el artista que tiene m√°s datos\n",
    "NUM_SEQS       = 3  # N√∫mero de secuencias a generar\n",
    "STEPS_PER_SEQ  = 200  # Notas que debe tener cada secuencia\n",
    "TEMPERATURE    = 0.7  # Temperatura\n",
    "NUM_LAYERS = 4\n",
    "DROPOUT = 0.3\n",
    "TOP_K = 20\n",
    "PESO_LOSS_CONT = 50\n",
    "SF2 = \"./soundfonts/FluidR3_GM.sf2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 13\n",
    "random.seed(RANDOM_STATE); np.random.seed(RANDOM_STATE); torch.manual_seed(RANDOM_STATE)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "beKjgq-gGSI6",
    "outputId": "764903b1-722b-490c-d606-c5f8b7d8f6ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFgUa-JNgPMd"
   },
   "source": [
    "# 1. Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJrvj5YdhVoo"
   },
   "source": [
    "## Lectura MIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_raw_note_sequences(root_dir, instrument_name=None, program_number=None, composer_name=None):\n",
    "    raw_sequences = []\n",
    "    candidates = [composer_name] if composer_name else [\n",
    "        d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))\n",
    "    ]\n",
    "    for composer in candidates:\n",
    "        folder = os.path.join(root_dir, composer)\n",
    "        midi_files = glob.glob(os.path.join(folder, \"*.mid\"))\n",
    "\n",
    "        for mf in midi_files:\n",
    "            try:\n",
    "                pm = pretty_midi.PrettyMIDI(mf)\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo leer {mf}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # --- Selecci√≥n de instrumento ---\n",
    "            chosen_instruments = []\n",
    "            for i, inst in enumerate(pm.instruments):\n",
    "                name = pretty_midi.program_to_instrument_name(inst.program)\n",
    "                print(f\"[{i}] prog={inst.program:>2} name={name} notas={len(inst.notes)}\")\n",
    "                if instrument_name is not None:\n",
    "                    inst_name = pretty_midi.program_to_instrument_name(inst.program)\n",
    "                    if inst_name.lower() == instrument_name.lower():\n",
    "                        chosen_instruments.append(inst)\n",
    "                elif program_number is not None:\n",
    "                    if inst.program == program_number:\n",
    "                        chosen_instruments.append(inst)\n",
    "\n",
    "            # Si no hubo match expl√≠cito y no se especific√≥ filtro, tomamos el primero (comportamiento viejo)\n",
    "            if instrument_name is None and program_number is None:\n",
    "                chosen_instruments = pm.instruments[:1]  # solo el primero\n",
    "\n",
    "            if not chosen_instruments:\n",
    "                # Nada que extraer en este archivo para el instrumento pedido\n",
    "                continue\n",
    "\n",
    "            # --- Extraer notas SOLO del/los instrumentos elegidos ---\n",
    "            notes = []\n",
    "            for inst in chosen_instruments:\n",
    "                for note_mus in inst.notes:\n",
    "                    start = note_mus.start\n",
    "                    end = note_mus.end\n",
    "                    duration = end - start\n",
    "                    velocity = note_mus.velocity\n",
    "                    notes.append((start, note_mus.pitch, duration, velocity))\n",
    "\n",
    "            if not notes:\n",
    "                continue\n",
    "\n",
    "            # Ordenar por inicio y construir [pitch, step, duration, velocity]\n",
    "            notes.sort(key=lambda x: x[0])\n",
    "            note_feats = []\n",
    "            prev_start = notes[0][0]\n",
    "            for start, pitch, duration, velocity in notes:\n",
    "                step = start - prev_start\n",
    "                prev_start = start\n",
    "                note_feats.append([pitch, step, duration, velocity])\n",
    "\n",
    "            if note_feats:\n",
    "                raw_sequences.append(np.array(note_feats, dtype=np.float32))\n",
    "\n",
    "    return raw_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C04D1njqhYFn"
   },
   "source": [
    "## Estandarizar variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Jv0A8oHWKEne"
   },
   "outputs": [],
   "source": [
    "def standardize_note_sequences(sequences):\n",
    "    \"\"\"\n",
    "    Estandariza las variables continuas (step, duration, velocity)\n",
    "    y mantiene el pitch intacto para usarlo luego con embeddings.\n",
    "    \"\"\"\n",
    "    all_steps, all_durations, all_velocities = [], [], []\n",
    "\n",
    "    # Recolectar todas las variables continuas para calcular media y std global\n",
    "    for seq in sequences:\n",
    "        all_steps.extend(seq[:, 1])\n",
    "        all_durations.extend(seq[:, 2])\n",
    "        all_velocities.extend(seq[:, 3])\n",
    "\n",
    "    # Estad√≠sticas globales\n",
    "    step_mean, step_std = np.mean(all_steps), np.std(all_steps)\n",
    "    dur_mean, dur_std = np.mean(all_durations), np.std(all_durations)\n",
    "    vel_mean, vel_std = np.mean(all_velocities), np.std(all_velocities)\n",
    "\n",
    "    standardized = []\n",
    "    for seq in sequences:\n",
    "        seq_std = seq.copy()\n",
    "        # No tocar pitch (columna 0)\n",
    "        seq_std[:, 1] = (seq[:, 1] - step_mean) / (step_std + 1e-6)\n",
    "        seq_std[:, 2] = (seq[:, 2] - dur_mean) / (dur_std + 1e-6)\n",
    "        seq_std[:, 3] = (seq[:, 3] - vel_mean) / (vel_std + 1e-6)\n",
    "        standardized.append(seq_std)\n",
    "\n",
    "    stats = {\n",
    "        \"step_mean\": step_mean, \"step_std\": step_std,\n",
    "        \"dur_mean\": dur_mean, \"dur_std\": dur_std,\n",
    "        \"vel_mean\": vel_mean, \"vel_std\": vel_std\n",
    "    }\n",
    "\n",
    "    return standardized, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1n9XyNyhcej"
   },
   "source": [
    "## Crear ventanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VWsFUkyhS404"
   },
   "outputs": [],
   "source": [
    "def create_windows(sequences, seq_len=32):\n",
    "    \"\"\"\n",
    "    Crea pares (X, y) para entrenamiento a partir de las secuencias estandarizadas.\n",
    "    X: secuencia de longitud seq_len\n",
    "    y: la nota siguiente\n",
    "    \"\"\"\n",
    "    X_pitch, X_cont, y_pitch, y_cont = [], [], [], []\n",
    "\n",
    "    for seq in sequences:\n",
    "        if len(seq) < seq_len + 1:\n",
    "            continue\n",
    "\n",
    "        # Dividir en ventanas\n",
    "        for i in range(len(seq) - seq_len):\n",
    "            window = seq[i:i+seq_len]\n",
    "            target = seq[i+seq_len]\n",
    "\n",
    "            # Separar pitch (entero) y las features continuas\n",
    "            X_pitch.append(window[:, 0].astype(np.int64))     # pitch\n",
    "            X_cont.append(window[:, 1:].astype(np.float32))   # step, duration, velocity\n",
    "            y_pitch.append(int(target[0]))                    # pitch de la siguiente nota\n",
    "            y_cont.append(target[1:].astype(np.float32))      # step, duration, velocity siguientes\n",
    "\n",
    "    # Convertir a arrays numpy\n",
    "    X_pitch = np.array(X_pitch, dtype=np.int64)\n",
    "    X_cont = np.array(X_cont, dtype=np.float32)\n",
    "    y_pitch = np.array(y_pitch, dtype=np.int64)\n",
    "    y_cont = np.array(y_cont, dtype=np.float32)\n",
    "\n",
    "    return (X_pitch, X_cont), (y_pitch, y_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vH4IXLREhjSW"
   },
   "source": [
    "## Guardar secuencias a MIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kkQMkq6idGIz"
   },
   "outputs": [],
   "source": [
    "def save_sequence_to_midi(seq, output_path=\"generated.mid\", instrument_name=\"Acoustic Grand Piano\"):\n",
    "    \"\"\"\n",
    "    seq: np.array (N,4) con columnas [pitch, step, duration, velocity] en ESCALA REAL.\n",
    "    \"\"\"\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    try:\n",
    "        program_number = pretty_midi.instrument_name_to_program(instrument_name)\n",
    "    except ValueError:\n",
    "        program_number = 0\n",
    "    instrument = pretty_midi.Instrument(program=program_number)\n",
    "\n",
    "    # Asegurar valores v√°lidos\n",
    "    pitch    = seq[:, 0].astype(int)\n",
    "    step     = np.maximum(seq[:, 1].astype(float), 0.0)\n",
    "    duration = np.maximum(seq[:, 2].astype(float), 0.01)\n",
    "    velocity = np.clip(seq[:, 3].astype(float), 0, 127).astype(int)\n",
    "\n",
    "    # Reconstruir tiempos absolutos\n",
    "    t = 0.0\n",
    "    for p, s, d, v in zip(pitch, step, duration, velocity):\n",
    "        t += s\n",
    "        note = pretty_midi.Note(velocity=int(v), pitch=int(p), start=float(t), end=float(t + d))\n",
    "        instrument.notes.append(note)\n",
    "\n",
    "    pm.instruments.append(instrument)\n",
    "    pm.write(output_path)\n",
    "    print(f\"‚úÖ MIDI guardado en: {output_path} ({instrument_name})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_std_sequence_to_midi(seq_std, stats, output_path=\"reconstructed.mid\", instrument_name=\"Acoustic Grand Piano\"):\n",
    "    \"\"\"\n",
    "    seq_std: np.array (N,4) [pitch, stepZ, durationZ, velocityZ] estandarizados.\n",
    "    stats: dict con medias/stds {'step_mean','step_std','dur_mean','dur_std','vel_mean','vel_std'}\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    # Desestandarizar\n",
    "    pitch    = seq_std[:, 0]\n",
    "    step     = seq_std[:, 1] * stats[\"step_std\"] + stats[\"step_mean\"]\n",
    "    duration = seq_std[:, 2] * stats[\"dur_std\"] + stats[\"dur_mean\"]\n",
    "    velocity = seq_std[:, 3] * stats[\"vel_std\"] + stats[\"vel_mean\"]\n",
    "    seq_real = np.stack([pitch, step, duration, velocity], axis=1)\n",
    "    # Reutilizar la can√≥nica\n",
    "    save_sequence_to_midi(seq_real, output_path=output_path, instrument_name=instrument_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasar de MIDI a WAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_midi_to_wav(midi_path: str, wav_path: str, sf2_path: str, samplerate: int = 44100):\n",
    "    fs = pyfluidsynth.Synth(samplerate=samplerate)  # <--- usa el alias importado\n",
    "    sfid = fs.sfload(sf2_path)\n",
    "    try:\n",
    "        pm = pretty_midi.PrettyMIDI(midi_path)\n",
    "        audio = pm.fluidsynth(fs=samplerate, synthesizer=fs, sfid=sfid, normalize=True)  # normaliza p/evitar clipping\n",
    "\n",
    "        # Convertir a PCM_16 (compatible con Reproductor de Windows)\n",
    "        peak = float(np.max(np.abs(audio))) if audio.size else 1.0\n",
    "        if peak == 0: peak = 1.0\n",
    "        audio = (audio / peak) * 0.99\n",
    "        audio_int16 = (np.clip(audio, -1, 1) * 32767).astype(np.int16)\n",
    "\n",
    "        write(wav_path, samplerate, audio_int16)\n",
    "    finally:\n",
    "        fs.delete()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDtYzja2g0S3"
   },
   "source": [
    "#  Dataset pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4KJLzr0Xg0CI"
   },
   "outputs": [],
   "source": [
    "class MusicWindowsDataset(Dataset):\n",
    "    def __init__(self, Xp, Xc, yp, yc):\n",
    "        self.Xp = Xp\n",
    "        self.Xc = Xc\n",
    "        self.yp = yp\n",
    "        self.yc = yc\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Xp)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        import torch\n",
    "        Xp = torch.as_tensor(self.Xp[i], dtype=torch.long)        # [L]\n",
    "        Xc = torch.as_tensor(self.Xc[i], dtype=torch.float32)     # [L,3]\n",
    "        yp = torch.as_tensor(self.yp[i], dtype=torch.long)        # []\n",
    "        yc = torch.as_tensor(self.yc[i], dtype=torch.float32)     # [3]\n",
    "        return (Xp, Xc), (yp, yc)  # <<< clave: 2-tuplas anidadas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No5bj9H_gUW7"
   },
   "source": [
    "# Test modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "p1x6IR8wfQj8"
   },
   "outputs": [],
   "source": [
    "class MusicLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=64, cont_dim=3, hidden_size=256, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=None)\n",
    "        self.input_dim = emb_dim + cont_dim\n",
    "        self.lstm = nn.LSTM(self.input_dim, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.pitch_out = nn.Linear(hidden_size, vocab_size)  # clasificaci√≥n pitch\n",
    "        self.cont_out = nn.Linear(hidden_size, cont_dim)     # regresi√≥n step,duration,velocity\n",
    "\n",
    "    def forward(self, pitch_seq, cont_seq):\n",
    "        \"\"\"\n",
    "        pitch_seq: LongTensor (B, seq_len)\n",
    "        cont_seq: FloatTensor (B, seq_len, cont_dim)\n",
    "        returns:\n",
    "            pitch_logits: (B, vocab_size)\n",
    "            cont_pred: (B, cont_dim)\n",
    "        \"\"\"\n",
    "        emb = self.emb(pitch_seq)                # (B, seq_len, emb_dim)\n",
    "        x = torch.cat([emb, cont_seq], dim=-1)   # (B, seq_len, emb+cont)\n",
    "        out, (h, c) = self.lstm(x)               # out: (B, seq_len, hidden)\n",
    "        last = out[:, -1, :]                     # (B, hidden)\n",
    "        pitch_logits = self.pitch_out(last)      # (B, vocab_size)\n",
    "        cont_pred = self.cont_out(last)          # (B, cont_dim)\n",
    "        return pitch_logits, cont_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qN3alkGGgWhe"
   },
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stopping basado en una m√©trica escalar (modo 'min').\n",
    "    Guarda el mejor valor observado y cuenta √©pocas sin mejora.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=6, min_delta=0.0):\n",
    "        self.patience = int(patience)\n",
    "        self.min_delta = float(min_delta)\n",
    "        self.best = None\n",
    "        self.bad_epochs = 0\n",
    "\n",
    "    def step(self, value: float) -> bool:\n",
    "        \"\"\"\n",
    "        Devuelve True si hubo mejora y debe guardarse checkpoint.\n",
    "        \"\"\"\n",
    "        if self.best is None or (value < self.best - self.min_delta):\n",
    "            self.best = float(value)\n",
    "            self.bad_epochs = 0\n",
    "            return True\n",
    "        else:\n",
    "            self.bad_epochs += 1\n",
    "            return False\n",
    "\n",
    "    def should_stop(self) -> bool:\n",
    "        return self.bad_epochs >= self.patience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "f-ekixiAfR_B"
   },
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          train_loader,\n",
    "          val_loader,\n",
    "          device,\n",
    "          epochs=40,\n",
    "          lr=5e-4,\n",
    "          cont_loss_weight=50.0,\n",
    "          # üîπ par√°metros de early stopping\n",
    "          es_patience=6,\n",
    "          es_min_delta=0.0,\n",
    "          best_ckpt_path=\"OUTPUT/best_music_lstm.pth\",\n",
    "          verbose=True):\n",
    "    import torch\n",
    "    import torch.nn.functional as F\n",
    "    from torch.optim import AdamW\n",
    "\n",
    "    model.to(device)\n",
    "    opt = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_CE\": [],\n",
    "        \"val_MSE\": [],\n",
    "        \"val_total\": [],\n",
    "        \"best_epoch\": None,\n",
    "        \"best_val_total\": None,\n",
    "        \"best_ckpt_path\": best_ckpt_path,\n",
    "    }\n",
    "\n",
    "    # üîπ inicializa EarlyStopping\n",
    "    es = EarlyStopping(patience=es_patience, min_delta=es_min_delta)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ---- TRAIN ----\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        for (Xp, Xc), (yp, yc) in train_loader:\n",
    "            Xp = Xp.to(device)           # long [B, L]\n",
    "            Xc = Xc.to(device)           # float [B, L, 3]\n",
    "            yp = yp.to(device)           # long [B]\n",
    "            yc = yc.to(device)           # float [B, 3]\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits, cont_pred = model(Xp, Xc)         # logits [B,L,V]; cont_pred [B,L,3]\n",
    "            # ‚úÖ usa directamente la salida del modelo\n",
    "            logits_last = logits               # (B, V)\n",
    "            cont_last   = cont_pred            # (B, 3)\n",
    "\n",
    "            ce  = F.cross_entropy(logits_last, yp)    # CE para pitch\n",
    "            mse = F.mse_loss(cont_last, yc)           # MSE para continuos (normalizados)\n",
    "            loss = ce + cont_loss_weight * mse\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "\n",
    "            running += loss.item()\n",
    "\n",
    "        train_loss = running / max(1, len(train_loader))\n",
    "\n",
    "        # ---- VALID ----\n",
    "        model.eval()\n",
    "        val_ce = 0.0\n",
    "        val_mse = 0.0\n",
    "        with torch.no_grad():\n",
    "            for (Xp, Xc), (yp, yc) in val_loader:\n",
    "                Xp = Xp.to(device)\n",
    "                Xc = Xc.to(device)\n",
    "                yp = yp.to(device)\n",
    "                yc = yc.to(device)\n",
    "\n",
    "                logits, cont_pred = model(Xp, Xc)\n",
    "                logits_last = logits          # (B, V)\n",
    "                cont_last   = cont_pred       # (B, 3)\n",
    "\n",
    "                ce  = F.cross_entropy(logits_last, yp)\n",
    "                mse = F.mse_loss(cont_last, yc)\n",
    "                val_ce  += ce.item()\n",
    "                val_mse += mse.item()\n",
    "\n",
    "        val_ce  /= max(1, len(val_loader))\n",
    "        val_mse /= max(1, len(val_loader))\n",
    "        # üîπ m√©trica de parada coherente con tu loss de entrenamiento\n",
    "        val_total = val_ce + cont_loss_weight * val_mse\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_CE\"].append(val_ce)\n",
    "        history[\"val_MSE\"].append(val_mse)\n",
    "        history[\"val_total\"].append(val_total)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch} | train_loss={train_loss:.4f} | \"\n",
    "                  f\"val_CE={val_ce:.4f} | val_MSE={val_mse:.5f} | \"\n",
    "                  f\"val_total={val_total:.4f}\")\n",
    "\n",
    "        # üîπ checkpoint si mejora\n",
    "        if es.step(val_total):\n",
    "            torch.save({\"model_state\": model.state_dict()}, best_ckpt_path)\n",
    "            history[\"best_epoch\"] = epoch\n",
    "            history[\"best_val_total\"] = val_total\n",
    "            if verbose:\n",
    "                print(f\"  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en {best_ckpt_path}\")\n",
    "\n",
    "        # üîπ parar si no mejora por 'patience'\n",
    "        if es.should_stop():\n",
    "            if verbose:\n",
    "                print(f\"  ‚Ü≥ Early stopping en epoch {epoch} (best_epoch={history['best_epoch']})\")\n",
    "            break\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImKXlCTVgYa5"
   },
   "source": [
    "# Generacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1ufTV-9JfX4E"
   },
   "outputs": [],
   "source": [
    "#sample_from_logits\n",
    "def sample_from_logits_topk(logits, k=10, temperature=1.0):\n",
    "    \"\"\"\n",
    "    logits: torch.Tensor [vocab] o numpy.ndarray [vocab]\n",
    "    Devuelve: √≠ndice entero muestreado en top-k (con temperatura).\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    if not isinstance(logits, torch.Tensor):\n",
    "        logits = torch.from_numpy(logits)\n",
    "\n",
    "    # Evita k inv√°lido\n",
    "    vocab = logits.shape[-1]\n",
    "    k = max(1, min(int(k), int(vocab)))\n",
    "\n",
    "    # √öltimo paso de la secuencia si viene con eje extra\n",
    "    # (p.ej., [1, V] -> [V])\n",
    "    if logits.ndim > 1:\n",
    "        logits = logits.view(-1)\n",
    "\n",
    "    # Temperatura\n",
    "    if temperature is None or temperature <= 0:\n",
    "        temperature = 1.0\n",
    "    logits = logits / float(temperature)\n",
    "\n",
    "    # Top-k + muestreo\n",
    "    topk_vals, topk_idx = torch.topk(logits, k)            # [k]\n",
    "    topk_probs = torch.softmax(topk_vals, dim=-1)           # [k]\n",
    "    choice = torch.multinomial(topk_probs, 1)               # [1]\n",
    "    return int(topk_idx[choice].item())\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_sequence(model, device,\n",
    "                      seed_pitch_seq,   # list[int] o np.ndarray shape [T]\n",
    "                      seed_cont_seq,    # np.ndarray shape [T, 3]\n",
    "                      steps=200,\n",
    "                      idx2pitch=None,\n",
    "                      stats=None,\n",
    "                      temperature=1.0,\n",
    "                      top_k=10,\n",
    "                      max_context=32):\n",
    "    \"\"\"\n",
    "    Devuelve: np.ndarray shape [T_gen, 4] con columnas [pitch, step, dur, vel]\n",
    "              (en tu mismo formato downstream).\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import torch\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # --- Normalizaci√≥n defensiva de entradas ---\n",
    "    seed_pitch_seq = np.asarray(seed_pitch_seq, dtype=np.int64)          # [T]\n",
    "    seed_cont_seq  = np.asarray(seed_cont_seq,  dtype=np.float32)        # [T,3]\n",
    "    assert seed_cont_seq.ndim == 2 and seed_cont_seq.shape[1] == 3, \"seed_cont_seq debe ser [T,3]\"\n",
    "\n",
    "    # Construir tensores en el dispositivo sin listas de ndarrays:\n",
    "    def _mk_inputs(pitches_np, cont_np):\n",
    "        # recorta al contexto\n",
    "        pitches_np = pitches_np[-max_context:]\n",
    "        cont_np    = cont_np[-max_context:]\n",
    "        inp_pitch = torch.as_tensor(pitches_np, dtype=torch.long, device=device).unsqueeze(0)   # [1, L]\n",
    "        inp_cont  = torch.as_tensor(cont_np,    dtype=torch.float32, device=device).unsqueeze(0) # [1, L, 3]\n",
    "        return inp_pitch, inp_cont\n",
    "\n",
    "    # Copias de trabajo (para ir anexando)\n",
    "    cur_pitch = seed_pitch_seq.copy()\n",
    "    cur_cont  = seed_cont_seq.copy()\n",
    "\n",
    "    generated_rows = []  # acumularemos filas [pitch, step, dur, vel] (desnormalizadas al final si aplica)\n",
    "\n",
    "    for _ in range(steps):\n",
    "        inp_pitch, inp_cont = _mk_inputs(cur_pitch, cur_cont)\n",
    "        logits, cont_pred = model(inp_pitch, inp_cont)   # logits: [1,L,V]; cont_pred: [1,L,3] (normalizado)\n",
    "\n",
    "        # Tomar el √∫ltimo paso temporal\n",
    "        logits_last = logits.squeeze(0)                  # (V,)  torch.Tensor\n",
    "        cont_last   = cont_pred.squeeze(0).cpu().numpy() # (3,)  np.float32 (normalizado)\n",
    "\n",
    "        # Muestreo discreto\n",
    "        next_pitch_idx = sample_from_logits_topk(logits_last, k=top_k, temperature=temperature)\n",
    "\n",
    "        # ---- Desnormalizar los 3 continuos (si diste 'stats') ----\n",
    "        if stats is not None:\n",
    "            step = (cont_last[0] * (float(stats[\"step_std\"]) + 1e-6)) + float(stats[\"step_mean\"])\n",
    "            dur  = (cont_last[1] * (float(stats[\"dur_std\"])  + 1e-6)) + float(stats[\"dur_mean\"])\n",
    "            vel  = (cont_last[2] * (float(stats[\"vel_std\"])  + 1e-6)) + float(stats[\"vel_mean\"])\n",
    "        else:\n",
    "            step, dur, vel = float(cont_last[0]), float(cont_last[1]), float(cont_last[2])\n",
    "\n",
    "        # Seguridad: valores v√°lidos\n",
    "        next_pitch = int(np.clip(next_pitch_idx, 0, 127))\n",
    "        step = max(0.0, float(step))\n",
    "        dur  = max(1e-3, float(dur))\n",
    "        vel  = float(np.clip(vel, 1.0, 127.0))\n",
    "\n",
    "        # Append a las listas de estado (en formato NORMALIZADO para el modelo)\n",
    "        # Nota: para la siguiente iteraci√≥n el modelo necesita los continuos NORMALIZADOS,\n",
    "        # por lo que guardamos adem√°s la versi√≥n normalizada:\n",
    "        if stats is not None:\n",
    "            step_n = (step - float(stats[\"step_mean\"])) / (float(stats[\"step_std\"]) + 1e-6)\n",
    "            dur_n  = (dur  - float(stats[\"dur_mean\"]))  / (float(stats[\"dur_std\"])  + 1e-6)\n",
    "            vel_n  = (vel  - float(stats[\"vel_mean\"]))  / (float(stats[\"vel_std\"])  + 1e-6)\n",
    "            cur_cont = np.vstack([cur_cont, [step_n, dur_n, vel_n]]).astype(np.float32)\n",
    "        else:\n",
    "            cur_cont = np.vstack([cur_cont, [step, dur, vel]]).astype(np.float32)\n",
    "\n",
    "        cur_pitch = np.append(cur_pitch, next_pitch).astype(np.int64)\n",
    "\n",
    "        # Guardar fila desnormalizada para el MIDI\n",
    "        generated_rows.append([next_pitch, step, dur, vel])\n",
    "\n",
    "    return np.asarray(generated_rows, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5fFn6iYgaUw"
   },
   "source": [
    "# Pipeline completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZSwCOwbfiQ4",
    "outputId": "6a88845d-4c25-4ac3-812e-601f5c7fed42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Extrayendo secuencias crudas...\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=4225\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=3300\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2954\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2173\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3868\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2580\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3185\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2792\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2854\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=3395\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1850\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=885\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3239\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=3186\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2970\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1822\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2592\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2073\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1779\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2002\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2191\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1494\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2027\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1588\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=5268\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=5465\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=1374\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=917\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=1705\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=1443\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=3118\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=2461\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2418\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2555\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2150\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=993\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2050\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=551\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3267\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2449\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1447\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1200\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=872\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=781\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=563\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=495\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1515\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1135\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1372\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=952\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1088\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=900\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2673\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2480\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=806\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=509\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1721\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1673\n",
      "  secuencias extra√≠das: 25\n",
      "2) Estandarizando (pitch se mantiene intacto)...\n",
      "  stats: {'step_mean': np.float32(0.098957), 'step_std': np.float32(0.18229377), 'dur_mean': np.float32(0.33029), 'dur_std': np.float32(0.41488776), 'vel_mean': np.float32(48.245155), 'vel_std': np.float32(17.51278)}\n",
      "3) Creando ventanas...\n",
      "  Train -> Xp_tr: (76482, 32) Xc_tr: (76482, 32, 3) yp_tr: (76482,)\n",
      "  Valid -> Xp_va: (22357, 32) Xc_va: (22357, 32, 3) yp_va: (22357,)\n",
      "vocab_size: 128\n",
      "Training model on device: cuda\n",
      "Epoch 1 | train_loss=35.2130 | val_CE=4.0524 | val_MSE=0.39785 | val_total=23.9451\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT/best_music_lstm.pth\n",
      "Epoch 2 | train_loss=27.8560 | val_CE=3.9662 | val_MSE=0.36526 | val_total=22.2293\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT/best_music_lstm.pth\n",
      "Epoch 3 | train_loss=25.4272 | val_CE=3.9671 | val_MSE=0.34419 | val_total=21.1766\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT/best_music_lstm.pth\n",
      "Epoch 4 | train_loss=23.4120 | val_CE=3.9062 | val_MSE=0.35024 | val_total=21.4183\n",
      "Epoch 5 | train_loss=21.6927 | val_CE=3.8658 | val_MSE=0.33892 | val_total=20.8120\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT/best_music_lstm.pth\n",
      "Epoch 6 | train_loss=19.9914 | val_CE=3.8628 | val_MSE=0.35157 | val_total=21.4415\n",
      "Epoch 7 | train_loss=18.6534 | val_CE=3.8284 | val_MSE=0.33691 | val_total=20.6741\n",
      "  ‚Ü≥ ‚úì Nuevo mejor modelo guardado en OUTPUT/best_music_lstm.pth\n",
      "Epoch 8 | train_loss=17.1289 | val_CE=3.8251 | val_MSE=0.34628 | val_total=21.1392\n",
      "Epoch 9 | train_loss=15.8784 | val_CE=3.8299 | val_MSE=0.34771 | val_total=21.2153\n",
      "Epoch 10 | train_loss=14.6018 | val_CE=3.8231 | val_MSE=0.34845 | val_total=21.2456\n",
      "Epoch 11 | train_loss=13.5706 | val_CE=3.7903 | val_MSE=0.34681 | val_total=21.1306\n",
      "Epoch 12 | train_loss=12.9673 | val_CE=3.7923 | val_MSE=0.34878 | val_total=21.2311\n",
      "Epoch 13 | train_loss=11.5705 | val_CE=3.7905 | val_MSE=0.35717 | val_total=21.6492\n",
      "  ‚Ü≥ Early stopping en epoch 13 (best_epoch=7)\n",
      "[Gen 1] Usando semilla index: 33948\n",
      "‚úÖ MIDI guardado en: OUTPUT/generated_music_lstm_1.mid (Acoustic Grand Piano)\n",
      "[Gen 1] WAV guardado en:  OUTPUT\\generated_music_lstm_1.wav\n",
      "[Gen 1] MIDI guardado en: OUTPUT\\generated_music_lstm_1.mid\n",
      "[Gen 2] Usando semilla index: 38110\n",
      "‚úÖ MIDI guardado en: OUTPUT/generated_music_lstm_2.mid (Acoustic Grand Piano)\n",
      "[Gen 2] WAV guardado en:  OUTPUT\\generated_music_lstm_2.wav\n",
      "[Gen 2] MIDI guardado en: OUTPUT\\generated_music_lstm_2.mid\n",
      "[Gen 3] Usando semilla index: 24343\n",
      "‚úÖ MIDI guardado en: OUTPUT/generated_music_lstm_3.mid (Acoustic Grand Piano)\n",
      "[Gen 3] WAV guardado en:  OUTPUT\\generated_music_lstm_3.wav\n",
      "[Gen 3] MIDI guardado en: OUTPUT\\generated_music_lstm_3.mid\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"1) Extrayendo secuencias crudas...\")\n",
    "    raw_sequences = extract_raw_note_sequences(ROOT_DIR, instrument_name= INSTRUMENT_NAME, composer_name=COMPOSER)\n",
    "    print(f\"  secuencias extra√≠das: {len(raw_sequences)}\")\n",
    "\n",
    "    train_sequences, val_sequences = train_test_split(raw_sequences, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "    print(\"2) Estandarizando (pitch se mantiene intacto)...\")\n",
    "    standardized_sequences, stats = standardize_note_sequences(train_sequences)\n",
    "    print(\"  stats:\", stats)\n",
    "\n",
    "\n",
    "\n",
    "    def apply_standardization(seqs, stats):\n",
    "        out = []\n",
    "        for seq in seqs:\n",
    "            s = seq.copy()\n",
    "            s[:,1] = (s[:,1]-stats[\"step_mean\"])/(stats[\"step_std\"]+1e-6)\n",
    "            s[:,2] = (s[:,2]-stats[\"dur_mean\"] )/(stats[\"dur_std\"] +1e-6)\n",
    "            s[:,3] = (s[:,3]-stats[\"vel_mean\"] )/(stats[\"vel_std\"] +1e-6)\n",
    "            out.append(s)\n",
    "        return out\n",
    "\n",
    "    val_standardized = apply_standardization(val_sequences, stats)\n",
    "    print(\"3) Creando ventanas...\")\n",
    "    (Xp_tr, Xc_tr), (yp_tr, yc_tr) = create_windows(standardized_sequences, seq_len=SEQ_LEN)\n",
    "    (Xp_va, Xc_va), (yp_va, yc_va) = create_windows(val_standardized,       seq_len=SEQ_LEN)\n",
    "\n",
    "    print(\"  Train -> Xp_tr:\", Xp_tr.shape, \"Xc_tr:\", Xc_tr.shape, \"yp_tr:\", yp_tr.shape)\n",
    "    print(\"  Valid -> Xp_va:\", Xp_va.shape, \"Xc_va:\", Xc_va.shape, \"yp_va:\", yp_va.shape)\n",
    "\n",
    "\n",
    "    # construir vocab (opcional\n",
    "    if Xp_tr.shape[0] == 0:\n",
    "        raise RuntimeError(\"No hay muestras. Aumenta datos o reduce SEQ_LEN.\")\n",
    "    max_pitch = int(np.max(Xp_tr))\n",
    "    vocab_size = max(128, max_pitch + 1)\n",
    "    print(\"vocab_size:\", vocab_size)\n",
    "\n",
    "    # dataset\n",
    "    train_ds = MusicWindowsDataset(Xp_tr, Xc_tr, yp_tr, yc_tr)\n",
    "    val_ds   = MusicWindowsDataset(Xp_va,   Xc_va,   yp_va,   yc_va)\n",
    "    loader   = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "    vloader  = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "    # modelo\n",
    "    model = MusicLSTM(vocab_size=vocab_size, emb_dim=64, cont_dim=3, hidden_size= HIDDEN_SIZE, num_layers= NUM_LAYERS,dropout=DROPOUT) # Ajustado num_layers\n",
    "    print(\"Training model on device:\", DEVICE)\n",
    "    history = train(\n",
    "        model,\n",
    "        train_loader=loader,\n",
    "        val_loader=vloader,\n",
    "        device=DEVICE,\n",
    "        epochs=EPOCHS,\n",
    "        lr=LR,\n",
    "        cont_loss_weight= PESO_LOSS_CONT,\n",
    "        es_patience=6,                 # ajusta si quieres m√°s/menos paciencia\n",
    "        es_min_delta=1e-4,             # mejora m√≠nima para considerar \"mejora\"\n",
    "        best_ckpt_path=(OUTPUT_DIR / \"best_music_lstm.pth\").as_posix(),\n",
    "    )\n",
    "\n",
    "    # guardar modelo y stats\n",
    "    # Cargar mejor estado antes de generar\n",
    "    best_ckpt = torch.load((OUTPUT_DIR / \"best_music_lstm.pth\").as_posix(), map_location=DEVICE)\n",
    "    model.load_state_dict(best_ckpt[\"model_state\"])\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    # ------------------ Generaci√≥n de ejemplos ------------------\n",
    " \n",
    "    total_samples = Xp_tr.shape[0]\n",
    "   \n",
    "    # Elegimos √≠ndices de semillas distintos si hay suficientes, o con reposici√≥n si no\n",
    "    idx_pool = list(range(total_samples))\n",
    "    if total_samples >= NUM_SEQS:\n",
    "        seed_indices = random.sample(idx_pool, NUM_SEQS)  # sin reemplazo\n",
    "    else:\n",
    "        seed_indices = [random.choice(idx_pool) for _ in range(NUM_SEQS)]  # con reemplazo\n",
    "    \n",
    "    for j, idx in enumerate(seed_indices, start=1):\n",
    "        seed_pitch = Xp_tr[idx].tolist()\n",
    "        seed_cont  = Xc_tr[idx]\n",
    "        print(f\"[Gen {j}] Usando semilla index: {idx}\")\n",
    "    \n",
    "        generated = generate_sequence(\n",
    "            model, DEVICE,\n",
    "            seed_pitch, seed_cont,\n",
    "            steps=STEPS_PER_SEQ,\n",
    "            idx2pitch=None,\n",
    "            stats=stats,\n",
    "            temperature=TEMPERATURE,\n",
    "            top_k=TOP_K   # prueba k=10; ajusta a 5‚Äì20 seg√∫n diversidad deseada\n",
    "        )\n",
    "        if generated.shape[0] > 200:\n",
    "          generated = generated[-200:, :]\n",
    "    \n",
    "        midi_path = OUTPUT_DIR / f\"generated_music_lstm_{j}.mid\"\n",
    "        wav_path = OUTPUT_DIR / f\"generated_music_lstm_{j}.wav\"\n",
    "        # Si tu save_sequence_to_midi acepta instrument_name:\n",
    "        save_sequence_to_midi(generated, output_path=midi_path.as_posix(), instrument_name=INSTRUMENT_NAME)\n",
    "        \n",
    "        try:\n",
    "            render_midi_to_wav(midi_path.as_posix(), wav_path.as_posix(), SF2, samplerate=44100)\n",
    "            print(f\"[Gen {j}] WAV guardado en:  {wav_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Gen {j}] ‚ö†Ô∏è No se pudo generar WAV (revisa pyfluidsynth/DLL/SF2): {e}\")\n",
    "        \n",
    "        print(f\"[Gen {j}] MIDI guardado en: {midi_path}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "iJrvj5YdhVoo",
    "C04D1njqhYFn",
    "w1n9XyNyhcej",
    "GtygejbZhgP-",
    "vH4IXLREhjSW"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (jlabclean)",
   "language": "python",
   "name": "jlabclean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
