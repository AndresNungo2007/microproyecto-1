{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IW1eQD90BIgG",
    "outputId": "e262966a-1613-46c1-ecd9-f57aa3bb2d5d"
   },
   "outputs": [],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3qMMYFXMBgxe",
    "outputId": "c795ad7b-f346-4455-e70d-a6f832dc6c39"
   },
   "outputs": [],
   "source": [
    "#!pip install pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CwOU59cOBqHA",
    "outputId": "2a037d31-79e2-4237-d960-a977dc93152c"
   },
   "outputs": [],
   "source": [
    "#!pip install mido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3ObmPXrCK_z"
   },
   "source": [
    "## Si es Gooogle colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKwqyl42CMPV",
    "outputId": "2d3f4677-f52b-4f48-de02-7eae82177470"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJAlithrCXJ5",
    "outputId": "5050e97a-b66c-4a87-c063-c8709ba2dfdd"
   },
   "outputs": [],
   "source": [
    "#!ls /content/drive/MyDrive/\"Colab Notebooks\"/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CDLL 'C:\\tools\\fluidsynth\\bin\\libfluidsynth-3.dll', handle 7ffc6cd80000 at 0x157fd1f5950>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Bootstrap FluidSynth (Windows, persistente por sesión de kernel) ---\n",
    "import os\n",
    "if os.name == \"nt\":\n",
    "    DLL_DIR = r\"C:\\tools\\fluidsynth\\bin\"  # carpeta donde pusiste libfluidsynth-3.dll\n",
    "    if hasattr(os, \"add_dll_directory\"):\n",
    "        os.add_dll_directory(DLL_DIR)\n",
    "    os.environ[\"FLUIDSYNTH_LIBRARY\"] = os.path.join(DLL_DIR, \"libfluidsynth-3.dll\")\n",
    "\n",
    "# (opcional) smoke test de la DLL para fallar pronto si algo cambió\n",
    "from ctypes import CDLL\n",
    "CDLL(os.environ[\"FLUIDSYNTH_LIBRARY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fluidsynth as pyfluidsynth\n",
    "import pretty_midi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WY-yhu2NgFf6"
   },
   "source": [
    "# Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_J3PzSeYEF4S"
   },
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import os, sys\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from scipy.io.wavfile import write\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPTN5Y8YgIjn"
   },
   "source": [
    "# Configuracion variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BU-R44U_GJ3O"
   },
   "outputs": [],
   "source": [
    "ROOT_DIR =  \"./Dataset/music_artist\"  # \"/content/drive/MyDrive/Colab Notebooks/Dataset/TEST\"   # <-- directorio raíz con carpetas de compositores\n",
    "OUTPUT_DIR = Path(\"./OUTPUT\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SEQ_LEN = 32 # Block size\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_SIZE = 384\n",
    "EPOCHS = 40\n",
    "LR = 3e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_TYPE = \"LSTM\"  # opciones: \"RNN\", \"LSTM\", \"GRU\"\n",
    "INSTRUMENT_NAME = \"Acoustic Grand Piano\"\n",
    "COMPOSER = \"schubert\"  # este es el artista que tiene más datos\n",
    "NUM_SEQS       = 3  # Número de secuencias a generar\n",
    "STEPS_PER_SEQ  = 200  # Notas que debe tener cada secuencia\n",
    "TEMPERATURE    = 0.7  # Temperatura\n",
    "NUM_LAYERS = 4\n",
    "DROPOUT = 0.3\n",
    "TOP_K = 20\n",
    "PESO_LOSS_CONT = 50\n",
    "SF2 = \"./soundfonts/FluidR3_GM.sf2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 13\n",
    "random.seed(RANDOM_STATE); np.random.seed(RANDOM_STATE); torch.manual_seed(RANDOM_STATE)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "beKjgq-gGSI6",
    "outputId": "764903b1-722b-490c-d606-c5f8b7d8f6ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFgUa-JNgPMd"
   },
   "source": [
    "# 1. Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJrvj5YdhVoo"
   },
   "source": [
    "## Lectura MIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_raw_note_sequences(root_dir, instrument_name=None, program_number=None, composer_name=None):\n",
    "    raw_sequences = []\n",
    "    candidates = [composer_name] if composer_name else [\n",
    "        d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))\n",
    "    ]\n",
    "    for composer in candidates:\n",
    "        folder = os.path.join(root_dir, composer)\n",
    "        midi_files = glob.glob(os.path.join(folder, \"*.mid\"))\n",
    "\n",
    "        for mf in midi_files:\n",
    "            try:\n",
    "                pm = pretty_midi.PrettyMIDI(mf)\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo leer {mf}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # --- Selección de instrumento ---\n",
    "            chosen_instruments = []\n",
    "            for i, inst in enumerate(pm.instruments):\n",
    "                name = pretty_midi.program_to_instrument_name(inst.program)\n",
    "                print(f\"[{i}] prog={inst.program:>2} name={name} notas={len(inst.notes)}\")\n",
    "                if instrument_name is not None:\n",
    "                    inst_name = pretty_midi.program_to_instrument_name(inst.program)\n",
    "                    if inst_name.lower() == instrument_name.lower():\n",
    "                        chosen_instruments.append(inst)\n",
    "                elif program_number is not None:\n",
    "                    if inst.program == program_number:\n",
    "                        chosen_instruments.append(inst)\n",
    "\n",
    "            # Si no hubo match explícito y no se especificó filtro, tomamos el primero (comportamiento viejo)\n",
    "            if instrument_name is None and program_number is None:\n",
    "                chosen_instruments = pm.instruments[:1]  # solo el primero\n",
    "\n",
    "            if not chosen_instruments:\n",
    "                # Nada que extraer en este archivo para el instrumento pedido\n",
    "                continue\n",
    "\n",
    "            # --- Extraer notas SOLO del/los instrumentos elegidos ---\n",
    "            notes = []\n",
    "            for inst in chosen_instruments:\n",
    "                for note_mus in inst.notes:\n",
    "                    start = note_mus.start\n",
    "                    end = note_mus.end\n",
    "                    duration = end - start\n",
    "                    velocity = note_mus.velocity\n",
    "                    notes.append((start, note_mus.pitch, duration, velocity))\n",
    "\n",
    "            if not notes:\n",
    "                continue\n",
    "\n",
    "            # Ordenar por inicio y construir [pitch, step, duration, velocity]\n",
    "            notes.sort(key=lambda x: x[0])\n",
    "            note_feats = []\n",
    "            prev_start = notes[0][0]\n",
    "            for start, pitch, duration, velocity in notes:\n",
    "                step = start - prev_start\n",
    "                prev_start = start\n",
    "                note_feats.append([pitch, step, duration, velocity])\n",
    "\n",
    "            if note_feats:\n",
    "                raw_sequences.append(np.array(note_feats, dtype=np.float32))\n",
    "\n",
    "    return raw_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C04D1njqhYFn"
   },
   "source": [
    "## Estandarizar variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Jv0A8oHWKEne"
   },
   "outputs": [],
   "source": [
    "def standardize_note_sequences(sequences):\n",
    "    \"\"\"\n",
    "    Estandariza las variables continuas (step, duration, velocity)\n",
    "    y mantiene el pitch intacto para usarlo luego con embeddings.\n",
    "    \"\"\"\n",
    "    all_steps, all_durations, all_velocities = [], [], []\n",
    "\n",
    "    # Recolectar todas las variables continuas para calcular media y std global\n",
    "    for seq in sequences:\n",
    "        all_steps.extend(seq[:, 1])\n",
    "        all_durations.extend(seq[:, 2])\n",
    "        all_velocities.extend(seq[:, 3])\n",
    "\n",
    "    # Estadísticas globales\n",
    "    step_mean, step_std = np.mean(all_steps), np.std(all_steps)\n",
    "    dur_mean, dur_std = np.mean(all_durations), np.std(all_durations)\n",
    "    vel_mean, vel_std = np.mean(all_velocities), np.std(all_velocities)\n",
    "\n",
    "    standardized = []\n",
    "    for seq in sequences:\n",
    "        seq_std = seq.copy()\n",
    "        # No tocar pitch (columna 0)\n",
    "        seq_std[:, 1] = (seq[:, 1] - step_mean) / (step_std + 1e-6)\n",
    "        seq_std[:, 2] = (seq[:, 2] - dur_mean) / (dur_std + 1e-6)\n",
    "        seq_std[:, 3] = (seq[:, 3] - vel_mean) / (vel_std + 1e-6)\n",
    "        standardized.append(seq_std)\n",
    "\n",
    "    stats = {\n",
    "        \"step_mean\": step_mean, \"step_std\": step_std,\n",
    "        \"dur_mean\": dur_mean, \"dur_std\": dur_std,\n",
    "        \"vel_mean\": vel_mean, \"vel_std\": vel_std\n",
    "    }\n",
    "\n",
    "    return standardized, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1n9XyNyhcej"
   },
   "source": [
    "## Crear ventanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VWsFUkyhS404"
   },
   "outputs": [],
   "source": [
    "def create_windows(sequences, seq_len=32):\n",
    "    \"\"\"\n",
    "    Crea pares (X, y) para entrenamiento a partir de las secuencias estandarizadas.\n",
    "    X: secuencia de longitud seq_len\n",
    "    y: la nota siguiente\n",
    "    \"\"\"\n",
    "    X_pitch, X_cont, y_pitch, y_cont = [], [], [], []\n",
    "\n",
    "    for seq in sequences:\n",
    "        if len(seq) < seq_len + 1:\n",
    "            continue\n",
    "\n",
    "        # Dividir en ventanas\n",
    "        for i in range(len(seq) - seq_len):\n",
    "            window = seq[i:i+seq_len]\n",
    "            target = seq[i+seq_len]\n",
    "\n",
    "            # Separar pitch (entero) y las features continuas\n",
    "            X_pitch.append(window[:, 0].astype(np.int64))     # pitch\n",
    "            X_cont.append(window[:, 1:].astype(np.float32))   # step, duration, velocity\n",
    "            y_pitch.append(int(target[0]))                    # pitch de la siguiente nota\n",
    "            y_cont.append(target[1:].astype(np.float32))      # step, duration, velocity siguientes\n",
    "\n",
    "    # Convertir a arrays numpy\n",
    "    X_pitch = np.array(X_pitch, dtype=np.int64)\n",
    "    X_cont = np.array(X_cont, dtype=np.float32)\n",
    "    y_pitch = np.array(y_pitch, dtype=np.int64)\n",
    "    y_cont = np.array(y_cont, dtype=np.float32)\n",
    "\n",
    "    return (X_pitch, X_cont), (y_pitch, y_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vH4IXLREhjSW"
   },
   "source": [
    "## Guardar secuencias a MIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kkQMkq6idGIz"
   },
   "outputs": [],
   "source": [
    "def save_sequence_to_midi(seq, output_path=\"generated.mid\", instrument_name=\"Acoustic Grand Piano\"):\n",
    "    \"\"\"\n",
    "    seq: np.array (N,4) con columnas [pitch, step, duration, velocity] en ESCALA REAL.\n",
    "    \"\"\"\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    try:\n",
    "        program_number = pretty_midi.instrument_name_to_program(instrument_name)\n",
    "    except ValueError:\n",
    "        program_number = 0\n",
    "    instrument = pretty_midi.Instrument(program=program_number)\n",
    "\n",
    "    # Asegurar valores válidos\n",
    "    pitch    = seq[:, 0].astype(int)\n",
    "    step     = np.maximum(seq[:, 1].astype(float), 0.0)\n",
    "    duration = np.maximum(seq[:, 2].astype(float), 0.01)\n",
    "    velocity = np.clip(seq[:, 3].astype(float), 0, 127).astype(int)\n",
    "\n",
    "    # Reconstruir tiempos absolutos\n",
    "    t = 0.0\n",
    "    for p, s, d, v in zip(pitch, step, duration, velocity):\n",
    "        t += s\n",
    "        note = pretty_midi.Note(velocity=int(v), pitch=int(p), start=float(t), end=float(t + d))\n",
    "        instrument.notes.append(note)\n",
    "\n",
    "    pm.instruments.append(instrument)\n",
    "    pm.write(output_path)\n",
    "    print(f\"✅ MIDI guardado en: {output_path} ({instrument_name})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_std_sequence_to_midi(seq_std, stats, output_path=\"reconstructed.mid\", instrument_name=\"Acoustic Grand Piano\"):\n",
    "    \"\"\"\n",
    "    seq_std: np.array (N,4) [pitch, stepZ, durationZ, velocityZ] estandarizados.\n",
    "    stats: dict con medias/stds {'step_mean','step_std','dur_mean','dur_std','vel_mean','vel_std'}\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    # Desestandarizar\n",
    "    pitch    = seq_std[:, 0]\n",
    "    step     = seq_std[:, 1] * stats[\"step_std\"] + stats[\"step_mean\"]\n",
    "    duration = seq_std[:, 2] * stats[\"dur_std\"] + stats[\"dur_mean\"]\n",
    "    velocity = seq_std[:, 3] * stats[\"vel_std\"] + stats[\"vel_mean\"]\n",
    "    seq_real = np.stack([pitch, step, duration, velocity], axis=1)\n",
    "    # Reutilizar la canónica\n",
    "    save_sequence_to_midi(seq_real, output_path=output_path, instrument_name=instrument_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasar de MIDI a WAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_midi_to_wav(midi_path: str, wav_path: str, sf2_path: str, samplerate: int = 44100):\n",
    "    fs = pyfluidsynth.Synth(samplerate=samplerate)  # <--- usa el alias importado\n",
    "    sfid = fs.sfload(sf2_path)\n",
    "    try:\n",
    "        pm = pretty_midi.PrettyMIDI(midi_path)\n",
    "        audio = pm.fluidsynth(fs=samplerate, synthesizer=fs, sfid=sfid, normalize=True)  # normaliza p/evitar clipping\n",
    "\n",
    "        # Convertir a PCM_16 (compatible con Reproductor de Windows)\n",
    "        peak = float(np.max(np.abs(audio))) if audio.size else 1.0\n",
    "        if peak == 0: peak = 1.0\n",
    "        audio = (audio / peak) * 0.99\n",
    "        audio_int16 = (np.clip(audio, -1, 1) * 32767).astype(np.int16)\n",
    "\n",
    "        write(wav_path, samplerate, audio_int16)\n",
    "    finally:\n",
    "        fs.delete()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDtYzja2g0S3"
   },
   "source": [
    "#  Dataset pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4KJLzr0Xg0CI"
   },
   "outputs": [],
   "source": [
    "class MusicWindowsDataset(Dataset):\n",
    "    def __init__(self, Xp, Xc, yp, yc):\n",
    "        self.Xp = Xp\n",
    "        self.Xc = Xc\n",
    "        self.yp = yp\n",
    "        self.yc = yc\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Xp)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        import torch\n",
    "        Xp = torch.as_tensor(self.Xp[i], dtype=torch.long)        # [L]\n",
    "        Xc = torch.as_tensor(self.Xc[i], dtype=torch.float32)     # [L,3]\n",
    "        yp = torch.as_tensor(self.yp[i], dtype=torch.long)        # []\n",
    "        yc = torch.as_tensor(self.yc[i], dtype=torch.float32)     # [3]\n",
    "        return (Xp, Xc), (yp, yc)  # <<< clave: 2-tuplas anidadas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No5bj9H_gUW7"
   },
   "source": [
    "# Test modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "p1x6IR8wfQj8"
   },
   "outputs": [],
   "source": [
    "class MusicLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=64, cont_dim=3, hidden_size=256, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=None)\n",
    "        self.input_dim = emb_dim + cont_dim\n",
    "        self.lstm = nn.LSTM(self.input_dim, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.pitch_out = nn.Linear(hidden_size, vocab_size)  # clasificación pitch\n",
    "        self.cont_out = nn.Linear(hidden_size, cont_dim)     # regresión step,duration,velocity\n",
    "\n",
    "    def forward(self, pitch_seq, cont_seq):\n",
    "        \"\"\"\n",
    "        pitch_seq: LongTensor (B, seq_len)\n",
    "        cont_seq: FloatTensor (B, seq_len, cont_dim)\n",
    "        returns:\n",
    "            pitch_logits: (B, vocab_size)\n",
    "            cont_pred: (B, cont_dim)\n",
    "        \"\"\"\n",
    "        emb = self.emb(pitch_seq)                # (B, seq_len, emb_dim)\n",
    "        x = torch.cat([emb, cont_seq], dim=-1)   # (B, seq_len, emb+cont)\n",
    "        out, (h, c) = self.lstm(x)               # out: (B, seq_len, hidden)\n",
    "        last = out[:, -1, :]                     # (B, hidden)\n",
    "        pitch_logits = self.pitch_out(last)      # (B, vocab_size)\n",
    "        cont_pred = self.cont_out(last)          # (B, cont_dim)\n",
    "        return pitch_logits, cont_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qN3alkGGgWhe"
   },
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stopping basado en una métrica escalar (modo 'min').\n",
    "    Guarda el mejor valor observado y cuenta épocas sin mejora.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=6, min_delta=0.0):\n",
    "        self.patience = int(patience)\n",
    "        self.min_delta = float(min_delta)\n",
    "        self.best = None\n",
    "        self.bad_epochs = 0\n",
    "\n",
    "    def step(self, value: float) -> bool:\n",
    "        \"\"\"\n",
    "        Devuelve True si hubo mejora y debe guardarse checkpoint.\n",
    "        \"\"\"\n",
    "        if self.best is None or (value < self.best - self.min_delta):\n",
    "            self.best = float(value)\n",
    "            self.bad_epochs = 0\n",
    "            return True\n",
    "        else:\n",
    "            self.bad_epochs += 1\n",
    "            return False\n",
    "\n",
    "    def should_stop(self) -> bool:\n",
    "        return self.bad_epochs >= self.patience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "f-ekixiAfR_B"
   },
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          train_loader,\n",
    "          val_loader,\n",
    "          device,\n",
    "          epochs=40,\n",
    "          lr=5e-4,\n",
    "          cont_loss_weight=50.0,\n",
    "          # 🔹 parámetros de early stopping\n",
    "          es_patience=6,\n",
    "          es_min_delta=0.0,\n",
    "          best_ckpt_path=\"OUTPUT/best_music_lstm.pth\",\n",
    "          verbose=True):\n",
    "    import torch\n",
    "    import torch.nn.functional as F\n",
    "    from torch.optim import AdamW\n",
    "\n",
    "    model.to(device)\n",
    "    opt = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_CE\": [],\n",
    "        \"val_MSE\": [],\n",
    "        \"val_total\": [],\n",
    "        \"best_epoch\": None,\n",
    "        \"best_val_total\": None,\n",
    "        \"best_ckpt_path\": best_ckpt_path,\n",
    "    }\n",
    "\n",
    "    # 🔹 inicializa EarlyStopping\n",
    "    es = EarlyStopping(patience=es_patience, min_delta=es_min_delta)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ---- TRAIN ----\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        for (Xp, Xc), (yp, yc) in train_loader:\n",
    "            Xp = Xp.to(device)           # long [B, L]\n",
    "            Xc = Xc.to(device)           # float [B, L, 3]\n",
    "            yp = yp.to(device)           # long [B]\n",
    "            yc = yc.to(device)           # float [B, 3]\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits, cont_pred = model(Xp, Xc)         # logits [B,L,V]; cont_pred [B,L,3]\n",
    "            # ✅ usa directamente la salida del modelo\n",
    "            logits_last = logits               # (B, V)\n",
    "            cont_last   = cont_pred            # (B, 3)\n",
    "\n",
    "            ce  = F.cross_entropy(logits_last, yp)    # CE para pitch\n",
    "            mse = F.mse_loss(cont_last, yc)           # MSE para continuos (normalizados)\n",
    "            loss = ce + cont_loss_weight * mse\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "\n",
    "            running += loss.item()\n",
    "\n",
    "        train_loss = running / max(1, len(train_loader))\n",
    "\n",
    "        # ---- VALID ----\n",
    "        model.eval()\n",
    "        val_ce = 0.0\n",
    "        val_mse = 0.0\n",
    "        with torch.no_grad():\n",
    "            for (Xp, Xc), (yp, yc) in val_loader:\n",
    "                Xp = Xp.to(device)\n",
    "                Xc = Xc.to(device)\n",
    "                yp = yp.to(device)\n",
    "                yc = yc.to(device)\n",
    "\n",
    "                logits, cont_pred = model(Xp, Xc)\n",
    "                logits_last = logits          # (B, V)\n",
    "                cont_last   = cont_pred       # (B, 3)\n",
    "\n",
    "                ce  = F.cross_entropy(logits_last, yp)\n",
    "                mse = F.mse_loss(cont_last, yc)\n",
    "                val_ce  += ce.item()\n",
    "                val_mse += mse.item()\n",
    "\n",
    "        val_ce  /= max(1, len(val_loader))\n",
    "        val_mse /= max(1, len(val_loader))\n",
    "        # 🔹 métrica de parada coherente con tu loss de entrenamiento\n",
    "        val_total = val_ce + cont_loss_weight * val_mse\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_CE\"].append(val_ce)\n",
    "        history[\"val_MSE\"].append(val_mse)\n",
    "        history[\"val_total\"].append(val_total)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch} | train_loss={train_loss:.4f} | \"\n",
    "                  f\"val_CE={val_ce:.4f} | val_MSE={val_mse:.5f} | \"\n",
    "                  f\"val_total={val_total:.4f}\")\n",
    "\n",
    "        # 🔹 checkpoint si mejora\n",
    "        if es.step(val_total):\n",
    "            torch.save({\"model_state\": model.state_dict()}, best_ckpt_path)\n",
    "            history[\"best_epoch\"] = epoch\n",
    "            history[\"best_val_total\"] = val_total\n",
    "            if verbose:\n",
    "                print(f\"  ↳ ✓ Nuevo mejor modelo guardado en {best_ckpt_path}\")\n",
    "\n",
    "        # 🔹 parar si no mejora por 'patience'\n",
    "        if es.should_stop():\n",
    "            if verbose:\n",
    "                print(f\"  ↳ Early stopping en epoch {epoch} (best_epoch={history['best_epoch']})\")\n",
    "            break\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImKXlCTVgYa5"
   },
   "source": [
    "# Generacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1ufTV-9JfX4E"
   },
   "outputs": [],
   "source": [
    "#sample_from_logits\n",
    "def sample_from_logits_topk(logits, k=10, temperature=1.0):\n",
    "    \"\"\"\n",
    "    logits: torch.Tensor [vocab] o numpy.ndarray [vocab]\n",
    "    Devuelve: índice entero muestreado en top-k (con temperatura).\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    if not isinstance(logits, torch.Tensor):\n",
    "        logits = torch.from_numpy(logits)\n",
    "\n",
    "    # Evita k inválido\n",
    "    vocab = logits.shape[-1]\n",
    "    k = max(1, min(int(k), int(vocab)))\n",
    "\n",
    "    # Último paso de la secuencia si viene con eje extra\n",
    "    # (p.ej., [1, V] -> [V])\n",
    "    if logits.ndim > 1:\n",
    "        logits = logits.view(-1)\n",
    "\n",
    "    # Temperatura\n",
    "    if temperature is None or temperature <= 0:\n",
    "        temperature = 1.0\n",
    "    logits = logits / float(temperature)\n",
    "\n",
    "    # Top-k + muestreo\n",
    "    topk_vals, topk_idx = torch.topk(logits, k)            # [k]\n",
    "    topk_probs = torch.softmax(topk_vals, dim=-1)           # [k]\n",
    "    choice = torch.multinomial(topk_probs, 1)               # [1]\n",
    "    return int(topk_idx[choice].item())\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_sequence(model, device,\n",
    "                      seed_pitch_seq,   # list[int] o np.ndarray shape [T]\n",
    "                      seed_cont_seq,    # np.ndarray shape [T, 3]\n",
    "                      steps=200,\n",
    "                      idx2pitch=None,\n",
    "                      stats=None,\n",
    "                      temperature=1.0,\n",
    "                      top_k=10,\n",
    "                      max_context=32):\n",
    "    \"\"\"\n",
    "    Devuelve: np.ndarray shape [T_gen, 4] con columnas [pitch, step, dur, vel]\n",
    "              (en tu mismo formato downstream).\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import torch\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # --- Normalización defensiva de entradas ---\n",
    "    seed_pitch_seq = np.asarray(seed_pitch_seq, dtype=np.int64)          # [T]\n",
    "    seed_cont_seq  = np.asarray(seed_cont_seq,  dtype=np.float32)        # [T,3]\n",
    "    assert seed_cont_seq.ndim == 2 and seed_cont_seq.shape[1] == 3, \"seed_cont_seq debe ser [T,3]\"\n",
    "\n",
    "    # Construir tensores en el dispositivo sin listas de ndarrays:\n",
    "    def _mk_inputs(pitches_np, cont_np):\n",
    "        # recorta al contexto\n",
    "        pitches_np = pitches_np[-max_context:]\n",
    "        cont_np    = cont_np[-max_context:]\n",
    "        inp_pitch = torch.as_tensor(pitches_np, dtype=torch.long, device=device).unsqueeze(0)   # [1, L]\n",
    "        inp_cont  = torch.as_tensor(cont_np,    dtype=torch.float32, device=device).unsqueeze(0) # [1, L, 3]\n",
    "        return inp_pitch, inp_cont\n",
    "\n",
    "    # Copias de trabajo (para ir anexando)\n",
    "    cur_pitch = seed_pitch_seq.copy()\n",
    "    cur_cont  = seed_cont_seq.copy()\n",
    "\n",
    "    generated_rows = []  # acumularemos filas [pitch, step, dur, vel] (desnormalizadas al final si aplica)\n",
    "\n",
    "    for _ in range(steps):\n",
    "        inp_pitch, inp_cont = _mk_inputs(cur_pitch, cur_cont)\n",
    "        logits, cont_pred = model(inp_pitch, inp_cont)   # logits: [1,L,V]; cont_pred: [1,L,3] (normalizado)\n",
    "\n",
    "        # Tomar el último paso temporal\n",
    "        logits_last = logits.squeeze(0)                  # (V,)  torch.Tensor\n",
    "        cont_last   = cont_pred.squeeze(0).cpu().numpy() # (3,)  np.float32 (normalizado)\n",
    "\n",
    "        # Muestreo discreto\n",
    "        next_pitch_idx = sample_from_logits_topk(logits_last, k=top_k, temperature=temperature)\n",
    "\n",
    "        # ---- Desnormalizar los 3 continuos (si diste 'stats') ----\n",
    "        if stats is not None:\n",
    "            step = (cont_last[0] * (float(stats[\"step_std\"]) + 1e-6)) + float(stats[\"step_mean\"])\n",
    "            dur  = (cont_last[1] * (float(stats[\"dur_std\"])  + 1e-6)) + float(stats[\"dur_mean\"])\n",
    "            vel  = (cont_last[2] * (float(stats[\"vel_std\"])  + 1e-6)) + float(stats[\"vel_mean\"])\n",
    "        else:\n",
    "            step, dur, vel = float(cont_last[0]), float(cont_last[1]), float(cont_last[2])\n",
    "\n",
    "        # Seguridad: valores válidos\n",
    "        next_pitch = int(np.clip(next_pitch_idx, 0, 127))\n",
    "        step = max(0.0, float(step))\n",
    "        dur  = max(1e-3, float(dur))\n",
    "        vel  = float(np.clip(vel, 1.0, 127.0))\n",
    "\n",
    "        # Append a las listas de estado (en formato NORMALIZADO para el modelo)\n",
    "        # Nota: para la siguiente iteración el modelo necesita los continuos NORMALIZADOS,\n",
    "        # por lo que guardamos además la versión normalizada:\n",
    "        if stats is not None:\n",
    "            step_n = (step - float(stats[\"step_mean\"])) / (float(stats[\"step_std\"]) + 1e-6)\n",
    "            dur_n  = (dur  - float(stats[\"dur_mean\"]))  / (float(stats[\"dur_std\"])  + 1e-6)\n",
    "            vel_n  = (vel  - float(stats[\"vel_mean\"]))  / (float(stats[\"vel_std\"])  + 1e-6)\n",
    "            cur_cont = np.vstack([cur_cont, [step_n, dur_n, vel_n]]).astype(np.float32)\n",
    "        else:\n",
    "            cur_cont = np.vstack([cur_cont, [step, dur, vel]]).astype(np.float32)\n",
    "\n",
    "        cur_pitch = np.append(cur_pitch, next_pitch).astype(np.int64)\n",
    "\n",
    "        # Guardar fila desnormalizada para el MIDI\n",
    "        generated_rows.append([next_pitch, step, dur, vel])\n",
    "\n",
    "    return np.asarray(generated_rows, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5fFn6iYgaUw"
   },
   "source": [
    "# Pipeline completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZSwCOwbfiQ4",
    "outputId": "6a88845d-4c25-4ac3-812e-601f5c7fed42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Extrayendo secuencias crudas...\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=4225\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=3300\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2954\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2173\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3868\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2580\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3185\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2792\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2854\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=3395\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1850\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=885\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3239\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=3186\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2970\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1822\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2592\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2073\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1779\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2002\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2191\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1494\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2027\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1588\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=5268\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=5465\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=1374\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=917\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=1705\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=1443\n",
      "[0] prog= 1 name=Bright Acoustic Piano notas=3118\n",
      "[1] prog= 1 name=Bright Acoustic Piano notas=2461\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2418\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2555\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2150\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=993\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2050\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=551\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=3267\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2449\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1447\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1200\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=872\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=781\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=563\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=495\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1515\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1135\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1372\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=952\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1088\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=900\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=2673\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=2480\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=806\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=509\n",
      "[0] prog= 0 name=Acoustic Grand Piano notas=1721\n",
      "[1] prog= 0 name=Acoustic Grand Piano notas=1673\n",
      "  secuencias extraídas: 25\n",
      "2) Estandarizando (pitch se mantiene intacto)...\n",
      "  stats: {'step_mean': np.float32(0.098957), 'step_std': np.float32(0.18229377), 'dur_mean': np.float32(0.33029), 'dur_std': np.float32(0.41488776), 'vel_mean': np.float32(48.245155), 'vel_std': np.float32(17.51278)}\n",
      "3) Creando ventanas...\n",
      "  Train -> Xp_tr: (76482, 32) Xc_tr: (76482, 32, 3) yp_tr: (76482,)\n",
      "  Valid -> Xp_va: (22357, 32) Xc_va: (22357, 32, 3) yp_va: (22357,)\n",
      "vocab_size: 128\n",
      "Training model on device: cuda\n",
      "Epoch 1 | train_loss=35.2130 | val_CE=4.0524 | val_MSE=0.39785 | val_total=23.9451\n",
      "  ↳ ✓ Nuevo mejor modelo guardado en OUTPUT/best_music_lstm.pth\n",
      "Epoch 2 | train_loss=27.8560 | val_CE=3.9662 | val_MSE=0.36526 | val_total=22.2293\n",
      "  ↳ ✓ Nuevo mejor modelo guardado en OUTPUT/best_music_lstm.pth\n",
      "Epoch 3 | train_loss=25.4272 | val_CE=3.9671 | val_MSE=0.34419 | val_total=21.1766\n",
      "  ↳ ✓ Nuevo mejor modelo guardado en OUTPUT/best_music_lstm.pth\n",
      "Epoch 4 | train_loss=23.4120 | val_CE=3.9062 | val_MSE=0.35024 | val_total=21.4183\n",
      "Epoch 5 | train_loss=21.6927 | val_CE=3.8658 | val_MSE=0.33892 | val_total=20.8120\n",
      "  ↳ ✓ Nuevo mejor modelo guardado en OUTPUT/best_music_lstm.pth\n",
      "Epoch 6 | train_loss=19.9914 | val_CE=3.8628 | val_MSE=0.35157 | val_total=21.4415\n",
      "Epoch 7 | train_loss=18.6534 | val_CE=3.8284 | val_MSE=0.33691 | val_total=20.6741\n",
      "  ↳ ✓ Nuevo mejor modelo guardado en OUTPUT/best_music_lstm.pth\n",
      "Epoch 8 | train_loss=17.1289 | val_CE=3.8251 | val_MSE=0.34628 | val_total=21.1392\n",
      "Epoch 9 | train_loss=15.8784 | val_CE=3.8299 | val_MSE=0.34771 | val_total=21.2153\n",
      "Epoch 10 | train_loss=14.6018 | val_CE=3.8231 | val_MSE=0.34845 | val_total=21.2456\n",
      "Epoch 11 | train_loss=13.5706 | val_CE=3.7903 | val_MSE=0.34681 | val_total=21.1306\n",
      "Epoch 12 | train_loss=12.9673 | val_CE=3.7923 | val_MSE=0.34878 | val_total=21.2311\n",
      "Epoch 13 | train_loss=11.5705 | val_CE=3.7905 | val_MSE=0.35717 | val_total=21.6492\n",
      "  ↳ Early stopping en epoch 13 (best_epoch=7)\n",
      "[Gen 1] Usando semilla index: 33948\n",
      "✅ MIDI guardado en: OUTPUT/generated_music_lstm_1.mid (Acoustic Grand Piano)\n",
      "[Gen 1] WAV guardado en:  OUTPUT\\generated_music_lstm_1.wav\n",
      "[Gen 1] MIDI guardado en: OUTPUT\\generated_music_lstm_1.mid\n",
      "[Gen 2] Usando semilla index: 38110\n",
      "✅ MIDI guardado en: OUTPUT/generated_music_lstm_2.mid (Acoustic Grand Piano)\n",
      "[Gen 2] WAV guardado en:  OUTPUT\\generated_music_lstm_2.wav\n",
      "[Gen 2] MIDI guardado en: OUTPUT\\generated_music_lstm_2.mid\n",
      "[Gen 3] Usando semilla index: 24343\n",
      "✅ MIDI guardado en: OUTPUT/generated_music_lstm_3.mid (Acoustic Grand Piano)\n",
      "[Gen 3] WAV guardado en:  OUTPUT\\generated_music_lstm_3.wav\n",
      "[Gen 3] MIDI guardado en: OUTPUT\\generated_music_lstm_3.mid\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"1) Extrayendo secuencias crudas...\")\n",
    "    raw_sequences = extract_raw_note_sequences(ROOT_DIR, instrument_name= INSTRUMENT_NAME, composer_name=COMPOSER)\n",
    "    print(f\"  secuencias extraídas: {len(raw_sequences)}\")\n",
    "\n",
    "    train_sequences, val_sequences = train_test_split(raw_sequences, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "    print(\"2) Estandarizando (pitch se mantiene intacto)...\")\n",
    "    standardized_sequences, stats = standardize_note_sequences(train_sequences)\n",
    "    print(\"  stats:\", stats)\n",
    "\n",
    "\n",
    "\n",
    "    def apply_standardization(seqs, stats):\n",
    "        out = []\n",
    "        for seq in seqs:\n",
    "            s = seq.copy()\n",
    "            s[:,1] = (s[:,1]-stats[\"step_mean\"])/(stats[\"step_std\"]+1e-6)\n",
    "            s[:,2] = (s[:,2]-stats[\"dur_mean\"] )/(stats[\"dur_std\"] +1e-6)\n",
    "            s[:,3] = (s[:,3]-stats[\"vel_mean\"] )/(stats[\"vel_std\"] +1e-6)\n",
    "            out.append(s)\n",
    "        return out\n",
    "\n",
    "    val_standardized = apply_standardization(val_sequences, stats)\n",
    "    print(\"3) Creando ventanas...\")\n",
    "    (Xp_tr, Xc_tr), (yp_tr, yc_tr) = create_windows(standardized_sequences, seq_len=SEQ_LEN)\n",
    "    (Xp_va, Xc_va), (yp_va, yc_va) = create_windows(val_standardized,       seq_len=SEQ_LEN)\n",
    "\n",
    "    print(\"  Train -> Xp_tr:\", Xp_tr.shape, \"Xc_tr:\", Xc_tr.shape, \"yp_tr:\", yp_tr.shape)\n",
    "    print(\"  Valid -> Xp_va:\", Xp_va.shape, \"Xc_va:\", Xc_va.shape, \"yp_va:\", yp_va.shape)\n",
    "\n",
    "\n",
    "    # construir vocab (opcional\n",
    "    if Xp_tr.shape[0] == 0:\n",
    "        raise RuntimeError(\"No hay muestras. Aumenta datos o reduce SEQ_LEN.\")\n",
    "    max_pitch = int(np.max(Xp_tr))\n",
    "    vocab_size = max(128, max_pitch + 1)\n",
    "    print(\"vocab_size:\", vocab_size)\n",
    "\n",
    "    # dataset\n",
    "    train_ds = MusicWindowsDataset(Xp_tr, Xc_tr, yp_tr, yc_tr)\n",
    "    val_ds   = MusicWindowsDataset(Xp_va,   Xc_va,   yp_va,   yc_va)\n",
    "    loader   = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "    vloader  = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "    # modelo\n",
    "    model = MusicLSTM(vocab_size=vocab_size, emb_dim=64, cont_dim=3, hidden_size= HIDDEN_SIZE, num_layers= NUM_LAYERS,dropout=DROPOUT) # Ajustado num_layers\n",
    "    print(\"Training model on device:\", DEVICE)\n",
    "    history = train(\n",
    "        model,\n",
    "        train_loader=loader,\n",
    "        val_loader=vloader,\n",
    "        device=DEVICE,\n",
    "        epochs=EPOCHS,\n",
    "        lr=LR,\n",
    "        cont_loss_weight= PESO_LOSS_CONT,\n",
    "        es_patience=6,                 # ajusta si quieres más/menos paciencia\n",
    "        es_min_delta=1e-4,             # mejora mínima para considerar \"mejora\"\n",
    "        best_ckpt_path=(OUTPUT_DIR / \"best_music_lstm.pth\").as_posix(),\n",
    "    )\n",
    "\n",
    "    # guardar modelo y stats\n",
    "    # Cargar mejor estado antes de generar\n",
    "    best_ckpt = torch.load((OUTPUT_DIR / \"best_music_lstm.pth\").as_posix(), map_location=DEVICE)\n",
    "    model.load_state_dict(best_ckpt[\"model_state\"])\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    # ------------------ Generación de ejemplos ------------------\n",
    " \n",
    "    total_samples = Xp_tr.shape[0]\n",
    "   \n",
    "    # Elegimos índices de semillas distintos si hay suficientes, o con reposición si no\n",
    "    idx_pool = list(range(total_samples))\n",
    "    if total_samples >= NUM_SEQS:\n",
    "        seed_indices = random.sample(idx_pool, NUM_SEQS)  # sin reemplazo\n",
    "    else:\n",
    "        seed_indices = [random.choice(idx_pool) for _ in range(NUM_SEQS)]  # con reemplazo\n",
    "    \n",
    "    for j, idx in enumerate(seed_indices, start=1):\n",
    "        seed_pitch = Xp_tr[idx].tolist()\n",
    "        seed_cont  = Xc_tr[idx]\n",
    "        print(f\"[Gen {j}] Usando semilla index: {idx}\")\n",
    "    \n",
    "        generated = generate_sequence(\n",
    "            model, DEVICE,\n",
    "            seed_pitch, seed_cont,\n",
    "            steps=STEPS_PER_SEQ,\n",
    "            idx2pitch=None,\n",
    "            stats=stats,\n",
    "            temperature=TEMPERATURE,\n",
    "            top_k=TOP_K   # prueba k=10; ajusta a 5–20 según diversidad deseada\n",
    "        )\n",
    "        if generated.shape[0] > 200:\n",
    "          generated = generated[-200:, :]\n",
    "    \n",
    "        midi_path = OUTPUT_DIR / f\"generated_music_lstm_{j}.mid\"\n",
    "        wav_path = OUTPUT_DIR / f\"generated_music_lstm_{j}.wav\"\n",
    "        # Si tu save_sequence_to_midi acepta instrument_name:\n",
    "        save_sequence_to_midi(generated, output_path=midi_path.as_posix(), instrument_name=INSTRUMENT_NAME)\n",
    "        \n",
    "        try:\n",
    "            render_midi_to_wav(midi_path.as_posix(), wav_path.as_posix(), SF2, samplerate=44100)\n",
    "            print(f\"[Gen {j}] WAV guardado en:  {wav_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Gen {j}] ⚠️ No se pudo generar WAV (revisa pyfluidsynth/DLL/SF2): {e}\")\n",
    "        \n",
    "        print(f\"[Gen {j}] MIDI guardado en: {midi_path}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "iJrvj5YdhVoo",
    "C04D1njqhYFn",
    "w1n9XyNyhcej",
    "GtygejbZhgP-",
    "vH4IXLREhjSW"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (jlabclean)",
   "language": "python",
   "name": "jlabclean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
